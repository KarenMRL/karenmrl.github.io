[["index.html", "Teoría del Riesgo Capítulo 1 Conceptos básicos y preeliminares 1.1 Introducción 1.2 Algunos antecedentes históricos 1.3 Algunos términos del seguro 1.4 Clase de primas: 1.5 Clasificación de los seguros 1.6 Distribuciones clásicas en Teoría del Riesgo 1.7 Familias paramétricas para modelar el monto de riesgo 1.8 Modelación del riesgo 1.9 Ajuste de funciones de probabilidad 1.10 Reconocimiento del modelo 1.11 Estimación de parámetros 1.12 Pruebas de bondad de ajuste 1.13 ¿Cómo leer un p-value? 1.14 El proceso de modelación del Riesgo", " Teoría del Riesgo Cinthya Denisse González Mendoza :o 2023-07-20 Capítulo 1 Conceptos básicos y preeliminares 1.1 Introducción La actividad aseguradora está difundida en el mundo entero, son de uso corriente los seguros de automóviles, incendios, robos, vida, etc. Esta actividad responde a la incertidumbre que sienten los individuos ante ciertas situaciones que pueden provocar distintos daños, tanto materiales como personales. El miedo a la posibilidad de que ocurran dichos acontecimientos se intenta eliminar mediante la compra de un seguro que compensará al asegurado en el caso de producirse algún daño. La base de esta actividad radica en la existencia de un equilibrio entre la prestación que hará la compañía de seguros y la contraprestación que ella recibe del asegurado. 1.2 Algunos antecedentes históricos En sus inicios, el seguro era una forma de solidaridad entre los miembros de una comunidad. Consistía en un fondo o bolsa en la que todas las personas depositaban parte de su dinero. Con el capital que acumulaban entre todos, se pagaban los da˜nos que sufrían algunos de ellos. Por ejemplo: Antiguamente existía en algunos puertos la costumbre de que todos los armadores de barcos que hacían una determinada línea, aportaban a un fondo común una cantidad de dinero en función del número de navíos que poseían. Aquellos armadores cuyos barcos se hundían o eran saqueados por piratas, recibían una compensación económica procedente del fondo común para poder adquirir otro barco para continuar su actividad laboral. La Ciencia Actuarial tal como hoy se concibe comienza en el siglo XVII. Durante este periodo las necesidades comerciales dieron lugar a operaciones que acarreaban un interés compuesto;los seguros marítimos eran algo habitual y el cálculo de las rentas vitalicias comenzaba a aparecer. Este tipo de operaciones requería algo más que el juicio intuitivo y comercial de los primeros aseguradores. Uno de los pilares de la Ciencia Actuarial fue la Teoría de Probabilidades, las bases del análisis estadístico en el seguro fueron establecidas por Pascal en 1654 en colaboración con el también matemático Pierre de Fermat. Otro de los pilares es el concepto de tablas de vida, basadas en las investigaciones sobre la mortalidad. Las primeras tablas son debidas a John Graunt (1662). En 1693 Edmund Halley, matemático ingles, publicó un famoso documento describiendo la construcción de tablas de vida completas a partir de la hipótesis de estacionariedad de la población, así como el método de valoración de las rentas vitalicias, que es, en esencia, el mismo que se utiliza hoy en día. Las tablas de Halley se utilizaron por la mayor´ıa de las compañías de seguros inglesas creadas durante el siglo XVIII. En el presente siglo, la Ciencia Actuarial se enriquece con las aportaciones de las matemáticas de los seguros no vida, la teoría estadístico-matemática de la estabilidad y la moderna teoría de la decisión. 1.3 Algunos términos del seguro La actividad aseguradora, como cualquier otra que supone una especialidad, tiene su propia forma de expresarse (jerga). Vamos a ver una serie de términos de uso frecuente: Seguro: Entendido como contrato, es el convenio entre dos partes, la compañía o entidad aseguradora por una parte y el contratante por otra, mediante la cual la primera se compromete a cubrir económicamente la pérdida o daño que el asegurado puede sufrir durante la vigencia del contrato. La obligación del asegurado es pagar, a la firma del contrato, el precio del seguro total o parcialmente. Riesgo: Es la posibilidad de pérdida o daño. El hombre desde que nace vive con la constante amenaza de enfermedad, accidente, muerte, etc. De la misma forma sus propiedades pueden sufrir incendios, robos, etc. Siniestro: Es la concreción del riesgo. Por ejemplo, un incendio que destruye una fábrica, el robo de mercancías, muerte en un accidente, etc. Asegurador: Es la persona jurídica que suscribe el compromiso de ofrecer la protección indemnizatoria cuando se produce el siniestro. Un asegurador es una sociedad anónima, una mutua de seguros, cooperativa, etc. Para que una empresa pueda ejercer legalmente como aseguradora debe tener una autorización que concede la autoridad correspondiente. Asegurado: Es la persona titular del interés asegurado. Es quien sufre el perjuicio económico en sus bienes, en caso de que ocurra el siniestro, o la persona cuya vida o integridad física se asegura y, por lo tanto, quien percibirá la indemnización en caso de que un siniestro afectase al objeto asegurado (excepto en el caso de seguros de vida, en que recibe la indemnización, en caso de muerte. el beneficiario). Beneficiario: Cuando se asegura la vida o la integridad física de una persona puede designarse a otra persona para que reciba las indemnizaciones, que es el beneficiario. Póliza: Es el documento en que se plasma el contrato de seguro. Tiene dos características que la hacen especialmente importante: Es la prueba de que el contrato existe; y Es la normativa que regula las relaciones entre los contratantes. Consta básicamente de tres partes: Condiciones generales: son una serie de cláusulas iguales para todos los contratos de la misma modalidad. Incluyen deberes y derechos, forma de atención del siniestro, riesgos cubiertos,etc. Condiciones particulares: son las que individualizan cada contrato de seguro. Incluyen datos personales del asegurado, características del riesgo que se asegura (incendio, accidente, robo…), importe de la prima, etc. Condiciones especiales: aparecen en algunas pólizas y suponen una adaptación para determinados casos especiales. Por ejemplo, hay unas condiciones generales para todos los seguros de robo, pero dadas las características que pueden tener el seguro de robo a joyerías, se crean para este tipo de establecimientos unas condiciones especiales. Prima: Es el precio del seguro. Es la cantidad de dinero que el asegurado paga para que, a cambio, el asegurador pague en caso de siniestro. La prima es por lo general para una vigencia anual del seguro, aunque excepcionalmente puede pagarse por una sola vez, para la cobertura de varios años (prima única en seguros de vida) y también por una vigencia menor de un año (prima a corto plazo, como en el caso de un viaje, transporte de mercancías, etc.). 1.4 Clase de primas: Prima de riesgo: llamada también prima pura, natural, matemática o estadística, es la cantidad necesaria y suficiente que el asegurador debe percibir para cubrir el riesgo. Nace del concepto de esperanza matemática como precio justo de una eventualidad. Prima de tarifa:también llamada prima comercial, es la prima de riesgo más los recargos. Estos recargos son de varios tipos: Gastos de administración: sueldos, alquileres de locales,etc. Gastos de adquisición: formado básicamente por la comisión que se le paga al corredor o intermediario. Margen de beneficio: son los recargos asignados a la utilidad razonable del asegurador. Prima de facturación:es la prima de tarifa más los recargos de ley, como son los impuestos sobre la prima, los derechos de emisión y otros agregados y ordenados por disposiciones legales, así como los intereses de financiación en el caso de que el asegurador otorgue facilidades de pago fraccionado de la prima anual. 1.5 Clasificación de los seguros Los seguros se pueden clasificar en dos grandes grupos: seguros de vida y seguros de no vida. Un seguro de vida es aquel en el que una entidad aseguradora se compromete, mediante el cobro de una prima única o periódica, a pagar la prestación convenida en el caso de que se cumpla la circunstancia prevista en el contrato: que la persona o personas fallezcan o sobrevivan a un periodo de tiempo determinado. Existen distintas modalidades de seguros de vida: Seguro de vida en caso de muerte. Seguro de vida en caso de vida. Seguro de vida mixtos. Los seguros de no vida van dirigidos a cubrir daños materiales que ocasionan pérdidas económicas. Los más frecuentes son los de automóviles, incendios, robos, etc. En este caso, las prestaciones o indemnizaciones están en función de la cuantía del daño. 1.6 Distribuciones clásicas en Teoría del Riesgo Asociadas al monto de una pérdida En esta materia se busca modelo en general las posibles pérdidas monetarias que pueden haber bajo diferentes contextos. De manera general vamos a ver que un riesgo monetario a asumir tiene dos principales componentes: Sea \\(Y\\) v.a. \\(\\rightarrow\\) continua \\(\\rightarrow\\) severidad($). Sea \\(N\\) v.a. \\(\\rightarrow\\) discreta \\(\\rightarrow\\) frecuencia(#siniestros). La severidad busca modelar pérdidas en términos monetarios, a diferencia de la frecuencia la cual modela la cantidad de siniestros que puede haber de cierto riesgo. Primeramente vamos a trabajar con la severidad. Al ser \\(Y\\) una variable aleatoria que mide la severidad pérdidas de un riesgo monetario. En general se busca que \\(Y\\) sea una v.a. no negativa y continua. Claramente esto puede venir dependiendo del tipo de riesgo que se esté modelando pero usualmente ” el dinero se comporta de forma continua”. Ejemplo: Se busca modelar cuánto hay que pagar si un coche nuevo cuesta (nuevo) $ $ 595,000 $ m.n. y éste sufre algún siniestro. El problema puede ponerse tan complicado como se desee, sin embargo y a priori podemos proponer: \\(X \\ddot{=}\\) monto a pagar si el coche sufre un siniestro \\(X \\sim Unif(0,595000)\\) 1.7 Familias paramétricas para modelar el monto de riesgo Cuando hablemos de las siguientes distribuciones durante el curso estaremos usando las siguientes parametrizaciones salvo que se indique lo contrario. Es ideal que exploren las siguientes distribuciones analizando cambios en sus parámetros, si son de escala, forma,localización, sus diferentes parametrizaciones, etc. Exponencial \\[\\begin{eqnarray*} X &amp;\\sim&amp;{ exp (\\lambda )}\\, \\mbox{con}\\ \\lambda &gt;0.\\\\ f(x) &amp;=&amp; \\lambda e ^{-\\lambda x}\\, \\mbox{para}\\ x &gt; 0.\\\\ F(x) &amp;=&amp; 1 - e ^{-\\lambda x}\\, \\mbox{para}\\ x &gt; 0.\\\\ \\mathbb{E}[X]&amp;=&amp;\\frac{1}{\\lambda}.\\\\ Var(X) &amp;=&amp; \\frac{1}{\\lambda^2}.\\\\ M(t)&amp;=&amp;\\frac{\\lambda}{\\lambda-t}\\, \\mbox{para}\\ t &lt; \\lambda.\\\\ \\end{eqnarray*}\\] Gamma \\[\\begin{eqnarray*} X &amp;\\sim&amp;{ gamma (n, \\lambda)},\\ \\mbox{con}\\ n&gt;0\\ y\\ \\lambda &gt; 0.\\\\ f(x) &amp;=&amp; \\frac{(\\lambda x)^{n-1}}{\\Gamma (n)} \\lambda e^{-\\lambda x}, \\mbox{para}\\ x&gt;0.\\\\ \\end{eqnarray*}\\] \\[\\begin{eqnarray*} F(x) = 1 - e^{-\\lambda x} \\sum_{k=0}^{n-1} \\frac{(\\lambda x)^{k}}{k!} \\quad \\text{para } x &gt; 0 \\text{ y } n \\text{ entero}.\\\\ \\end{eqnarray*}\\] \\[\\begin{eqnarray*} \\mathbb{E}[X]&amp;=&amp;\\frac{n}{\\lambda}\\\\ Var(X)&amp;=&amp;\\frac{n}{\\lambda^2}\\\\ M(t)&amp;=&amp;\\left[ \\frac{\\lambda}{(\\lambda -t)}\\right]^n\\ \\lambda&gt;0\\ y\\ n\\ \\mbox{entero}. \\end{eqnarray*}\\] Log - Normal Nota: La función generadora de momentos no existe. Si X tiene distribución N(\\(\\mu\\) , \\(\\sigma^{2}\\)), entonces \\(e^{x}\\) tiene distribución log normal \\((\\mu , \\sigma^{2})\\). \\[\\begin{eqnarray*} X &amp;\\sim&amp;{ log\\ normal(\\mu , \\sigma^{2})}\\ con\\ \\mu \\in \\mathbb R\\ y\\ \\sigma^{2} &gt; 0.\\\\ f(x) &amp;=&amp; \\frac{1}{x\\sqrt{2 \\pi\\ \\sigma^{2}}}exp\\left[{-\\frac{(ln(x)-\\mu)^{2}}{2\\sigma^{2}}}\\right]\\ para\\ x &gt;0.\\\\ \\mathbb{E}[X]&amp;=&amp; exp\\left(\\frac{\\mu + \\sigma^{2}}{2}\\right).\\\\ \\mathbb{[X^{n}]}&amp;=&amp; exp\\left(n\\mu + \\frac{n^{2}\\sigma^{2}}{2}\\right).\\\\ Var(X)&amp;=&amp; exp(2\\mu + 2\\sigma^{2}) - exp(2\\mu + \\sigma^{2}).\\\\ \\end{eqnarray*}\\] Weibull \\[\\begin{eqnarray*} X &amp;\\sim&amp; Weibull (r, \\lambda)\\ con\\ r&gt;0\\ y\\ \\lambda &gt;0. \\\\ f(x) &amp;=&amp; e^{-(\\lambda x)^{r}} r \\lambda ^{r} x^{r -1}\\ para\\ x&gt;0.\\\\ F(x) &amp;=&amp; 1 - e^{{-(\\lambda x)}^{r}}\\ para\\ x&gt;0.\\\\ E(X) &amp;=&amp; \\frac{\\Gamma \\left(1+\\frac{1}{r}\\right)}{\\lambda}.\\\\ Var(X) &amp;=&amp; \\frac{\\Gamma (1+\\frac{2}{r})-\\Gamma^{2} (1+\\frac{1}{r})}{\\lambda^{2}} \\end{eqnarray*}\\] Nota: En R está parametrizado con \\(\\frac{1}{\\lambda}\\). Burr \\[\\begin{eqnarray*} X&amp;\\sim&amp;Burr(\\theta,\\alpha,\\beta)\\\\ f(x) &amp;=&amp; \\frac{\\beta \\alpha \\theta^{\\alpha} x^{\\beta-1}}{(x^{\\beta} + \\theta)^{\\alpha + 1}}\\ x \\geq 0,\\ \\theta &gt; 0,\\ \\alpha &gt;0,\\ \\beta &gt; 0.\\\\ \\mathbb E (x^{r}) &amp;=&amp; \\frac{\\theta^{\\frac{r}{\\beta}}\\Gamma( \\alpha-\\frac{r}{\\beta})\\Gamma (\\frac{r}{\\beta +1})}{\\Gamma (\\alpha)}\\ ,\\ que\\ existe\\ si\\ r&lt;\\alpha\\beta \\end{eqnarray*}\\] Pareto Pareto \\[\\begin{eqnarray*} X &amp;\\sim&amp;{Pareto (a,b)}\\ con\\ a&gt;0\\ y \\ b&gt;0.\\\\ f(x)&amp;=&amp; \\frac{ab^{a}}{(b+x)^{a+1}}\\ para\\ x&gt;0.\\\\ F(x)&amp;=&amp; 1-\\left[\\frac{b}{(b+x)}\\right]^{a}\\ para\\ x&gt;0.\\\\ \\mathbb{E}[X]&amp;=&amp; \\frac{b}{(a-1)}\\ para\\ a&gt;1.\\\\ Var(X)&amp;=&amp;\\frac{ab^{2}}{(a-1)^{2}(a-2)}\\ para\\ a&gt;2. \\end{eqnarray*}\\] Pareto1 \\[\\begin{eqnarray*} \\mathbb P(X&gt;x)&amp;=&amp; \\left(\\frac{\\theta}{x}\\right)^{\\alpha}\\, x \\geq \\theta,\\ \\alpha&gt;0,\\ \\theta&gt;0.\\\\ F(x)&amp;=&amp; 1-\\mathbb P (X&gt;x) = 1-\\left(\\frac{\\theta}{x}\\right)^{\\alpha}\\\\ f(x; \\alpha, \\theta) &amp;=&amp; F&#39;(x) = \\frac{\\alpha\\theta^{\\alpha}}{x^{\\alpha + 1}},\\ x \\geq \\theta,\\ \\alpha&gt;0,\\ \\theta&gt;0.\\\\ \\end{eqnarray*}\\] \\[\\begin{eqnarray*} \\mathbb E(X) &amp;=&amp; \\frac{\\alpha \\theta}{(\\alpha - 1)}; \\ \\mathbb V(X) = \\frac{\\alpha \\theta^{2}}{(\\alpha-2)(\\alpha - 1)^{2}};\\ \\mathbb E (X^{r})= \\frac{\\alpha \\theta^{r}}{(\\alpha-r)},\\ \\alpha&gt;r,\\ r=1,2,... \\end{eqnarray*}\\] El paquete actuar de R llama como pareto2 o bien pareto a la distribución aquí marcada como “Pareto”. Revisar Script: “Distribuciones asociadas al monto de una pérdida”. 1.8 Modelación del riesgo 1.9 Ajuste de funciones de probabilidad Ahora veamos cómo se hace un ajuste de modelos (distribuciones) de riesgo en una situación donde se tienen datos reales. Cuando se dispone de un conjunto de observaciones pertenecientes a una determinada variable aleatoria con distribución desconocida, lo primero que conviene hacer es tratar de identificar alguna distribución teórica (modelo) que pudiera ajustar bien dichas observaciones. En otras palabras, se trataría de comprobar si estos datos se distribuyen de acuerdo a alguna distribución conocida (Gamma, Pareto, log-normal , Binomial, Poisson, etc.), pues ello facilitaría la realización de inferencias sobre la población. Este proceso se realiza mediante tres etapas básicas. Reconocimiento de la familia de modelos (densidades) subyacente a los datos. Estimación de los parámetros que determinan la densidad particular de esta familia que ajusta a los datos recabados. Verificación de lo adecuado del ajuste del modelo a los datos. 1.10 Reconocimiento del modelo Esta primer etapa combina el conocimiento previo que el usuario posea sobre los datos a modelar, con las diferentes ́técnicas de estad ́ıstica descriptiva que puedan determinar, por ejemplo: Forma de la densidad subyacente. Simetría de la densidad. Unimodalidad o multimodalidad de la densidad. Forma de la función de distribución Dado que en la mayoría de los casos, los usuarios tienen algún conocimiento sobre el modelo que pudo generar la información , ya sea por experiencia empírica o por la literatura del ́área particular de aplicación, un buen principio es tomar en cuenta esta opinión y complementarla con las descripciones gráficas y numéricas que proporciona el análisis descriptivo de los datos. Es aquí donde nos interesa utilizar algunas herramientas estadísticas que nos permitan identificar y comprobar si la información o los datos (variables aleatorias) en cuestión, siguen alguna distribución. En esta parte hablaremos de las propiedades estadísticas que tienen las variables aleatorias que pueden caracterizarlas con la finalidad de lograr reconocerlas a partir de datos con los que contemos. A continuación algunas: Métodos numéricos Medidas de tendencia central (Media, mediana, moda) Medidas de dispersión (Varianza, desviación estándar, rango, rango intercuartilico, coeficiente de variación) Medida de forma (sesgo, curtosis) Forma de la función de distribución Métodos gráficos Histogramas Diagramas de tallo y hoja Box plot Curvas suavizadas de densidad (densidades tipo kernel) Curva de la función de distribución empírica Gráficas de probabilidad A continuación hablaremos de algunos de estos métodos. 1.10.1 Moda de una función de densidad Recordemos que la moda de una variable aleatoria X la definimos como el punto \\(x_{0}\\) tal que: \\[\\begin{eqnarray*} f_{X}(x_{0})\\geq f_{X}(x) \\quad \\forall x \\in Sop\\{x \\} \\\\ \\end{eqnarray*}\\] Ejemplo La moda de una densidad \\(Gamma(n, \\lambda)\\) está dada por lo siguiente: \\[\\begin{eqnarray*} f_{X}(x)= \\frac{(\\lambda x)^{n-1}}{\\Gamma(n)} \\lambda e^{-\\lambda x}\\quad \\mathbb{I}_{(x&gt;0)}(x)\\\\ \\end{eqnarray*}\\] Calculamos su derivada: \\[\\begin{eqnarray*} f^{&#39;}_{X}(x)= \\frac{\\lambda^{n}}{\\Gamma(n)} \\left[ (n-1)x^{n-2}e^{-\\lambda x}-x^{n-1}\\lambda e^{-\\lambda x} \\right] \\end{eqnarray*}\\] Luego, igualamos a cero para encontrar un punto crítico \\[\\begin{eqnarray*} f^{&#39;}_{X}(x_{0})= 0 &amp;\\Leftrightarrow&amp; \\left[ (n-1)x_{0}^{n-2}e^{-\\lambda x_{0}} \\right] =x_{0}^{n-1}\\lambda e^{-\\lambda x} \\end{eqnarray*}\\] Finalmente, obtenemos que: \\[\\begin{eqnarray*} \\therefore x_{0}&amp;=&amp; \\frac{n-1}{\\lambda} \\end{eqnarray*}\\] Entonces si se tiene un conjunto de datos \\(\\{d_{i}\\}_{i=1}^{n}\\) y pudiera trazar su función de densidad empírica; si yo sospecho que esos datos tienen una distribución asociada \\(Gamma(n, \\lambda)\\) entonces su moda debería verse algo así: De tal manera que al ver esto, podamos sospechar que la información que tenemos, realmente proviene de la distribución que nosotros propusimos. Existen distribuciones que tienen dos o más modas, a aquellas que tienen dos son las llamadas distribuciones bimodales. Es posible que una distribución de este estilo sea provocada por una mezcla de variables aleatorias. Una mezcla es una variable aleatoria, digamos \\(Z\\), cuya función de densidad es una combinación lineal de las funciones de densidad de otras dos variables aleatorias, digamos \\(X\\) y \\(Y\\). De tal manera que, tomando \\(a,b \\in (0,1)\\) con \\(a+b=1\\), tenemos que: \\[\\begin{eqnarray*} f_{Z}(t)&amp;=&amp; af_{X}(t)+bf_{Y}(t) \\end{eqnarray*}\\] Dando como resultado que la función de densidad \\(Z\\) tenga un comportamiento similar al siguiente: Script: “Mezclas” 1.10.2 Coeficiente de asimetría (Skewness) Sea \\(X\\) una v.a, el coeficiente de asimetría usualmente se denota como \\(\\alpha\\) y se define: \\[\\begin{eqnarray*}\\alpha \\ddot{=} \\displaystyle\\frac{\\mathbb{E}[(X-\\mu_{X})^{3}]}{\\sigma_{X}^{3}} \\end{eqnarray*}\\] Donde: \\[\\begin{eqnarray*} \\mu_{X}&amp;\\ddot{=}&amp; \\mathbb{E}[X]\\\\ \\sigma_{X}&amp;\\ddot{=}&amp; \\sqrt{Var(X)} \\end{eqnarray*}\\] Este número es de interés ya que gracias a él, podemos describir de manera teórica la forma de la densidad de una variable aleatoria. Dada una muestra aleatoria \\(\\{X_{i}\\}_{i=1}^{n}\\), podemos obtener el coeficiente de asimetría de forma ’’empírica” (o muestral), simplemente tomando los estimadoras de la media y la varianza que ya conocemos: Para la esperanza tenemos: \\[\\begin{equation*} \\widehat{\\mathbb{E}[X]} = \\frac{1}{n} \\sum_{i=1}^{n} x_{i} = \\bar{x} \\end{equation*}\\] Y para la varianza, tenemos: \\[\\begin{eqnarray*} \\widehat{Var[X]} &amp;=&amp; \\left \\{ \\begin{matrix} \\displaystyle\\frac{1}{n-1} \\displaystyle\\sum_{i=1}^{n}(x_{i}-\\bar{x})^2&amp; insesgado \\\\ \\displaystyle\\frac{1}{n} \\displaystyle\\sum_{i=1}^{n}(x_{i}-\\bar{x})^2&amp; máximo \\quad versosímil\\\\ \\end{matrix}\\right. \\end{eqnarray*}\\] Por lo tanto, el coeficiente de asimetría queda definido como sigue: \\[\\begin{eqnarray*} \\widehat{\\alpha}= \\displaystyle\\frac{\\displaystyle\\frac{1}{n} \\displaystyle\\sum_{i=1}^{n}(x_{i}-\\bar{x})^{3}}{(\\widehat{Var[X]})^{3/2}}\\\\ \\end{eqnarray*}\\] Dado un valor de \\(\\alpha\\) entonces: Si \\(\\alpha&gt;\\) 0, entonces la distribución es “asimétrica positiva” (o “asimétrica a la derecha”). Si \\(\\alpha\\)=0, entonces la distribución es “simétrica”. Si \\(\\alpha&lt;\\) 0, entonces la distribución es “asimétrica negativa (o”asimétrica a la izquierda). 1.10.3 Coeficiente de Kurtosis Sea \\(X\\) una v.a. el coeficiente de kurtosis, usualmente se denota como \\(K\\) y se define: \\[\\begin{eqnarray*} K \\ddot{=} \\frac{\\mathbb{E}[(X-\\mu_{X})^{4}]}{\\sigma_{X}^{4}}\\\\ \\end{eqnarray*}\\] Análogamente al coeficiente de asimetría podemos calcular de manera muestral el coeficiente de Kurtosis tomando los estimados de la esperanza y varianza: Para la esperanza tenemos: \\[\\begin{equation*} \\widehat{\\mathbb{E}[X]} = \\displaystyle\\frac{1}{n} \\sum_{i=1}^{n}x_{i}= \\bar{x} \\end{equation*}\\] Y para la varianza, tenemos: \\[\\begin{eqnarray*} \\widehat{Var[X]} &amp;=&amp; \\left \\{ \\begin{matrix} \\displaystyle\\frac{1}{n-1} \\displaystyle\\sum_{i=1}^{n}(x_{i}-\\bar{x})^2&amp; insesgado \\\\ \\displaystyle\\frac{1}{n} \\displaystyle\\sum_{i=1}^{n}(x_{i}-\\bar{x})^2&amp; máximo \\quad versosímil\\\\ \\end{matrix}\\right. \\end{eqnarray*}\\] Por lo tanto, el coeficiente de asimetría queda definido como sigue: \\[\\begin{eqnarray*}\\widehat{K}= \\displaystyle\\frac{\\displaystyle\\frac{1}{n} \\displaystyle\\sum_{i=1}^{n}(x_{i}-\\bar{x})^{4}}{(\\widehat{Var[X]})^{2}}\\\\ \\end{eqnarray*}\\] Donde \\(K\\) también tiene una interpretación gráfica como veremos a continuación: Si \\(K&gt;\\) 3, entonces la distribución es más apuntada y con colas menos gruesas que la normal estándar. Si \\(K\\)=3, entonces la distribución tiene una forma apuntada y con colas similares la normal estándar. Si \\(K&lt;\\) 3, entonces la distribución es menos apuntada y con colas más gruesas que la normal estándar. 1.10.4 Función de distribución empírica Dada una muestra de datos \\(\\{X_{i}\\}_{i=1}^{n}\\) construimos la función de distribución empírica como: \\[\\begin{equation*} F_n(t) \\ddot{=} \\frac{\\sum_{i=1}^{n} \\mathbb{I}(x_{i} \\leq t)}{n} = \\frac{\\#\\{ x_{i}: x_{i} \\leq t\\}}{n} \\end{equation*}\\] Véase: Figura 1. https://www.youtube.com/watch?v=iN3BDlmfdT0 Teniendo nuestros datos, la distribución empírica se ve de la siguiente manera: 1.10.5 Cuantiles Recordemos que, dada una variable aleatoria \\(X\\) si denotamos a \\(F_{X}(t)\\) como su función de distribución (acumulada) de \\(X\\), entonces, tomando \\(\\alpha \\in [0,1]\\). El cuantíl del \\(\\alpha\\) de \\(X\\) se define como: \\[\\begin{eqnarray*} q_{X}(\\alpha)\\ \\ddot{=}\\ ínf\\{t \\in Sop\\{X\\}: F_{X}(t)\\geq \\alpha\\}\\\\ \\end{eqnarray*}\\] La definición anterior está muy ligada con el concepto de “Inversa generalizada de la distribución acumulada”. Podemos decir que si \\(t \\in Sop \\{X\\}\\): \\[\\begin{eqnarray*} F_{X}(t)= \\alpha &amp;\\Rightarrow&amp; t=q_{X}(\\alpha) \\end{eqnarray*}\\] Como estos conceptos aplican para cualquier función de distribución (acumulada), en particular aplicará para la función de distribución empírica. En tal caso dichos cuantiles son también llamados cuantiles empíricos. 1.10.6 Rango intercuantílico Dada una variable aleatoria \\(X\\), definimos al rango intercuantílico como: \\[\\begin{eqnarray*} q_{X}(75\\%)-q_{X}(25\\%)\\\\ \\end{eqnarray*}\\] Una vez que determinamos una posible familia paramétrica (distribución) que siguen los datos, procedemos a dar el siguiente paso. 1.11 Estimación de parámetros Una vez que se ha reconocido la familia a la que pertenece el modelo que pueda ajustar a los datos, el siguiente paso es determinar concretamente cuál de los modelos de esta familia es el que se ajusta a nuestra información. Es decir, necesitamos estimar los parámetros de este modelo particular. Existen diversos métodos para estimar los parámetros de una distribución, los más usuales son: 1.11.1 Método de momentos Se tiene una muestra aleatoria \\(\\{{X_i}\\}^n_{i=1}\\) de una distribución \\(F(\\underline{X},\\underline{\\theta})\\) donde \\(\\underline{\\theta}\\ \\ddot{=}\\ (\\theta_1,\\ldots,\\theta_p)\\) es un vector de parámetros. Sean: \\[\\begin{eqnarray*} \\mu_k(\\underline{\\theta})\\ \\ddot{=}\\ \\mathbb{E}[X^k | \\underline{\\theta}]=\\int x^k f_X(x)dx\\quad \\rightarrow \\quad \\text{momentos poblacionales.}\\\\ \\end{eqnarray*}\\] \\[\\begin{eqnarray*} \\mu_k\\ \\ddot{=}\\ \\frac{1}{n} \\sum^n_{i=1}x^k_i \\rightarrow \\quad \\text{momentos muestrales.} \\end{eqnarray*}\\] La metodología consiste en obtener momentos poblacionales (teóricos) en términos de los momentos muestrales a través de un planteamiento de sistemas de ecuaciones. En pocas palabras, si \\(\\underline{\\theta}=(\\theta_1,\\ldots,\\theta_p)\\) son los parámetros, que es lo que buscamos. Entonces podemos calcular \\(\\underline{\\mu}=(\\mu_1,\\ldots,\\mu_p)\\) y resolver: \\[\\begin{eqnarray*} \\underline{\\mu} = (\\mu_1,\\ldots,\\mu_p) = (\\mu_1(\\underline{\\theta}),\\ldots,\\mu_p(\\underline{\\theta}))\\ \\ddot{=}\\ \\underline{\\mu(\\underline{\\theta})} \\end{eqnarray*}\\] Ejemplo 1: \\(X\\sim Bernoulli(\\underbrace{p}_1)\\)\\(\\rightsquigarrow\\) tiene un parámetro \\[\\begin{eqnarray*} \\underline{\\mu} = (\\underline{\\mu}_1(\\underline{\\theta}))= \\underline{\\mu(\\underline{\\theta})}\\\\ \\end{eqnarray*}\\] \\[\\begin{eqnarray*} = \\frac{1}{n} \\sum^n_{i=1}x_i\\ \\ddot{=}\\ \\overline{X}= \\mathbb{E}[X]=p \\end{eqnarray*}\\] Entonces, si tú sospechas que las \\(\\{x_i\\}^n_{i=1}\\) vienen de una distribución Bernoulli, entonces en tal caso, su parámetro estimado es: \\[\\begin{eqnarray*} \\widehat{p}=\\overline{X} \\end{eqnarray*}\\] Ejemplo 2: \\(X\\sim Normal(\\underbrace{\\mu}_{1},\\underbrace{\\sigma^2}_{2})\\)\\(\\rightsquigarrow\\) 2 parámetros necesitamos \\(\\mu_1\\) y \\(\\mu_2\\) y nosotros sabemos que \\(\\mathbb{E}[X]=\\mu\\) y \\(Var(X)=\\sigma^2\\) entonces: \\[\\begin{equation*} \\left\\lbrace \\begin{array}{ll} \\mathbb{E}[X]=\\mu\\\\ \\mathbb{E}[X^2]=Var(X)+\\mathbb{E}^2[X]=\\sigma^2+\\mu^2 \\end{array} \\right. \\end{equation*}\\] \\[\\begin{eqnarray*} \\mu_1&amp;=&amp;\\mu\\\\ \\mu_2&amp;=&amp;\\sigma^2+\\mu^2 \\Leftrightarrow \\sigma^2=\\mu_2 - \\mu^2 = \\mu_2-\\mu^2_1 \\end{eqnarray*}\\] Luego, haciendo un poco de desarrollo algebraico: \\(\\widehat{\\mu}=\\mu_1\\ \\ddot{=}\\ \\overline{X}\\) \\(\\widehat{\\sigma^2}=\\mu_2-\\mu_1^2=\\frac{1}{n} \\sum\\limits^n_{i=1} x^2_i-\\overline{X}^2\\) \\(=\\cdots=\\frac{1}{n}\\sum\\limits^n_{i=1}(x_i-\\overline{x})^2\\) Ejemplo 3: Sea \\(X\\sim Gamma(\\underbrace{\\alpha}_{1},\\underbrace{\\beta}_{2})\\)\\(\\rightsquigarrow\\) 2 parámetros Tomamos el sistema de ecuaciones: \\[\\begin{eqnarray*} \\mathbb{E}[X]&amp;=&amp;\\frac{\\alpha}{\\beta}=\\mu_1=\\frac{1}{n}\\sum^n_{i=1}x_i=\\overline{X}\\rightsquigarrow \\text{Muestra de tamaño n.}\\\\ \\mathbb{E}[X^2] &amp;=&amp; Var(X)+\\mathbb{E}^2[X]\\\\ &amp;=&amp;\\frac{\\alpha}{\\beta^2}+\\left(\\frac{\\alpha}{\\beta}\\right)^2=\\mu_2=\\frac{1}{n}\\sum^n_{i=1}x^2_i \\end{eqnarray*}\\] \\[\\begin{equation*} \\left\\lbrace \\begin{array}{ll} \\mu_1=\\frac{\\alpha}{\\beta} \\Leftrightarrow \\beta=\\frac{\\alpha}{\\mu_1}\\\\ \\mu_2=\\frac{\\alpha}{\\beta^2}+\\frac{\\alpha^2}{\\beta^2}=\\frac{\\alpha(1+\\alpha)}{\\beta^2}\\Leftrightarrow \\mu_2=\\frac{\\alpha(\\alpha+1)}{\\left(\\frac{\\alpha}{\\mu_1}\\right)^2} \\end{array} \\right. \\end{equation*}\\] \\[\\begin{eqnarray*} &amp;\\Leftrightarrow&amp; \\mu_2=\\mu^2_1\\left(\\frac{\\alpha+1}{\\alpha}\\right)=\\mu^2_1\\left(1+\\frac{1}{\\alpha}\\right)\\\\ &amp;\\Leftrightarrow&amp; \\frac{1}{\\alpha}=\\frac{\\mu_2}{\\mu^2_1}-1=\\frac{\\mu_2-\\mu^2_1}{\\mu^2_1} \\Leftrightarrow \\underline{\\widehat{\\alpha}=\\frac{\\mu^2_1}{\\mu_2-\\mu^2_1}}\\\\ &amp;\\Leftrightarrow&amp;\\underline{\\widehat{\\beta}=\\frac{\\widehat{\\alpha}}{\\mu_1}=\\frac{\\mu_1}{\\mu_2-\\mu^2_1}} \\end{eqnarray*}\\] 1.11.2 Máxima verosimilitud Dada una muestra \\(\\{X_i\\}^n_{i=1}\\) de v.a.i.i.d. procedemos a obtener su función de verosimilitud la cual sabemos está ligada con la **función de densidad conjunta. Al ser i.i.d tendremos que: \\[\\begin{eqnarray*} \\mathcal{L}(\\theta,\\underline{X})=f(\\underline{X},\\theta)=\\prod^n_{i=1}f(x_i|\\theta) \\end{eqnarray*}\\] La metodología nos dice que fijemos \\(\\underline{X}\\) (haciendo referencia a que esos son los datos que tenemos) y maximicemos con respecto de los parámetros. Debido a que \\(ln(x)\\) es una función creciente, maximizar \\(\\ell(\\theta,\\underline{X})\\ \\ddot{=}\\ ln(\\mathcal{L}(\\theta,\\underline{X}))\\) resulta ser equivalente y más sencillo en la mayoría de las ocasiones. Ejemplo: Asumamos una muestra \\(\\{X_i\\}^{k}_{i=1}\\) de v.a.i.i.d. con distribución \\(Gamma(n,\\lambda\\)). Con parámetro n conocido (como es conocido no necesito estimarlo). Entonces: \\[\\begin{eqnarray*} \\mathcal{L}(\\lambda|\\underline{X},n)&amp;=&amp;\\prod^{k}_{i=1}f(x_i|\\lambda,n)=\\prod^{k}_{i=1}\\frac{(\\lambda x_i)^{n-1}}{\\Gamma(n)}\\lambda e ^{-\\lambda x_i}\\\\&amp;=&amp;\\prod^{k}_{i=1}\\frac{ x_i^{n-1}}{\\Gamma(n)}\\lambda^n e ^{-\\lambda x_i}\\\\ \\Rightarrow \\ell(\\lambda|\\underline{X},n)&amp;=&amp;ln(\\mathcal{L}(\\lambda|\\underline{X},n))\\\\ &amp;=&amp;\\sum^{k}_{i=1}((n-1)ln(x_i)-ln(\\Gamma(n))+nln(\\lambda)-\\lambda x_i)\\\\ &amp;=&amp;(n-1)\\sum^{k}_{i=1}ln(x_i)-kln(\\Gamma(n))+nkln(\\lambda)-\\lambda\\sum^{k}_{i=1}x_i \\end{eqnarray*}\\] \\[\\begin{eqnarray*} \\Rightarrow \\frac{\\partial}{\\partial\\lambda}\\ell(\\lambda|\\underline{X},n)&amp;=&amp;nk\\left(\\frac{1}{\\lambda}\\right)-\\sum^{k}_{i=1}x_i\\\\ &amp;=&amp;nk\\frac{1}{\\lambda}-k\\overline{X} \\end{eqnarray*}\\] Así: \\[\\begin{eqnarray*} \\frac{\\partial}{\\partial \\lambda}\\ell(\\widehat{\\lambda}|\\underline{X},n)= 0 &amp;\\Leftrightarrow&amp; nk\\left(\\frac{1}{\\widehat{\\lambda}}\\right)=k\\overline{X}\\\\ &amp;\\Leftrightarrow&amp; \\underline{\\widehat{\\lambda}=\\frac{n}{\\overline{X}}} \\end{eqnarray*}\\] ¿Cómo sabemos si es máximo? \\[\\begin{eqnarray*} \\frac{\\partial^2}{\\partial\\lambda^2}\\ell(\\lambda|\\underline{X},n)=-nk\\left(\\frac{1}{\\lambda^2}\\right)&lt;0\\quad\\forall\\lambda\\in\\mathbb{R}\\\\ \\therefore \\widehat{\\lambda}=\\frac{n}{\\overline{X}} \\quad \\underline{\\text{es máximo}} \\end{eqnarray*}\\] Existen diversas metodologías para obtener los parámetros del modelo que nosotros estamos proponiendo. En particular, la paquetería estadística R utiliza métodos numéricos para hacer ésta estimación. Propiedad de Invarianza para los estimadores máximo verosímiles: Esta propiedad establece principalmente que si \\(\\eta=\\tau(\\theta)\\) es una función de un parámetro de interés y \\(\\widehat{\\theta}\\) es el EMV para \\(\\theta\\), entonces el EMV para \\(\\eta\\) es \\(\\widehat{\\eta}=\\widehat{\\tau(\\theta)}=\\tau(\\widehat{\\theta})\\). Ejemplo: De nuestro ejemplo anterior, el EMV para \\(\\tau (\\lambda)\\) es \\(\\tau\\left(\\frac{n}{\\overline{X}}\\right)\\). Un vídeo donde se explica a grandes rasgos lo anterior lo podrán ver en el siguiente enlace: https://www.youtube.com/watch?v=zPSj0ltrBoc 1.12 Pruebas de bondad de ajuste Los procedimientos para probar qué tan bien se ajusta un modelo a un conjunto de datos reciben el nombre genérico pruebas de bondad de ajuste y constituyen un área de desarrollo permanente en la estadística. Como mencionamos líneas arriba, en la determinación de un modelo paramétrico, es necesario asignar una distribución para los datos de severidad, de frecuencia o ambos. En el caso de las distribuciones asociadas a la frecuencia de reclamaciones, existen algunas guías que pueden sugerir el modelo a considerar en una situación particular, como el hecho que una distribución Poisson posea media y varianza iguales, mismo que puede comprobarse calculando las correspondientes versiones muestrales de estos parámetros. Si, como ocurre frecuentemente, la varianza es mayor a la media, entonces tendríamos evidencia empírica para suponer un modelo binomial negativo. No obstante esto, no existen de manera general, este tipo de indicaciones que sugieran qué distribución elegir cuando tenemos datos de severidad. Por esta razón, es necesario recurrir a procesos generales como las pruebas de bondad de ajuste, que puedan auxiliarnos en esta importante tarea. 1.12.1 Planteamiento general de una prueba de bondad de ajuste Este tipo de pruebas son esencialmente pruebas de hipótesis, con la característica particular de que la hipótesis que queremos probar no es, como generalmente ocurre, acerca del valor particular de algún(os) parámetro(s), sino sobre una función de distribución específica. Estas pruebas se enuncian como: \\[H_0:F(x)=F_0(x) \\quad\\forall x\\quad vs\\quad H_1: F(x) \\neq F_0(x) \\quad p.a.x\\] donde \\(F_0\\) es la distribución que suponemos siguen nuestros datos. Como podemos observar necesitamos definir qué distribución es la que consideramos que ajusta a nuestra información. A este respecto podemos tener diversas opciones: \\(F_0\\) es totalmente conocida. En el sentido que se conoce su forma funcional y su(s) parámetro(s). \\(F_0\\) es parcialmente conocida. Se conoce su forma funcional pero se desconoce algún(os) de su(s) parámetro(s). \\(F_0\\) es totalmente desconocida. Se conoce su forma funcional pero se desconocen su(s) parámetro(s). Contrario a las pruebas de hipótesis usuales, en las pruebas de bondad de ajuste no se especifica la hipótesis alternativa, ya que el modelo que se enuncia en la hipótesis nula, no se compara contra un modelo alternativo que debería estar especificado en la hipótesis alternativa. La razón de este hecho es que estamos interesados en verificar que la distribución de nuestros datos es la que proponemos y si no lo es, no es de interés saber qué otra distribución sí es. 1.12.2 Algunas pruebas de bondad de ajuste Presentaremos de manera sencilla algunas de las pruebas más comunes para realizar bondad de ajuste. Dado que nuestros datos sobre la severidad de una pérdida pueden presentar truncamiento por la izquierda, que corresponde a aquellas pérdidas que no rebasaron el deducible, y censura por la derecha, que son las pérdidas que sobrepasaron el límite de póliza, las estadísticas se deben modificar para contemplar estas particularidades de los datos. 1.12.2.1 Prueba de Kolmogorov-Smirnov (K-S) La estadística se define como \\[D=\\mathop{sup}\\limits_x\\ |F_n(x)-F_0(x)|\\] que se puede expresar mediante las dos estadísticas \\[D^+=\\mathop{sup}\\limits_x\\{F_n(x)-F_0(x)\\}\\quad\\text{y}\\] \\[D^-=\\mathop{sup}\\limits_x\\{F_0(x)-F_n(x)\\}\\] y se calcula mediante \\[\\begin{eqnarray*} D^+ &amp;=&amp; \\mathop{máx}\\limits_{1\\leq x\\leq n}\\left\\{\\frac{i}{n}-z_{(i)}\\right\\}\\\\ D^- &amp;=&amp; \\mathop{máx}\\limits_{1\\leq x\\leq n}\\left\\{z_{(i)}-\\frac{(i-1)}{n}\\right\\}\\\\ D&amp;=&amp; máx\\{D^+,D^-\\} \\end{eqnarray*}\\] con \\(z_{(i)}=F(x_i)\\) y \\(z_{(i)}\\) el i-ésimo elemento en la muestra ordenada de las \\(z&#39;_is\\). Esta prueba se usa para datos desagregados y para variables aleatorias continuas, i.e.,\\(F_0\\) es una función de distribución continua \\(F_n\\) es la función de distribución empírica, y se calcula con los datos reales. 1.12.2.2 Prueba Anderson-Darling (A-D) Esta prueba es similar a la K-S pero mide las diferencias entre las funciones empírica y propuesta de distinta manera. Una característica a destacar de esta prueba es que asigna mayor peso a las colas de la distribución, es decir, enfatiza la bondad de ajuste que se tenga en las colas entre el modelo propuesto y la función de distribución empírica, que es el modelo asociado a los datos reales. La forma explícita de la Anderson-Darling es: \\[\\begin{eqnarray*} A^2&amp;=&amp; n\\displaystyle \\int_0^1\\frac{[F_n(x)-F_0(x)]^2}{F_0(x)[1-F_0(x)]}dF_0(x)dx\\\\ &amp;=&amp; -n-\\frac{1}{n}(2i-1)\\sum^n_{i=1}\\{log(z_{(i)})+log(1-z_{(n+1-i)})\\}\\\\ &amp;=&amp;-n-\\frac{1}{n}\\sum^n_{i=1}\\{(2i-1)log(z_{(i)})+(2n+1-2i)log(1-z_{(i)})\\} \\end{eqnarray*}\\] al igual que K-S esta es una prueba que no trabaja con datos agrupados. 1.12.2.3 Prueba Ji-cuadrada de bondad de ajuste Esta es probablemente la más popular de las pruebas de bondad de ajuste, además de que, contrario a K-S y A-D, es una prueba para distribuciones continuas y discretas; de hecho, también tiene una versión multivariada.La prueba se basa en particionar el rango de las variables observadas en \\(k\\) celdas o clases, y calcular el número de observaciones que se esperaría tener en cada clase si la hipótesis nula fuera correcta, i.e., si \\(F_0\\) es cierta, y compararlo contra el número de observaciones que realmente cayeron en cada celda. Si denotamos por \\(\\mathbb{E}_j\\) al número esperado y por \\(O_j\\) al observado en la celda \\(j,j=1,2,\\ldots,k,\\) la estadística Ji-cuadrada de bondad de ajuste es: \\[\\chi^2=\\sum^k_{j=1}\\frac{(\\mathbb{E}_j-O_j)^2}{\\mathbb{E_j}}\\] Si los valores observados \\((O_j)\\) y esperados \\((\\mathbb{E_j})\\) son similares, el valor de esta estadística es pequeño, e indicaría que \\(F_0\\) es cierta. Si, por el contrario, estos valores son muy distintos, su valor debería ser grande e implicaría que \\(F_0\\) es falsa. Prueba de Kolmogorov-Smirnov. Tenemos el siguiente planteamiento de hipótesis: \\(H_0\\): los datos provienen de la misma distribución \\(F(x)=F_0(x)\\) vs \\(H_1:F(x)\\neq F_0(x).\\) Para realizar la prueba en R, usamos el siguiente comando: Comandos para la prueba de Kolmogorov Smirnov: ks.test(muestra1,muestra2) ks.test(muestra,\"distribución\",parámetros) Prueba de Anderson-Darling. Las hipótesis para la prueba de Anderson-Darling son: \\(H_0\\): los datos siguen una distribución especificada. \\(H_1\\): Los datos no siguen una distribución especificada. En R, haremos uso de la librería goftest, y usamos la funcióngoftest::ad.test(). Prueba Ji-Cuadrada. En términos generales, esta prueba contrasta frecuencias (o categorías) observadas contra las frecuencias esperadas (las que te da la teoría). Donde: \\(O_j: Observados\\) y \\(e_j:Esperados\\) \\[X^2=\\sum^k_{j=1}\\frac{(O_j-e_j)^2}{e_j}\\sim \\chi^2_{(k-1)}\\] Usando la función: chisq.test(x=observados,p=esperados). 1.13 ¿Cómo leer un p-value? Para eso recordemos que cada prueba de hipótesis tiene detrás un estadístico de prueba. Veamos el caso de la prueba Ji-cuadrada, si observamos el estadístico de prueba, podemos notar que si tienen un valor “muy grande” entonces “lo que espero ver se aleja demasiado de lo que realmente observé. Por lo que debería rechazar lo que yo estaba esperando (suponiendo) pues no se parece a lo que observo.” De manera genérica podemos pensar que si tengo un estadístico de prueba “muy grande” entonces “es porque estoy cometiendo errores grandes”. Llamemos Z como el estadístico de prueba, entonces el p-value es la probabilidad de superar el umbral Z. Recordemos un gráfico muy socorrido en estadística: 1.13.1 Región de Rechazo y no rechazo: En general, podríamos ver gráficamente una prueba de hipótesis asi: Dado un estadístico de prueba, este podría caer en la región de “aceptación” (no-rechazo) o en la región de rechazo. Eso pues precisamente si el estadístico de prueba (Z) es muy grande, es porque lo que supongo \\((H_0)\\) comente muchos errores. Bueno, pues si fijamos que la región de rechazo tenga un área del \\(\\alpha=5\\%\\) (como usualmente se toma) entonces tendremos algo así: Si el p-value es la probabilidad de ver un valor más extremo que el estadístico de prueba (estadística observada) entonces existen básicamente dos casos: p-value \\(&gt; \\alpha\\) Como p-value \\(&gt; \\alpha\\) en el fondo estamos diciendo que el estadístico de prueba no fue tan grande y por tanto la hipótesis nula es estadísticamente correcta al coincidir lo suficiente con lo observado. \\[\\begin{eqnarray*} \\therefore p-value &gt; \\alpha &amp;\\Leftrightarrow&amp;\\quad \\text{``El estadístico de prueba cae en la región de no-rechazo&#39;&#39;}\\\\ &amp;\\Leftrightarrow&amp; \\quad\\text{No Rechazamos $H_0$ a un nivel de significancia $\\alpha$ (confianza 1-$\\alpha)$} \\end{eqnarray*}\\] p-value \\(&lt; \\alpha\\) Este es el caso contrario, por tanto, lo que estamos asumiendo como \\(H_0\\) no está viéndose reflejado en los datos observados. \\[\\begin{eqnarray*} \\therefore p-value &lt; \\alpha &amp;\\Leftrightarrow&amp;\\quad \\text{&quot;El estadístico de prueba cae en la región de rechazo&#39;&#39;}\\\\ &amp;\\Leftrightarrow&amp; \\quad\\text{Rechazamos $H_0$ a un nivel de significancia $\\alpha$ (confianza 1-$\\alpha)$} \\end{eqnarray*}\\] 1.14 El proceso de modelación del Riesgo Recordemos que un modelo matemático, estadístico, actuarial, o de cualquier naturaleza, es una representación simplificada de algún fenómeno real. En un contexto actuarial específico, proponer un modelo para describir una situación, se basa en la experiencia y conocimiento que el Actuario tenga del fenómeno bajo estudio, así como de la información histórica que posea sobre él. El modelo debe proveer un balance entre simplicidad (parsimonia) y conformidad (ajuste) con la información disponible para elaborarlo. 1.14.1 El proceso de modelado Sin pretender ser exhaustivos, podemos reconocer ciertos pasos a seguir para modelar una situación actuarial. Es importante remarcar que, aunque los pasos se enumeren ordenadamente, la dinámica del proceso permite regresar a algunos puntos anteriores, para su mejor especificación. Finalmente, hay que recordar que modelar tiene algo de técnica y mucho de arte. 1.14.2 Pasos Uno o más modelos pueden seleccionarse de acuerdo al conocimiento inicial y experiencia que posea el analista, además de la naturaleza de la información disponible. Ajustar el modelo con la información disponible. Realizar pruebas de bondad de ajuste y diagnóstico del modelo, para determinar si su ajuste es adecuado para los datos utilizados. Considerar, a partir del paso anterior, la posibilidad de utilizar otros modelos. Si existen varios modelos que pueden ser adecuados, entonces, es necesario compararlos con la finalidad de decidir por alguno de ellos. Finalmente, el modelo seleccionado puede adaptarse para aplicarlo en el futuro. Esto puede involucrar algún ajuste de los parámetros, previendo cambios por alguna característica exógena, como inflación, cambios del mercado asegurado o cualquier otra. "],["medidas-de-riesgo.html", "Capítulo 2 Medidas de Riesgo 2.1 Distribuciones para valores extremos 2.2 VaR &amp; T-VaR", " Capítulo 2 Medidas de Riesgo 2.1 Distribuciones para valores extremos 2.1.1 Teoría de valores extremos La Teoría de Valores Extremos (Extreme value theory) consiste en el empleo de una serie de técnicas estadísticas para la identificación y modelado de observaciones extremas u outliers. Su objeto es determinar que tan extrema puede ser la mayor o menor observación de un fenómeno aleatorio, es decir, estudia el comportamiento del valor máximo o mínimo de una variable aleatoria. El comportamiento inusual de una variable aleatoria merece una consideración especial, ya que puede tener un gran impacto para las decisiones que se desprendan del análisis de la información a la que pertenece. Para explicar este tipo de sucesos que ocurren, generalmente, con muy baja frecuencia, que ocurren, generalmente, con muy baja frecuencia, pero que tienen influencia muy significativa sobre todo un modelo. La Teoría de Valores Extremos emplea métodos matemáticos basados en comportamientos asintóticos, distribuciones, procesos estocásticos y leyes limite. Diferentes investigaciones provenientes de múltiples disciplinas científicas, han desarrollado métodos para cuantificar eventos extremos y sus consecuencias de un modo estadísticamente óptimo,dando lugar a unas distribuciones de probabilidad que permiten la modelación de los valores máximos o mínimos de una variable aleatoria. De forma simplificada, nuestro problema es el siguiente: Dada una muestra independiente \\(X_{1}, X_{2},...,X_{n}\\) de una distribución desconocida, queremos estimar la cola de \\(F\\). Los problemas más importantes son: Las observaciones en la cola de la distribución son escasas. Por lo general, queremos estimar valores por encima del valor máximo de la muestra. Las técnicas usuales de estimación de densidades ajustan bien en las zonas donde los datos tienen mayor densidad, pero pueden ser inadecuadas para estimar las colas. Los modelos correspondientes a esta teoría de valores extremos, tienen aplicaciones en muchas áreas, una de las principales es: las ciencias ambientales, donde se estudian valores extremos, por ejemplo en: Nivel de una presa, velocidad del viento, nivel de un río, concentración de contaminantes, niveles de precipitación pluvial, etc… No obstante , nosotros nos enfocamos en aplicarla dentro del marco del seguro. En esta área, el análisis de siniestralidad extrema es de gran interés, puesto que constituye un riesgo que pone en peligro la estabilidad y solvencia de entidades aseguradoras. Recordemos una de las definiciones de convergencia, que aprendieron en los cursos de probabilidad básica: Definición: Convergencia en distribución La sucesión de variables aleatorias \\(X_{1}, X_{2},...\\) converge en distribución a \\(X\\), si para todo punto \\(x\\) en donde la función \\(F_{X}(x)\\) es continua, se cumple que: \\(lim_{ n \\to\\infty}F_{X_{n}}(x) = F_{X}(x)\\) En este curso nosotros vamos a trabajar únicamente el caso univariado. Corolario Sea \\(\\{X_{i}\\}_{i=1}^{n}\\) una muestra de v.a.i.i.d. Definimos \\(M_{n}=máx\\{x_{i}\\} \\quad \\forall i\\) Entonces para cualquier distribución que tengan los \\(X_{i}&#39;s\\), si existe \\(a_{n}&gt;0\\) y \\(b_{n}\\in \\mathbb{R}\\), tales que: \\(\\lim_{x\\to\\infty}\\mathbb{P}\\left[\\frac{M_{n}-b_{n}}{a_{n}}\\leq z\\right]={G}(z)\\) Donde \\({\\color{tuftsblue}G}(z)\\) es una función de distribución (acumulada), llamando \\(M\\) a la v.a cuya función de distribución es \\({\\color{tuftsblue}G}\\), decimos entonces que: \\(\\frac{M_{n}-b_{n}}{a_{n}} \\quad \\xrightarrow{\\quad d \\quad} \\quad M\\) Entonces, en caso de encontrar dichas \\(a_{n}\\) y \\(b_{n}\\) donde \\(\\frac{M_{n}-b_{n}}{a_{n}}\\) tenga una convergencia en distribución a \\(M\\), entonces la función de distribución (acumulada) de \\(M\\) será \\(G\\), que basado en el teorema de Fisher-Tippett-Gnedenko, solo podrá tener una de las siguientes formas: Distribuciones de valores extremos \\(M \\sim Weibull(\\alpha, \\beta, \\lambda&gt;0)\\) \\[\\begin{equation*} \\label{Weibull} G(z) = \\left\\{ \\begin{array}{ll} exp\\left[ -\\left(- \\left( \\frac{z-\\beta}{\\alpha} \\right) \\right)^{\\lambda}\\right]&amp; \\mathrm{si\\ } z&lt; \\beta \\\\ 1 &amp; \\mathrm{si\\ }\\underbrace{ z \\geq \\beta}_{\\text{Soporte}} \\end{array} \\right. \\end{equation*}\\] \\(M \\sim Gumbel(\\alpha, \\beta)\\) \\[\\begin{eqnarray*} G(z) = exp \\left[-exp \\left(- \\left( \\frac{z-\\beta}{\\alpha} \\right) \\right)\\right] \\quad \\underbrace{ \\forall z\\in \\mathbb{R}}_{\\text{Soporte}} \\\\ \\end{eqnarray*}\\] \\(M \\sim Fréchet(\\alpha, \\beta, \\lambda&gt;0)\\) \\[\\begin{equation*} G(z) = \\begin{cases} 0 &amp; si\\ z\\leq \\beta \\\\ exp\\left[- \\left( \\frac{z-\\beta}{\\alpha} \\right)^{-\\lambda} \\right] &amp; si\\ \\underbrace{z &gt;\\beta}_{\\text{Soporte}} \\end{cases} \\end{equation*}\\] Observación: n es el tamaño de muestra \\(\\{{X_i}_{i=1}^{n}\\}\\). Si \\((\\{{X_i}_{i=1}^{n}\\})\\) son una muestra de v.a.i.i.d entonces la función de distribución de \\(M_{n}= máx\\{ X_{i}\\}\\quad \\forall i\\), será: \\[\\begin{eqnarray*} F_{M_{n}}(t) =\\mathbb{P}[M_{n} \\leq t]={P}[X_{1} \\leq t,X_{2} \\leq t,...,X_{n} \\leq t] &amp; \\overset{indep}{=}&amp; \\prod_{i=1}^{n}\\mathbb{P}[X_{i} \\leq t] &amp;\\overset{i.d}{=}&amp; \\mathbb{P}^{n}[X \\leq t] =F_{X}^{n}(t)\\\\ \\end{eqnarray*}\\] Por lo tanto \\(F_{M_{n}}(t)=F_{X}^{n}(t) \\quad \\forall t\\in \\mathbb{R}\\) Entonces: \\[\\begin{eqnarray*} \\mathbb{P}\\left[ \\frac{M_{n}-b_{n}}{a_{n}} \\leq z \\right]= \\mathbb{P}\\left[ M_{n}\\leq a_{n}z+ b_{n} \\leq z \\right]= F_{M_{n}}(a_{n}z+b_{n}) = F_{X}^{n}(a_{n}z+b_{n})\\\\ \\end{eqnarray*}\\] Por lo tanto: \\[\\begin{eqnarray*} \\mathbb{P}\\left[ \\frac{M_{n}-b_{n}}{a_{n}} \\leq z \\right]&amp;=&amp; F_{X}^{n}(a_{n}z+b_{n})\\\\ \\end{eqnarray*}\\] Noten que los limites a los que se llegan son de la forma \\(e^{x}\\), entonces es considerable aprender el siguiente limite: \\[\\begin{eqnarray*} \\displaystyle\\lim_{n} \\to \\infty\\left( 1+ \\frac{x}{{n} }\\right)^{{n} }=e^{x} \\quad \\quad \\forall x\\in \\mathbb{R} \\quad {\\text{($x$ NO depende de n)}}\\\\ \\end{eqnarray*}\\] Observen que el soporte de todas las distribuciones mencionadas son diferentes, por lo que observar detenidamente el soporte al calcular el limite puede ser una guía importante. Ejemplo 1 Sea \\(X \\sim exp(1)\\). \\[\\begin{eqnarray*} F_{X}(x) = (1-e^{-x}) \\mathbb{I}_{(x\\geq 0)} (x)\\\\ \\end{eqnarray*}\\] Entonces: \\[\\begin{eqnarray*} F_{M_{n}}(x) = F_{X}^{n}(x) = (1-e^{-x})^{n} \\mathbb{I}_{(x\\geq 0)} (x)\\\\ \\end{eqnarray*}\\] Ahora, considerando las constantes de normalización \\(a_{n}=1\\) y \\(b_{n}=ln(n)\\) entonces: \\[\\begin{eqnarray*} \\displaystyle\\lim_{x \\to \\infty}\\mathbb{P}\\left[ \\frac{M_{n}-b_{n}}{a_{n}}\\leq z \\right]&amp;=&amp;\\displaystyle\\lim_{x \\to \\infty} F_{X}^{n}(a_{n}z+b_{n})\\\\ &amp;=&amp; \\displaystyle\\lim_{x \\to \\infty} (1-e^{-(a_{n}z+b_{n})})^{n} \\mathbb{I}{((a{n}z+b_{n})\\geq 0)} (a_{n}z+b_{n})\\\\ &amp;=&amp; \\displaystyle\\lim_{x \\to \\infty} (1-e^{-(z+b_{n})})^{n} \\mathbb{I}\\underbrace{((z+b{n})\\geq 0)}_{\\text{Observación}} (z+b{n})\\\\ &amp;=&amp; \\displaystyle\\lim_{x \\to \\infty} (1-e^{-z} \\cdot e^{ln(1/n)})^{n} \\\\ &amp;=&amp; \\displaystyle\\lim_{x \\to \\infty} (1+\\frac{-e^{-z}}{n})^{n} \\\\ &amp;=&amp; exp\\{- e^{-z}\\} \\\\ \\end{eqnarray*}\\] Observación: \\[z+ ln(n) \\geq 0 \\Leftrightarrow z \\geq -ln(n) \\xrightarrow[\\quad n \\rightarrow \\infty \\quad]{} z \\geq -\\infty \\] \\[ \\therefore \\quad z \\in \\mathbb{R}\\] Lo que nos da como resultado: \\[ \\lim\\limits_{n \\to \\infty}\\mathbb{P} [ \\frac{\\mu_n - b_n}{a_n} \\leq z]= \\lim\\limits_{n \\to \\infty} ( 1 - e^{-(z + In (n))})^{n} \\mathbb{I}_{(z+In (n) \\geq 0)} (z+In(n)) = e^{-e^{-z}} , \\forall z \\in \\mathbb{R} \\] Gracias al soporte identificamos que \\(M \\sim {Gumbel}\\), luego buscamos sus parámetros, pero una vez ya identificada es fácil notar que si \\(\\alpha = 1, \\beta = 0\\): \\[\\begin{eqnarray*} \\rightarrow G(x) = exp {-exp {-[\\frac{x - \\beta }{\\alpha}]}} = e^{-e^{-[\\frac{x-0}{1}]}} = e^{-e^{-x}} , \\forall z \\in \\mathbb{R} \\end{eqnarray*}\\] CORREGIR \\[\\begin{eqnarray*} \\therefore\\frac{ M_n - b_n }{a_n} = M_n - ln(n) \\overset{d}{\\underset{n \\rightarrow \\infty}{\\longrightarrow}} M \\sim {Gumbel ( \\alpha = 1, \\beta = 0)} \\end{eqnarray*}\\] Ejemplo 2 Consideremos \\(X \\sim{ Unif (0, 1) }\\) \\(\\Longrightarrow\\) \\(F_{x} (x) = x\\) \\(\\overset{\\star}{\\mathbb{I}}_{(0,1)} (x)\\) \\[\\begin{equation*} \\label{ } \\overset{\\star}{\\mathbb{I}}_{(a,b)} (x) = \\left\\{ \\begin{array}{ll} si\\ x \\leq a \\Rightarrow\\ F_x(x) \\equiv 0 \\\\ si\\ x \\in\\ (a,b) \\Rightarrow\\ \\overset{\\star}{\\mathbb{I}}_{(a,b)} (x) = 1\\\\ si\\ x \\geq\\ b \\Rightarrow\\ F_x(x) \\equiv 1 \\end{array} \\right. \\end{equation*}\\] Tomando una muestra \\(\\{X_{i}\\}_{i=1}^{n}\\), entonces: \\({F_M}_n(t) = \\mathbb{P} [ M_n = \\underset{\\forall _i}{ máx }\\{ X_i\\} \\leq t ] = {F_x}^{n}(t)= t^{n} \\overset{\\star}{\\mathbb{I}}_{(0,1)} (t)\\) Pequeña observación: \\({F_M}_n (t)\\) = \\(t^{n} \\overset{\\star}{\\mathbb{I}}_{(0,1)} (t)\\) \\({F_M}_n (t)\\) = \\({f_M}_n\\) (t) = \\(n t^{n-1}\\) {\\(\\mathbb{I}_{(0,1)}(t)\\)} \\(\\dashrightarrow\\) Indicadora usual \\(\\Rightarrow\\) \\({f_M}_n(t) = nt^{n-1} \\mathbb{I}_{(0,1)}(t) = \\frac{\\Gamma(n-1)}{\\Gamma(n) \\Gamma(1)} t^{n-1} (1-t)^{1-1} \\mathbb{I}_{(0,1)}(t)\\) \\(\\therefore M_n = \\underset{\\forall _i}{ máx }\\{ X_i\\} \\sim{ Beta (n,1)}\\ ( si \\ x_i \\perp &#39; s\\ Unif (0,1)\\) \\(\\mathbb{E}\\)[\\(M_n\\)] = \\(\\frac{n}{n+1}\\); \\(\\mathbb{V}\\)ar(\\(M_n\\))= \\(\\frac{ n(1)}{(n+1+1)(n+1)^{2}}\\) = \\(\\frac{n}{(n+2) (n+1)^{2}}\\) Consideremos \\(b_n=1\\) y \\(a_n\\) = \\(\\frac{1}{n}\\), entonces: \\[\\begin{eqnarray*} \\displaystyle \\lim\\limits_{n \\to \\infty}\\mathbb{P} \\left[ \\frac{M_n - b_n}{a_n} \\leq t\\right] &amp;=&amp; \\lim\\limits_{n \\to \\infty} {F_M}_n (a_nt + b_n) \\\\ &amp;=&amp; \\displaystyle \\lim\\limits_{n \\to \\infty} {F_x}^{n} (a_nt + b_n) \\\\ &amp;=&amp; \\displaystyle\\lim\\limits_{n \\to \\infty} [a_nt + b_n]^{n} \\overset{\\star}{\\mathbb{I}}_{(0,1)} (a_nt + b_n) \\\\ &amp;=&amp; \\displaystyle\\lim\\limits_{n \\to \\infty}\\underbrace{\\left[\\frac{t}{n} + 1\\right]^{n}}_{\\substack{Atendiendo \\ el \\ límite}}\\underbrace{ \\overset{\\star}{\\mathbb{I}}_{(0,1)}\\left(\\frac{t}{n} + 1\\right)}_{\\substack{Atendiendo \\ la \\ indicadora}} \\\\ \\end{eqnarray*}\\] Observación: Atendiendo el límite \\(\\lim\\limits_{n \\to \\infty} ( 1 + \\frac{t}{n} ) ^{n} = e^{t}\\) Atendiendo la indicadora \\(0 \\leq 1 + \\frac{t}{n} \\leq 1 \\Leftrightarrow\\) \\(-1 \\leq \\frac{t}{n} \\leq 0 \\Leftrightarrow -n \\leq t \\leq 0\\) Cuando \\(n\\) \\(\\rightarrow \\infty\\) entonces: \\[t \\in (-\\infty , 0)\\] Por lo tanto: \\(\\lim\\limits_{n \\to \\infty}\\mathbb{P} [ \\frac{M_n - b_n}{a_n} \\leq t]\\)= \\(\\lim\\limits_{n \\to \\infty} ( 1 + \\frac{t}{n} )^{n} \\overset{\\star}{\\mathbb{I}}_{(0,1)}(1+\\frac{t}{n})\\) = \\(e^{t} \\overset{\\star}{\\mathbb{I}}_{(-\\infty , 0)}(t)\\) \\[\\begin{equation*} \\Rightarrow G(x) = \\begin{cases} e^{t} &amp; si\\ x &lt; 0 \\\\ 1 &amp; si\\ x \\geq 0 \\end{cases} \\rightarrow \\ M \\sim Weibull \\end{equation*}\\] Una vez más, gracias al soporte podemos identificar la distribución de valor extremo a la que converge en distribución \\(\\frac{M_n - b_n}{a_n}\\). Procedemos a buscar a cuál en específico. Recordemos que la f.d.a. de una Weibull es: \\[\\begin{equation*} G(z) = \\begin{cases} exp [ - ( - ( \\frac{z - \\beta }{ \\alpha }) )^{ \\lambda } ] &amp; si\\ z &lt; \\beta \\\\ 1 &amp; si\\ z \\geq \\beta \\end{cases} \\end{equation*}\\] Tomando \\(\\alpha = 1, \\beta = 0, \\lambda = 1\\): \\[\\begin{equation*} G(z) = \\begin{cases} exp [ - ( - ( z) ) ] = e^{z} &amp; si\\ z &lt; 0 \\\\ 1 &amp; si\\ z \\geq 0 \\end{cases} \\end{equation*}\\] \\(\\therefore \\frac{ M_n - b_n }{a_n} \\overset{d}{ \\longrightarrow } M\\ \\sim{ Weibull ( \\alpha = 1, \\beta = 0, \\lambda = 1) }\\) ¡Más aún! Tomando \\(G&#39;(z)\\) = \\(\\underbrace{g(z) = e^{z} \\mathbb{I}_{(-\\infty , 0)}(z)}_{\\substack{\\text{Función de densidad}\\\\\\text{de M}}}\\) \\[\\begin{eqnarray*} \\Rightarrow \\mathbb{E} [M] &amp;=&amp; \\int \\limits_{-\\infty}^{0} z e^{z} dz\\underset{\\underset{\\underset{u=-z}{ du=-dz}}{\\downarrow}}{=}\\int \\limits_{\\infty}^{0} (-u) e^{-u} (-du) = \\int \\limits_{\\infty}^{0} u e^{-u} du\\\\ &amp;=&amp; - \\int \\limits_{0}^{\\infty} u e^{-u} du = - \\int \\limits_{0}^{\\infty} u f_{Exp(1)} (u) du = -\\mathbb{E} [Exp(1)] = -1 \\end{eqnarray*}\\] \\[\\begin{eqnarray*} \\therefore \\mathbb{E} [M] = -1 \\end{eqnarray*}\\] La siguiente pregunta es ¿Estará ligado al valor anterior con la convergencia  que tiene \\(\\frac{ M_n - b_n }{a_n}\\)? Tomando: \\[\\begin{eqnarray*} \\mathbb{E} \\left[\\frac{M_n - b_n}{a_n}\\right] &amp;=&amp; \\frac{\\mathbb{E}[M_n] - b_n}{a_n} \\quad( \\text{pues $a_n$ y $b_n$ no son v.a.&#39;s)}\\\\ &amp;=&amp;\\frac{(\\frac{n}{n+1})-1}{\\frac{1}{n}}=n\\left[\\frac{n-n-1}{n+1}\\right]=-\\frac{n}{n+1}=-\\left(\\frac{n+1-1}{n+1}\\right)\\\\ &amp;=&amp;-\\left(1-\\frac{1}{n+1}\\right)=\\frac{1}{n+1}-1\\\\ &amp;\\therefore&amp; \\mathbb{E}\\left[\\frac{M_n-b_n}{a_n}\\right]=\\frac{1}{n+1}-1\\\\ \\text{Pero luego:}\\\\ &amp;\\lim\\limits_{n \\to \\infty}&amp;\\mathbb{E}\\left[\\frac{M_n-b_n}{a_n}\\right]=-1=\\mathbb{E}[M] \\end{eqnarray*}\\] Noten que no necesitábamos conocer la distribución de \\(M\\) para lograr obtener su esperanza. Queda como ejercicio para el lector calcular \\(Var(M)\\) y comprobar que \\[\\lim\\limits_{n \\to \\infty}Var(\\frac{\\mu_n - b_n}{a_n}) = Var(M)\\mbox{ en este caso}\\] 2.2 VaR &amp; T-VaR VaR El VaR es un valor utilizado para cuantificar el riesgo. En términos formales, el VaR mide la máxima pérdida esperada en un intervalo de tiempo determinado, bajo condiciones normales del mercado y bajo un nivel de confianza dado. Traducido a una forma sencilla y como se estará manejando desde el punto de vista de Teoría del Riesgo y la estadística, el VaR diremos que es un cuantil; dada una variable aleatoria \\(X\\) que mida el monto de pérdida de una compañía de seguros el VaR a cierto nivel de confianza \\(p\\) se define como: \\(VaR_{p}(X) := F_{X}^{-1}(p) = \\pi_{p}\\) \\(\\longleftrightarrow\\) \\(F_{X}(VaR_{p}(X))=p=F_{X}(\\pi_{p})\\) T-VaR El valor de la cola en riesgo (TVaR), es una medida de riesgo asociada con el valor más general en riesgo. Cuantifica el valor esperado de la pérdida dado que se ha producido un evento fuera de un nivel de probabilidad dado. Dada una variable aleatoria \\(X\\) que mide el monto de pérdida de una compañía de seguros y una cierta cantidad \\(\\pi_{p}\\) definimos el TVaR como: \\[TVaR_{p}(X):=\\mathbb E [X|X&gt;\\pi_{p}] = \\frac{\\int_{\\pi_{p}}^{\\infty} xf_{x}dx}{1-F(\\pi_{p})}\\] \\[TVaR_{p}(X) \\overset{P.D.}{=} \\pi_{p} + e(\\pi_{p}) = \\displaystyle\\frac{\\int_{\\pi_{p}}^{\\infty} xf_{x}dx}{1-F(\\pi_{p})}, con: e(\\pi_{p}) = \\frac{\\int_{\\pi_{p}}^{\\infty} (x-\\pi_{p})f_{x}(x) dx}{1-p}\\] Demostración. Tenemos que: \\[\\begin{eqnarray*} \\displaystyle\\pi_{p} + \\frac{\\int_{\\pi_{p}}^{\\infty} xf_{x}(x)dx - \\int_{\\pi_{p}}^{\\infty} \\pi_{p}f_{x}(x)dx } {1-p} &amp;=&amp; \\frac{\\pi_{p}(1-p-(1-p)) + \\int_{\\pi_{p}}^{\\infty} xf_{x}(x)dx} {1-p} \\\\ &amp;=&amp; \\displaystyle \\frac{\\int_{\\pi_{p}}^{\\infty} xf_{x}(x)dx}{1-p} \\\\ &amp;=&amp; \\displaystyle TVaR_{p}(X) \\\\ \\end{eqnarray*}\\] Queda como ejercicio para el lector que: \\[TVaR_{p}(X) = \\frac{\\int_{p}^{1} VaR_{u}(X)du}{1-p}\\] Aclaración: Sea \\(Y = X|X&gt;a\\) con \\(X\\) una v.a continua. Si \\(t&gt;a\\), entonces: \\[\\begin{eqnarray*} \\Rightarrow F_Y(t)\\ \\ddot{=}\\ \\mathbb{P}[Y \\leq t]=\\mathbb{P}[X\\leq t | X&gt;a]=\\frac{\\mathbb{P}[a&lt;X\\leq t]}{\\mathbb{P}[X&gt;a]}=\\frac{F_X(t)-F_X(a)}{S_X(a)}\\quad\\forall t\\geq a \\end{eqnarray*}\\] Obs: si \\(t \\leq a \\Rightarrow \\mathbb{P}[X\\leq t| X&gt;a]=0\\) \\[\\begin{eqnarray*} \\Rightarrow f_Y(t) =\\frac{d}{dt}F_Y(t)=\\frac{f_X(t)}{S_X(a)}\\qquad {\\therefore f_{X|X&gt;a}(t)=\\frac{f_X(t)}{S_X(a)}\\mathbb{I}_{t&gt;a}(t)} \\end{eqnarray*}\\] De tal manera que: \\[\\begin{eqnarray*} TVaR \\ \\ddot{=}\\ \\mathbb{E}[X|X&gt;\\pi_p]=\\int^{\\infty}_{\\pi_p}tf_{X|X&gt;\\pi_p}(t)dt=\\int^{\\infty}_{\\pi_p}t\\frac{f_X(t)}{S_X(\\pi_p)}dt=\\frac{\\int^{\\infty}_{\\pi_p}tf_X(t)dt}{S_X(\\pi_p)} \\end{eqnarray*}\\] De ahí obtenemos el cálculo para el TVaR. Como ya hemos visto, hay maneras alternativas para calcular este valor. Anteriormente se mostró que: \\[TVaR_p(X)=\\pi_p+\\frac{\\int^\\infty_{\\pi_p}f_X(x)dx}{1-p}\\] A partir de este último resultado veamos otro par de detalles. Recordemos lo siguiente: PROPOSICIÓN. (DESIGUALDAD DE MARKOV) Sea \\(X\\geq 0\\) una variable aleatoria con esperanza finita. para cualquier \\(\\varepsilon&gt;0\\),\\[P(X&gt;\\varepsilon)\\geq \\frac{E(X)}{\\varepsilon}\\] Demostración. \\[\\begin{eqnarray*} E(X)&amp;=&amp; E(X1_{(X\\geq \\varepsilon)}+X1_{(X&lt;\\varepsilon)}) &amp;\\geq&amp; E(X1_{(X\\geq \\varepsilon)}) &amp;\\geq&amp; E(\\varepsilon 1_{(X\\geq\\varepsilon)})\\\\ &amp;=&amp; \\varepsilon P(X\\geq\\varepsilon)\\blacksquare \\end{eqnarray*}\\] Dicho de otra manera, si \\(X\\) es continua con función de supervivencia \\(S_X(t)\\) entonces: \\[0\\leq tS_X(t)\\leq\\mathbb{E}[X]\\quad\\forall t\\geq 0\\] Entonces \\(\\lim\\limits_{t\\rightarrow\\infty} tS_X(t)\\) existe y es no negativo si \\(\\mathbb{E}[X]&lt;\\infty\\) Más aún: pues \\(t\\leq \\underset{\\downarrow}{x}\\leq\\infty\\) \\[0\\leq\\lim\\limits_{t\\rightarrow\\infty} tS_X(t)=\\lim\\limits_{t\\rightarrow\\infty} t\\int^\\infty_tf_X(x)dx=\\lim\\limits_{t\\rightarrow\\infty} \\int^\\infty_t tf_X(x)dx\\leq\\lim\\limits_{t\\rightarrow\\infty} \\int^\\infty_t xf_X(x)dx=0\\] \\(0\\leq\\int^\\infty_0xf_X(x)dx=\\mathbb{E}[X]&lt;\\infty\\) e integrar asi la reduce\\(\\quad\\hookleftarrow\\) \\(\\therefore\\lim\\limits_{t\\rightarrow 0}tS_X(t)=0 \\quad\\text{si}\\quad X\\geq 0\\quad\\text{y}\\quad \\mathbb{E}[X]&lt;\\infty\\) Una identidad interesante a notar es, dados los supuestos anteriores: \\(\\int^\\infty_{\\pi_p}(x-\\pi_p)f_X(x)dx=\\int^\\infty_{\\pi_p}S_X(x)dx\\) Demostración. \\[\\begin{eqnarray*} \\underbrace{\\int^b_{\\pi_p}(x-\\pi_p)f_X(x)dx}_{\\substack{u=(x-\\pi_p)\\Rightarrow du=dx\\\\dv=f_X(x)dx\\Rightarrow v=F_X(x)}}&amp;=&amp;(x-\\pi_p)F_X(x)|^b{\\pi_p}-\\int^b_{\\pi_p}F_X(x)dx=(b-\\pi_p)F_X(b)-\\int^b_{\\pi_p}(1-S_X(x)dx)\\\\ &amp;=&amp;(b-\\pi_p)F_X(b)-(b-\\pi_p)+\\int^b_{\\pi_p} S_X(x)dx\\\\ &amp;=&amp;(b-\\pi_p)(F_X(b)-1)+\\int^b_{\\pi_p} S_X(x)dx=(\\pi_p-b)S_X(b)+\\int^b_{\\pi_p} S_X(x)dx\\\\ &amp;=&amp;\\pi_p S(b)-bS_X(b)+\\int^b_{\\pi_p}S_X(x)dx \\end{eqnarray*}\\] \\[\\therefore\\lim\\limits_{b\\rightarrow\\infty}\\int^b_{\\pi_p}(x-\\pi_p)f_X(x)dx=\\lim\\limits_{b\\rightarrow\\infty}\\int^b_{\\pi_p}S_X(x)dx\\blacksquare\\] Habiendo probado esto, se deduce que si \\(X\\) es v.a no-negativa con esperanza finita, entonces: \\(TVaR_p(X)=\\pi_p+\\frac{\\int^\\infty_{\\pi_p}S_X(t)dt}{1-p}\\) Observación: \\(\\phi(t)\\ \\ddot{=}\\ \\) función de densidad de una normal estándar (evaluada en t). \\(\\Phi(t)\\ \\ddot{=}\\ \\) función de distribución de una normal estándar (evaluada en t). La notación \\(VaR_p(X)\\) puede cambiar por \\(VaR_p\\) si ya se entiende sobre qué se calcula. Igual para \\(TVaR_p\\) ¿De dónde sale la tabla anterior? Ejemplo 1: \\(X\\sim Exp(\\lambda)\\) obtengamos \\(VaR_p(X)\\) Sea \\(VaR_p(X)=\\pi_p\\) entonces: \\[\\begin{eqnarray*} \\mathbb{P}[X\\leq\\pi_p]&amp;=&amp;p=1-e^{\\lambda\\pi_p}\\\\ &amp;\\Leftrightarrow&amp; e^{-\\lambda\\pi_p}=1-p \\Leftrightarrow \\lambda\\pi_p=-ln(1-p)\\\\ &amp;\\Leftrightarrow&amp; \\pi_p=-\\frac{ln(1-p)}{\\lambda}=VaR_p\\qquad \\text{Lo que teníamos:}-\\frac{ln(1-p)}{\\lambda} \\end{eqnarray*}\\] Obtengamos \\(TVaR_p(x)\\) Primero: \\[\\begin{eqnarray*} \\int^\\infty_{\\pi_p}S_X(x)dx&amp;=&amp;\\int^\\infty_{\\pi_p}e^{-\\lambda x} dx=\\frac{1}{\\lambda}\\int^\\infty_{\\pi_p}\\lambda e^{-\\lambda x}dx\\\\ &amp;=&amp;\\frac{1}{\\lambda}\\int^\\infty_{\\pi_p}f_X(x)dx=\\frac{1}{\\lambda}S_X(\\pi p)\\\\ &amp;=&amp;\\frac{e^{-\\lambda\\pi_p}}{\\lambda}\\\\ \\Rightarrow TVaR_p&amp;=&amp;\\pi_p+\\frac{\\int^\\infty_{\\pi_p}S_X(x)dx}{S_X(\\pi_p)}=-\\frac{ln(1-p)}{\\lambda}+\\frac{\\frac{{e^{-\\lambda(\\pi_p)}}}{\\lambda}}{{e^{-\\lambda(\\pi_p)}}}\\\\ &amp;=&amp;\\underbrace{-\\frac{ln(1-p)}{\\lambda}}+\\underbrace{\\frac{1}{\\lambda}}=\\frac{1-ln(1-p)}{\\lambda}\\\\ \\mathbb{E}[X|X&gt;\\pi_p]&amp;=&amp;\\ \\pi_p\\ +\\mathbb{E}[X] \\end{eqnarray*}\\] Pérdida de memoria de la distribución exponencial. Ejemplo 2: Sea \\(X\\sim Pareto1(\\alpha,\\theta)\\) btengamos \\(VaR_p(x)\\) \\[\\begin{eqnarray*} F_X(x)&amp;=&amp; 1-\\left(\\frac{\\theta}{x}\\right)^\\alpha\\\\ &amp;\\Rightarrow&amp; F_X(\\pi_p)\\ \\ddot{=}\\ \\mathbb{P}[X\\leq\\pi_p]=p=1\\left(\\frac{\\theta}{\\pi_p}\\right)^\\alpha\\\\ &amp;\\Leftrightarrow&amp;\\left(\\frac{\\theta}{\\pi_p}\\right)^\\alpha\\Leftrightarrow\\frac{\\theta}{\\pi_p}=(1-p)^{-\\frac{1}{\\alpha}}\\\\ &amp;\\Leftrightarrow&amp;\\pi_p=\\frac{\\theta}{(1-p)^{\\frac{1}{\\alpha}}}=\\theta(1-p)^{-\\frac{1}{\\alpha}} \\end{eqnarray*}\\] Queda como ejercicio para el lector obtener \\(VaR_p\\) de una v.a \\(X\\sim log-Normal(\\mu,\\sigma^2)\\). Hint: \\(Y\\sim N(\\mu,\\sigma^2)\\Leftrightarrow X=e^Y\\sim log-Normal(\\mu,\\sigma^2)\\) De tal manera que: \\[F_X(x)=F_Y(ln(x))=\\Phi\\left(\\frac{ln(x)-\\mu}{\\sigma^2}\\right)\\] Script: ‘’Valores extremos y VaR’’. "],["frecuencia.html", "Capítulo 3 Frecuencia 3.1 Frecuencia", " Capítulo 3 Frecuencia 3.1 Frecuencia Hasta el momento estuvimos hablando principalmente de variables aleatorias continuas, esto con la finalidad de modelar algo que nosotros llamamos “severidad”. La severidad no es estrictamente continua (puede ser discreta o incluso una v.a. mixta) pero hay una parte de la teoría del riesgo que sí debe ser discreta, la frecuencia. En esta parte vamos a conocer las variables aleatorias más usuales que se utilizan para modelar fenómenos discretos, así como propiedades importantes que nos ayudarán a facilitar cálculos y expandir la forma en que podemos modelar un riesgo. Resulta ser, que si una variable aleatoria pertenece a un grupo conocido como familia/clase (a,b,i) es entonces discreta, alguna de las siguientes distribuciones y cuentan con una propiedad de recursividad. 3.1.1 Familia (a,b,0) Las siguientes distribuciones son las pertenecientes a la Familia/Clase (a,b,0), cuando hablemos de ellas, vamos a considerar las siguientes parametrizaciones: \\(X\\sim Binomial(n,p)\\Rightarrow f_X(x)=\\binom{n}{x}p^x(1-p)^{n-x} \\hspace{.4em}x\\in \\{0,1,...,n\\}, n\\in\\mathbb{N}-\\{0\\},p\\in[0,1]\\) \\(X\\sim Geométrica(p)\\Rightarrow f_X(x)=p(1-p)^x \\quad x\\in\\mathbb{N},p\\in[0,1]\\) \\(X\\sim Poisson(\\lambda)\\Rightarrow f_X(x)=e^{-\\lambda}\\frac{\\lambda^x}{x!} \\quad x\\in\\mathbb{N},\\lambda&gt;0\\) \\(X\\sim BinNeg(r,p)\\Rightarrow f_X(x)=\\binom{r+x-1}{x}p^r(1-p)^x \\quad x\\in\\mathbb{N},r\\geq 1,p\\in[0,1]\\) Sea \\(p_k:=\\mathbb{P}[X=k]\\). Resulta ser que las distribuciones anteriores se pueden escribir de manera recursiva bajo la siguiente regla: \\(p_k = p_{k-1}(a+\\frac{b}{k})\\) Con base en la regla anterior, conociendo inicialmente nuestra distribución, y resolviendo por un sistema de ecuaciones, podríamos determinar los valores de a y b para las distribuciones anteriores. Lo cuál nos lleva al siguiente cuadro: Notemos que si conocemos información mínima de este cuadro para alguna variable aleatoria, podemos determinar por completo de qué distribución se está hablando. Importante. La recursión anterior, también funciona para lo que diremos a continuación. Caso cero truncado. Aquí vamos a asumir que \\(p^T_0=0\\) y haciendo ésto, debemos modificar nuestra función de masa de probabilidad y lo haremos de la siguiente forma: \\(P^T_k=\\frac{P_k}{1-P_0}\\quad\\forall k\\neq0\\) Caso cero modificado. Aquí vamos a modificar la probabilidad original en cero y la reemplazaremos por algún otro valor cualquiera \\(p^M_0\\in(0,1)\\) y haciendo ésto, debemos modificar nuestra función de masa de probabilidad y lo haremos de la siguiente forma: \\(P^M_k=\\frac{1-P^M_0}{1-P_0}P_k\\quad\\forall k\\neq0\\) Estas dos últimas son la familia/clase (a,b,1). Recordando un poco de las distribuciones: Distribución Poisson \\(X\\sim Poisson(\\lambda) \\quad\\text{con}\\quad \\lambda&gt;0\\). \\(f(x)=e^{-\\lambda}\\frac{\\lambda^x}{x!}\\quad\\text{para}\\quad x=0,1,...\\) \\(\\mathbb{E}(X)=\\lambda\\). \\(Var(X)=\\lambda\\). \\(G(t)=e^{-\\lambda(1-t)}\\). \\(M(t)=exp[\\lambda(e^t-1)]\\). La suma de dos variables independientes con distribución Poisson(\\(\\lambda_1\\)) y Poisson(\\(\\lambda_2\\)) tiene distribución Poisson(\\(\\lambda_1+\\lambda_2\\)). Nota: \\(Var(X)=\\mathbb{E}[X]\\). https://youtu.be/y_dOx8FhHpQ Distribución Binomial \\(X\\sim Bin(n,p) \\quad\\text{con}\\quad n\\in\\mathbb{N}\\hspace{0.4em}\\text{y}\\hspace{0.4em} p\\in(0,1)\\). \\(f(x)=\\binom{n}{x}p^x(1-p)^{n-x}\\quad\\text{para}\\quad x=0,1,...,n\\). \\(\\mathbb{E}(X)=np.\\) \\(Var(X)=np(1-p)\\). \\(G(t)=(1-p+pt)^n\\). \\(M(t)=[1-p+pe^t]^n\\). Una variable aleatoria binomial registra el número de éxitos en \\(n\\) ensayos independientes Bernoulli en donde en cada ensayo la probabilidad de éxito es \\(p\\). La suma de dos variables independientes con distribución \\(Bin(n,p)\\) y \\(Bin(m,p)\\) tiene distribución \\(Bin(n+m,p)\\). Nota: \\(\\mathbb{E}[X]&gt;Var(X)\\). https://youtu.be/Tf08fZWbyV8 Distribución Binomial Negativa \\(X\\sim BinNeg(r,p) \\quad\\text{con}\\quad r\\in\\mathbb{N}\\hspace{0.4em}\\text{y}\\hspace{0.4em}\\in(0,1)\\). \\(f(x)=\\binom{r+x-1}{x}p^r(1-p)^x\\quad\\text{para}\\quad x=0,1,...\\) \\(\\mathbb{E}(X)=\\frac{r(1-p)}{p}\\) \\(Var(X)=\\frac{r(1-p)}{p^2}\\). \\(G(t)=[\\frac{p}{(1-t(1-p))}]^r\\). \\(M(t)=[\\frac{p}{(1-qe^t)}]^r\\). Este es el modelo que se usa para contar el número de fracasos antes de obtener el r-ésimo éxito en una sucesión de ensayos independientes Bernoulli, en donde en cada ensayo la probabilidad de éxito es \\(p\\). La distribución Binomial Negativa se reduce a la distribución geo métrica cuando \\(r=1\\). Nota: \\(\\mathbb{E}[X]&lt;Var(X)\\). https://youtu.be/l5uUzzUuZH4 Observe que bajo el supuesto de clase (a,b,0), teniendo los valores de la esperanza y varianza se puede deducir la distribución. Existen diferentes parametrizaciones de las distribuciones anteriores, pero cuando nosotros hablemos de ellas, haremos referencia a las indicadas en esta sección salvo que se especifique lo contrario. En el caso de la distribución binomial negativa hay una variante importante a considerar. Tomando \\(X\\sim Bin Neg(r,p)\\) como se muestra en las distribuciones anteriores, \\(X\\) mide el número de fracasos antes del r-ésimo éxito. Siendo este el caso, \\(X\\) podría modelar problemas del estilo: Número de prendas que descartaste antes de elegir ``r’’. Número de veces que perdiste en un videojuego antes de ganar. Número de parejas tóxicas antes de tu \\(2^{da}\\) relación sana. Y tomando en cuenta la modificación \\(N=X+r\\), entonces la función de masa de probabilidad (f.m.p.) es: \\(\\mathbb{P}[N=n]=\\mathbb{P}[X+r=n]=\\mathbb{P}[X=n-r]=\\binom{n-1}{n-r}p^r(1-p)^{n-r}\\mathbb{I}_{\\mathbb{N}\\cup\\{0\\}}(n)\\) Esta es también llamada binomial negativa y cuenta el número total de ensayos: Número de prendas que viste en total antes de elegir ``r’’. Número de veces que jugaste un videojuego antes de ganarlo. Número de parejas que tuviste antes de tu \\(2^{da}\\) relación sana. Por su naturaleza, podemos ver que tomando la recursión de clase (a,b,i) y haciendo un ajuste: \\(P_k=P_{k-1}\\left(a+\\frac{b}{k}\\right)\\Leftrightarrow k\\left(\\frac{P_k}{P{k-1}}\\right)=ak+b\\hspace{0.4em}\\ddot{=}\\hspace{0.4em}f(k)\\) Obtenemos una ecuación de una línea recta \\((ak+b)\\), esto gráficamente muestra lo siguiente: \\(f(k)=b\\quad\\text{(constante)}\\quad\\text{donde}\\quad a=0\\quad ; \\quad b&gt;0\\) \\(f(k)=ak+b\\quad \\text{donde}\\quad a&lt;0\\quad ; \\quad b&gt;0\\) \\(f(k)=ak+b\\quad \\text{donde}\\quad a\\in(0,1)\\quad ; \\quad b\\leq0\\) Observación: Si \\(P_{0}^{m}=0\\) entonces tomamos el caso de cero-truncado. En páginas anteriores se afirma que la recursión de la clase \\((a,b,0)\\) es válida para la clase \\((a,b,1)\\). Vamos a demostrar esto para el caso cero-modificado, ya que esto generaliza el caso cero-truncado. Proposición: Cero modificado Sea \\(P_{0}^{M} \\in (0,1)\\). \\[\\begin{eqnarray*} P_{k}^{M}&amp;=&amp;\\frac{1-P_{0}^{M}}{1-P_{0}} P_{k} \\quad \\forall k \\neq 0\\\\ \\end{eqnarray*}\\] \\[\\begin{eqnarray*} &amp;\\text{P.D.}&amp; \\quad P_{k}^{M}=P_{k-1}^{M}\\left( a + \\frac{b}{k} \\right) \\quad \\forall k \\in \\mathbb{N}\\backslash \\{ 0,1\\} \\\\ &amp;\\text{P.D.}&amp; \\quad \\displaystyle\\sum_{i=0}^{\\infty} P_{i}^{M}=1 \\quad y \\quad P_{i}^{M} \\in[0,1] \\quad \\forall i \\end{eqnarray*}\\] Demostración. \\[\\text{P.D.} \\quad P_{k}^{M}=P_{k-1}^{M}\\left( a + \\frac{b}{k} \\right) \\] \\[\\begin{eqnarray*} P_{k}^{M}&amp;=&amp;\\frac{1-P_{0}^{M}}{1-P_{0}} P_{k}\\\\ &amp;\\overset{\\mathrm{k&gt;1}}{=}&amp; \\frac{1-P_{0}^{M}}{1-P_{0}} P_{k-1}\\left( a + \\frac{b}{k} \\right) \\\\ &amp;=&amp; \\left[ \\frac{1-P_{0}^{M}}{1-P_{0}} P_{k-1} \\right] \\left( a + \\frac{b}{k} \\right)\\\\ &amp;=&amp; P_{k-1}^{M}\\left( a + \\frac{b}{k} \\right) \\end{eqnarray*}\\] Por lo tanto: \\[\\begin{eqnarray*} P_{k}^{M}&amp;=&amp;P_{k-1}^{M}\\left( a + \\frac{b}{k} \\right) \\quad \\forall k \\in \\mathbb{N}\\backslash \\{0,1\\}\\blacksquare\\\\ \\end{eqnarray*}\\] Surge la siguiente incógnita: ¿Será el conjunto de probabilidades modificadas, una función de masa de probabilidad (f.m.p)? \\[\\begin{eqnarray*} \\text{P.D.} \\quad \\displaystyle\\sum_{i=0}^{\\infty} P_{i}^{M}&amp;=&amp;1 \\end{eqnarray*}\\] Demostración. \\[\\begin{eqnarray*} \\sum_{i=0}^{\\infty} P_{i}^{M} &amp;=&amp; P_{0}^{M}+ \\sum_{i=1}^{\\infty}P_{i}^{M}\\\\ &amp;=&amp; P_{0}^{M}+\\sum_{i=1}^{\\infty}\\left( \\frac{1-P_{0}^{M}}{1-P_{0}} P_{i} \\right)\\\\ &amp;=&amp; P_{0}^{M}+\\left(\\frac{1-P_{0}^{M}}{1-P_{0}} (1-P_{0}) \\right)\\\\ &amp;=&amp; P_{0}^{M}+1-P_{0}^{M}\\\\ &amp;=&amp; 1\\blacksquare \\end{eqnarray*}\\] Demostración. \\[\\begin{eqnarray*} P.D \\quad P_{i}^{M} \\in [0,1] \\quad \\forall i \\end{eqnarray*}\\] Tenemos que, \\(P_{0}^{M} \\in [0,1]\\) por definición del modelo. Entonces: \\[\\begin{eqnarray*} 1-P_{0}^{M} \\in [0,1]\\\\ \\end{eqnarray*}\\] Luego, \\(P_{i} \\in [0,1]\\) , ya que viene de una de las variables aleatorias que ya conocemos. De este modo: \\[\\begin{eqnarray*} 1-P_{i} \\in [0,1] \\forall i \\\\ \\end{eqnarray*}\\] Entonces: \\[\\begin{eqnarray*} P_{k}^{M}&amp;=&amp;\\frac{1-P_{0}^{M}}{1-P_{0}} P_{k} \\geq 0 \\quad \\forall k \\in \\mathbb{N}\\backslash \\{ 0\\}\\\\ \\end{eqnarray*}\\] Además, por la demostración anterior: \\(\\sum_{i=0}^{\\infty} P_{i}^{M}=1\\), es imposible que \\(P_{i} &gt;1\\), debido a que todos son no-negativos y en total suman 1. Por lo tanto: \\[\\begin{eqnarray*} P_{i}^{M} \\in [0,1] \\forall i\\blacksquare \\end{eqnarray*}\\] ¿Qué finalidad tiene modificar una variable aleatoria de clase \\((a,b,0)\\) a una de clase \\((a,b,1)\\)? Noten que en concreto, lo que se modifica en la clase \\((a,b,1)\\), es la probabilidad en cero; esa es la que nosotros podemos manipular a nuestro antojo. Basándonos en el fenómeno que estamos modelando, lo que nosotros buscamos ahí, es alterar la probabilidad de observar un siniestro. Lo que sucede fuera del cero es simplemente una compensación a la modificación que nosotros hicimos, conservando la forma fuera del cero que tiene la distribución por naturaleza. Ejemplo 1. Si N pertenece a la familia \\((a=0, b=8)\\). Encuentra: \\(\\mathbb{P}[N=2]\\) y \\(M_{N}(t)\\). Solución: Como \\(a=0\\); \\(b&gt;0\\). Entonces \\(N \\sim P_{oi}(\\lambda=b=8)\\). Por lo que: \\[\\begin{eqnarray*} f_{N}(n)&amp;=&amp; \\mathbb{P}[N=n]\\\\ &amp;=&amp; e^{-8}\\left( \\frac{8^{n}}{n!} \\right) \\mathbb{I}_{\\mathbb{N} \\bigcup \\{0\\}} \\quad (n)\\\\ \\end{eqnarray*}\\] Entonces: \\[\\begin{eqnarray*} f_{N}(2)&amp;=&amp; e^{-8}\\left( \\frac{8^{2}}{2!} \\right)\\\\ &amp;\\approx &amp; 0.0107348 \\end{eqnarray*}\\] Por otro lado: \\[\\begin{eqnarray*} M_{N}(t)&amp;=&amp; e^{\\lambda(e^{t}-1)}\\\\ &amp;=&amp; 0.0107348 \\end{eqnarray*}\\] Ejemplo 2. Sabemos que N es de la familia \\((a,b,0)\\) y \\(P_{0}=e^{-1.5}\\), \\(P_{1}=1.5e^{-1.5}\\), \\(P_{2}=\\frac{9}{8}e^{-1.5}\\). Encontrar \\(\\mathbb{E}[N^{2}]\\) Solución: Recordemos que al ser familia \\((a,b,0)\\), entonces: \\[\\begin{eqnarray*} \\frac{P_k}{P_{k-1}}&amp;=&amp; a+ \\frac{b}{k} \\quad \\forall k \\in \\mathbb{N}\\backslash \\{ 0\\}\\\\ \\end{eqnarray*}\\] Lo cual, nos da el siguiente sistema de ecuaciones: \\[\\begin{equation*} \\left \\{ \\begin{matrix} \\displaystyle\\frac{P_1}{P_0}=\\displaystyle\\frac{3}{2}=a+b\\\\ \\\\\\displaystyle\\frac{P_2}{P_1}=\\displaystyle\\frac{3}{4}=a+\\displaystyle\\frac{b}{2} \\\\ \\end{matrix}\\right. \\end{equation*}\\] Resolviendo el sistema de ecuaciones, obtenemos: \\(a=0\\) y \\(b=3/2\\). \\(\\therefore\\) N es de clase/familia \\((a=0, b=3/2&gt;0,0)\\). Entonces \\(N \\sim P_{oi}(\\lambda=3/2=1.5=b)\\). De este modo \\[\\begin{eqnarray*} \\mathbb{E}[N^{2}]&amp;=&amp; Var(N)+\\mathbb{E}^{2}[N]\\\\ &amp;=&amp; \\lambda + \\lambda^{2}\\\\ &amp;=&amp; 3.75\\\\ \\end{eqnarray*}\\] Por lo tanto: \\[\\begin{eqnarray*} \\mathbb{E}[N^{2}]&amp;=&amp;3.75\\\\ \\end{eqnarray*}\\] Ejemplo 3. Consideremos \\(N \\sim P_{oi}\\)(2.1), encuentre, \\(P_{1}, P_{2}, P_{3}\\) para los casos: cero truncado y cero modificado con \\(P_{0}^{M}=0.6\\). Solución: Recordemos que: \\[\\begin{eqnarray*} P_{k}^{T}&amp;=&amp; \\frac{P_{k}}{1-P_{0}}\\\\ P_{k}^{M}&amp;=&amp; \\frac{1-P_{0}^{M}}{1-P_{0}}P_{k} \\quad \\forall k \\in \\mathbb{N} \\backslash \\{ 0\\} \\end{eqnarray*}\\] \\(P_{k} \\ddot{=} \\mathbb P [N=k] = f_{N}(k) = e^{\\text{2.1}}(\\frac{\\text{-2.1}^{n}}{n!})\\) \\(\\mathbb I_{\\mathbb N \\cup \\{0\\}}^{(n)}\\) La recursión es válida incluso para la clase \\((a,b,1)\\). \\(\\Rightarrow P_{k}^{M} = P_{k-1}^{M} (a+\\frac{b}{k}) = \\frac{1-P_{0}^{M}}{P_{0}}P_{k} \\forall k\\in\\mathbb{N}\\backslash\\{0,1\\}\\) Caso cero truncado \\[\\begin{eqnarray*} P_{1}^{T} &amp;=&amp;\\underbrace{\\frac{e^{-2.1}(2.1)}{1-e^{-2.1}}}_{\\substack{\\frac{P_1}{1-P_0}=\\frac{1-P_0^T}{1-P_0}P_1}}\\approx 0.293043568\\\\ P_2^T&amp;=&amp;\\underbrace{\\frac{e^{-2.1}(2.1)}{1-e^{-2.1}}\\left(0+\\frac{2.1}{2}\\right)}_{\\substack{P_1^T\\left(a+\\frac{b}{2}\\right)\\\\\\text{(recursión)}}}=\\underbrace{\\frac{1-0}{1-e^{-2.1}}\\left[e^{-2.1}\\left(\\frac{2.1^2}{2!}\\right)\\right]}_{\\substack{\\frac{1-P_0^T}{1-P_0}(P_2)\\\\\\text{(identidad)}}}\\approx 0.3076957464\\\\ P_3^T&amp;=&amp;P_2^T\\left(0+\\frac{b}{3}\\right)\\approx 0.215387 \\end{eqnarray*}\\] Caso cero truncado \\[\\begin{eqnarray*} P_{0}^{M} &amp;=&amp; 0.6\\mbox{ entonces:}\\\\ P_{1}^{M} &amp;=&amp;\\frac{1-P_{0}^{M}}{1-P_{0}}P_{1} = \\frac{1-0.6}{1-e^{-2.1}}(2.1)e^{-2.1} \\approx 0.117217\\\\ P_{2}^{M} &amp;=&amp; P_{1}^{M}\\left(a+\\frac{b}{2}\\right) \\approx 0.123078\\\\ P_{3}^{M} &amp;=&amp; P_{2}^{M}\\left(a+\\frac{b}{3}\\right) \\approx 0.086154 \\end{eqnarray*}\\] Todo es muy lindo hasta aquí pero… ¿Qué sucedería si buscamos obtener momentos utilizando las probabilidades modificadas? Buscamos la mantera de encontrar la función generadora de momentos de una \\(N^{*}\\) de clase \\((a,b,1)\\) en términos de su correspondiente \\(N\\) original de clase \\((a,b,0)\\). Entonces, recordemos que \\(\\mathbb P[N^{*} = 0] \\ddot{=} P_{0}^{M}\\) definida por nosotros. Usando la notación: \\[\\begin{eqnarray*} \\mathbb P[N^{*} = k] &amp;\\ddot{=}&amp; P_{k}^{M} \\mbox{ &amp; } \\mathbb P[N = k] \\ddot{=} P_{k}, \\mbox{ así }:\\\\ P_{k}^{M} &amp;=&amp; \\frac{1-P_{0}^{M}}{1-P_{k}}P_{k} \\forall k\\neq 0\\\\ \\end{eqnarray*}\\] Luego, se tiene que: \\[\\begin{eqnarray*} \\displaystyle M_{N^{*}}(t) = \\mathbb E[e^{N^{*}t}] = \\sum_{k=0}^{\\infty}P_{k}^{M}e^{tk} &amp;=&amp; P_{0}^{M} +\\sum_{k=1}^{\\infty} P_{k}^{M}e^{tk}\\\\ &amp;=&amp; \\displaystyle P_{0}^{M} + \\sum_{k=1}^{\\infty} \\left(\\frac{1-P_{0}^{M}}{1-P_{0}}\\right) P_{k}e^{tk}\\\\ &amp;=&amp; \\displaystyle P_{0}^{M} + \\left(\\frac{1-P_{0}^{M}}{1-P_{0}}\\right) \\sum_{k=1}^{\\infty} P_{k}e^{tk}\\\\ &amp;=&amp; \\displaystyle P_{0}^{M} + \\left(\\frac{1-P_{0}^{M}}{1-P_{0}}\\right) \\left[\\sum_{k=0}^{\\infty} P_{k}e^{tk} - P_{0}{e^0}\\hspace{0.7em} \\right]\\\\ &amp;=&amp; \\displaystyle P_{0}^{M} + \\left(\\frac{1-P_{0}^{M}}{1-P_{0}}\\right) [M_{N}(t) - P_{0}]\\\\ &amp;=&amp; \\displaystyle P_{0}^{M} + \\left(\\frac{1-P_{0}^{M}}{1-P_{0}}\\right) [M_{N}(t)-1+1 - P_{0}]\\\\ &amp;=&amp; \\displaystyle P_{0}^{M} +\\left[\\frac{(1-P_{0}^{M})(M_{N}(t)-1)}{1-P_{0}} +1 - P_{0}^{M}\\right]\\\\ &amp;=&amp; \\displaystyle 1 -\\left(\\frac{1-P_{0}^{M}}{1-P_{0}}\\right) (1-M_{N}(t))\\\\ \\end{eqnarray*}\\] \\(M_{N^{*}}(t) = 1 -(\\frac{1-P_{0}^{M}}{1-P_{0}}) (1-M_{N}(t))\\) Recordemos que en general la generadora de probabilidades de una variable aleatoria \\(X\\) se define como: \\[G_{X}(t) \\hspace{0.4em}\\ddot{=}\\hspace{0.4em} \\mathbb E[t^{X}]\\] \\[\\begin{eqnarray*} \\mbox{Además }M_{X}(ln(t)) \\ddot{=} \\mathbb E [e^{ln(t)X}] = \\mathbb E [e^{ln(t^{X})}]=\\mathbb E[t^{X}] \\ddot{=} G_{X}^{(t)}\\\\ \\end{eqnarray*}\\] \\[\\begin{eqnarray*} \\Rightarrow \\underline{G_{N^*}}= M_{N^{*}}(ln(t)) = 1-\\left(\\frac{1-P_{0}^{M}}{1-P_{0}}\\right)[1-M_{N}(ln(t))]\\\\ &amp;=&amp; \\underline{1-\\left(\\frac{1-P_{0}^{M}}{1-P_{0}}\\right)[1-G_{N}(t)]} \\end{eqnarray*}\\] Por lo tanto, la generadora de momentos y la generadora de probabilidad de \\(N^{*}\\) de clase \\((a,b,1)\\) en términos de su original \\(N\\) de clase \\((a,b,0)\\) son: Generadora de momentos: \\(M_{N^{*}}(t) = 1 -(\\frac{1-P_{0}^{M}}{1-P_{0}}) (1-M_{N}(t))\\) Generadora de probabilidad: \\(G_{N^{*}} = 1-(\\frac{1-P_{0}^{M}}{1-P_{0}})[1-G_{N}(t)]\\) Esto da como resultado un último lema y corolario: Lema \\[\\begin{eqnarray*} \\frac{\\partial^{k}}{\\partial t^{k}} M_{N^{*}}(t) \\doteq M_{N^{*}}^{(k)}(t) = (\\frac{1-P_{0}^{M}}{1-P_{0}}) M_{N}^{(k)}(t) \\doteq (\\frac{1-P_{0}^{M}}{1-P_{0}}) \\frac{\\partial^{k}}{\\partial t^{k}} M_{N}(t) \\end{eqnarray*}\\] Demostración. (Inducción) \\(n=1\\) (Base de inducción) \\[\\begin{eqnarray*} \\displaystyle M_{N^{*}}^{(1)}(t) &amp;=&amp; \\frac{\\partial}{\\partial t} \\left[1 - \\left(\\frac{1-P_{0}^{M}}{1-P_{0}}\\right) (1 - M_{N}(t))\\right]\\\\ &amp;=&amp; \\displaystyle \\frac{\\partial}{\\partial t} \\left[- \\left(\\frac{1-P_{0}^{M}}{1-P_{0}}\\right) + \\left(\\frac{1-P_{0}^{M}}{1-P_{0}}\\right) M_{N}(t)\\right] \\\\ &amp;=&amp; \\displaystyle \\left(\\frac{1-P_{0}^{M}}{1-P_{0}}\\right) M_{N}^{(1)}(t) \\\\ \\end{eqnarray*}\\] Supongamos válido para \\(k-1\\) (Hipotesis de inducción) \\[M_{N^{*}}^{(k-1)}(t) = \\left(\\frac{1-P_{0}^{M}}{1-P_{0}}\\right) M_{N}^{(k-1)}(t)\\] - P.D. Válido para \\(k\\) (Paso inductivo) \\[\\begin{eqnarray*} M_{N^{*}}^{(k)}(t) = \\frac{\\partial}{\\partial t} M_{N^{*}}^{(k-1)}(t) &amp;=&amp; \\frac{\\partial}{\\partial t} \\left[\\left(\\frac{1-P_{0}^{M}}{1-P_{0}}\\right) M_{N}^{(k-1)}(t)\\right]\\\\ &amp;=&amp; \\left(\\frac{1-P_{0}^{M}}{1-P_{0}}\\right) M_{N}^{(k)}(t)_{\\blacksquare} \\end{eqnarray*}\\] Corolario \\[\\begin{eqnarray*} \\mathbb E[(N^{*})^{k}] = \\left(\\frac{1-P_{0}^{M}}{1-P_{0}}\\right) \\mathbb E [N^{k}] \\end{eqnarray*}\\] Script:“Familia (a,b,i)” Un vídeo donde se explica a grandes rasgos lo anterior lo podrán ver en el siguiente enlace: https://www.youtube.com/watch?v=ZX2W59Mdaag "],["frecuencia-anexo.html", "Capítulo 4 Frecuencia Anexo", " Capítulo 4 Frecuencia Anexo Sea \\(N\\) una v.a. discreta con distribución \\(\\{P_{k}: k= 0,1,...\\}\\) . Sean \\(a\\) y \\(b\\) dos constantes. Se dice que \\(N\\) tiene distribución tipo \\((a,b,0)\\) si se cumple la igualdad \\[P_{k} = \\left(a+\\frac{b}{k}\\right)P_{k+1} \\quad\\mbox{para } k= 1,2,...\\] Demuestre que las siguientes distribuciones son de tipo \\((a,b,0)\\) encontrando las constantes \\(a\\) y \\(b\\) con las cuales se cumple la condición mencionada: a.1) \\(bin(n,p)\\) a.2) \\(Poisson(\\lambda)\\) a.3) \\(bin. neg(r,p)\\) Recíprocamente, demuestre que si \\(N\\) tiene distribución tipo (a,b,0), entonces \\(N\\) es alguna de (a.1), (a.2) ó (a.3) a) a.1) Consideremos \\(X\\sim{ Bin (n, \\gamma) }\\). Entonces su f.m.p. está dada por: \\[P_{x} = \\begin{pmatrix} n\\\\ x \\end{pmatrix} (1-\\gamma)^{n-x}\\gamma^{x}\\mathbb{I} (x)_{\\{0,1,...,n\\}} \\mbox{ para } n\\in\\mathbb N_{1} \\mbox{ &amp; } \\gamma\\in(0,1)\\] Demostración: Tomando \\(k\\in\\{1,2,...\\}\\) tenemos: \\[\\begin{eqnarray*} \\frac{P_k}{P_{k-1}}&amp;=&amp;\\frac{\\begin{pmatrix} n\\\\ k \\end{pmatrix}(1-\\gamma)^{n-k}\\gamma^k}{\\begin{pmatrix} n\\\\ k-1 \\end{pmatrix}(1-\\gamma)^{n-k+1}\\gamma^{k-1}}\\mathbb{I}_{1,2,...,n}(k)\\\\ &amp;=&amp;\\frac{\\frac{n!}{(n-k)!k!}}{\\frac{n!}{(n-k+1)(k-1)}}\\frac{\\gamma}{1-\\gamma}\\\\ &amp;=&amp;\\frac{(n-k+1)!(k-1)!}{(n-k)!k!}\\frac{\\gamma}{1-\\gamma}\\\\ &amp;=&amp;\\frac{n-k+1}{k}\\cdot\\frac{\\gamma}{1-\\gamma}\\\\ &amp;=&amp;-\\frac{\\gamma}{1-\\gamma}+\\frac{(n+1)\\left(\\frac{\\gamma}{1-\\gamma}\\right)}{k}\\\\ &amp;=&amp; a+\\frac{b}{k}{\\left\\{\\begin{array}{lcc} \\text{Tomando} \\\\ a=-\\frac{\\gamma}{1-\\gamma}\\mbox{ \\&amp; } b=(n+1)\\left(\\frac{\\gamma}{q-\\gamma}\\right) \\end{array}\\right.}\\\\ \\therefore P_k&amp;=&amp;\\left(a+\\frac{b}{k}\\right)P_{k-1}\\mbox{ con } a=-\\frac{\\gamma}{1-\\gamma}\\mbox{ &amp; } b=(n+1)\\left(\\frac{\\gamma}{1-\\gamma}\\right)\\hspace{0.5em} \\forall\\hspace{0.4em} k \\in\\{1,2,...\\}_{\\hspace{0.5em}\\square} \\end{eqnarray*}\\] a.2) Consideremos \\(X\\sim{ Poi (\\lambda) }\\). Entonces su f.m.p. está dada por: \\[P_{x} = e^{-\\lambda}\\frac{\\lambda^x}{x!}\\hspace{2mm}\\mathbb{I}_{\\mathbb{N}_{0}} (x) \\mbox{ para } \\lambda&gt;0\\] Demostración. Tomando \\(k\\in\\{1,2,...\\}\\) tenemos: \\[\\begin{eqnarray*} \\frac{P_{k}}{P_{k-1}} = \\frac{e^{-\\lambda}\\frac{\\lambda^k}{k!}}{e^{-\\lambda}\\frac{\\lambda^{k-1}}{(k-1)!}}\\mathbb{I}_{\\{1,2,...\\}}(k)=\\frac{\\lambda}{k}=a+\\frac{b}{k}\\quad{\\left\\{\\begin{array}{lcc} \\text{Tomando $a=0$ &amp; $b=\\lambda$}\\\\ \\end{array}\\right.}\\\\ \\therefore P_k=\\left(a+\\frac{b}{k}\\right)P_{k-1} \\mbox{ con } a=0 \\mbox{ \\&amp; } b=\\lambda.\\hspace{0.5em} \\forall\\hspace{0.4em} k\\in\\{1,2,...\\}_{\\hspace{0.5em}\\blacksquare} \\end{eqnarray*}\\] a.3) Consideremos \\(X\\sim{ BinNeg (r,\\gamma) }\\). Entonces su f.m.p. está dada por: \\[P_{k} =\\frac{\\Gamma(r+k)}{\\Gamma(r)\\Gamma(k+1)}(1-\\gamma)^{r}\\gamma^{k}\\hspace{2mm}\\mathbb{I}_{\\mathbb{N}_0} (x) \\mbox{ para } r&gt;0 \\mbox{ &amp; } \\gamma\\in(0,1)\\] Demostración. Tomando \\(k\\in\\{1,2,...\\}\\) tenemos: \\[\\begin{eqnarray*} \\frac{P_k}{P_{k-1}}&amp;=&amp;\\frac{\\frac{\\Gamma(r+k)}{{\\Gamma(r)}\\Gamma(k+1)}{(1-\\gamma)^r}\\gamma^k}{\\frac{\\Gamma(r+k-1)}{{\\Gamma(r)}\\Gamma(k)}{(1-\\gamma)^r}\\gamma^{k-1}}=\\frac{\\Gamma(r+k)\\Gamma(k)}{\\Gamma(k+1)\\Gamma(r+k-1)}\\gamma=\\frac{(r+k-1){\\Gamma(r+k-1)}{\\Gamma(k)}}{k{\\Gamma(k)}{\\Gamma(r+k-1)}}\\gamma\\\\ &amp;=&amp;\\frac{r+k-1}{k}\\gamma=\\gamma+\\frac{r-1}{k}\\gamma=a+\\frac{b}{k}\\quad{\\left\\{\\begin{array}{lcc} \\text{Tomando $a=\\gamma$ \\&amp; $b=(r-1)\\gamma$}\\\\ \\end{array}\\right.}\\\\ \\therefore P_k&amp;=&amp;\\left(a+\\frac{b}{k}\\right)P_{k-1} \\mbox{ con } a=\\gamma \\mbox{ \\&amp; } b=(r-1)\\gamma\\hspace{0.5em}\\forall k \\in \\{1,2,...\\}_{\\hspace{0.5em}\\blacksquare} \\end{eqnarray*}\\] b) Nota 1: Primero notemos que los casos anteriores son excluyentes \\((a,b)\\) a.1) Como \\(\\gamma\\in(0,1)\\) y \\(n\\in\\mathbb N_{1}\\) entonces: \\[\\begin{eqnarray*} &amp;\\frac{\\gamma}{1-\\gamma}&gt;0 \\Longleftrightarrow -\\frac{\\gamma}{1-\\gamma}=a&lt;0 \\mbox{ y } (n+1)\\left(\\frac{\\gamma}{1-\\gamma}\\right)=b&gt;0 \\\\ &amp;\\therefore \\mbox{Si } X\\sim{Bin(n,p)}\\Rightarrow X\\in \\mbox{ Tipo}(a=0,b&gt;0) \\end{eqnarray*}\\] a.2) Como \\(\\lambda&gt;0\\) entonces: \\(\\lambda=b&gt;0\\) y \\(a=0\\) \\[\\therefore\\mbox{ Si } X\\sim{Poi(\\lambda)} \\Rightarrow X\\in \\mbox{ Tipo}(a=0,b&gt;0)\\] a.3) Como \\(\\gamma\\in(0,1)\\) y \\(r&gt;0\\) entonces: \\[\\begin{eqnarray*} &amp;\\gamma=a\\in(0,1)\\mbox{ y }(r-1)\\gamma = b\\geq 0\\\\ &amp;\\therefore\\mbox{ Si } X\\sim{BinNeg(\\gamma,r)} \\Rightarrow X\\in \\mbox{ Tipo}(a\\in(0,1),b\\geq0) \\end{eqnarray*}\\] Nota 2: Si \\(X\\in \\mbox{ Tipo}(a,b=-a) \\Rightarrow P_{1}=(a+\\frac{b}{1})P_{0} \\Rightarrow P_{k}=(a+\\frac{b}{k})P_{k-1} = 0\\hspace{2mm}\\forall k&gt;0.\\) De tal manera que \\(P_{0}\\equiv1\\hspace{0.4em}\\therefore\\hspace{0.4em} X\\equiv 0 \\in\\mbox{ Tipo}(a,b=-a)\\) Nota 3: Veamos que si \\(X\\in \\mbox{ Tipo} (a_{x},b_{x}) \\mbox{ y } Y\\in \\mbox{ Tipo}(a_{y},b_{y}) \\mbox{ con } a_{x}=a_{y} \\mbox{ y } b_{x}=b_{y} \\mbox{ entonces }\\)\\(X\\overset{d}{\\equiv} Y\\). Demostración. Sea \\(P_{k}^x \\ddot{=}\\mathbb{P}[x=k]\\mbox{ y } P_{k}^Y\\equiv\\mathbb{P}[Y=k]\\) En general \\[\\begin{eqnarray*} P_{k}=(a+\\frac{b}{k})P_{k-1} \\hspace{0.4em}\\forall k\\in \\mathbb{N}_{1} \\mbox{, entonces,}P_{x} = \\left[\\displaystyle\\prod_{n=1}^{k}\\left(a+\\frac{b}{k-n+1}\\right)\\right]P_{0}\\hspace{0.4em}\\forall k\\in \\mathbb{N}_{1} \\end{eqnarray*}\\] Así: \\[\\begin{eqnarray*} 1 &amp;=&amp; \\displaystyle\\sum_{k=0}^{\\infty}P_{k}\\\\ &amp;=&amp; P_{0} + \\sum_{k=1}^{\\infty}P_{k} \\\\ &amp;=&amp; P_{0} + \\sum_{k=1}^{\\infty}\\left[\\displaystyle\\prod_{n=1}^{k}\\left(a+\\frac{b}{k-n+1}\\right)\\right]P_0 \\\\ &amp;=&amp; P_{0}\\left[1+\\displaystyle\\sum_{k=1}^{\\infty}\\displaystyle\\prod_{n=1}^{k}\\left(a+\\frac{b}{k-n+1}\\right)\\right] \\end{eqnarray*}\\] \\[\\begin{eqnarray*} \\rightarrow P_{0} = \\left[1+\\displaystyle\\sum_{k=1}^{\\infty}\\displaystyle\\prod_{n=1}^{k}\\left(a+\\frac{b}{k-n+1}\\right)\\right]^{-1} \\end{eqnarray*}\\] De esta manera, si dos variables aleatorias tienen los mismos parámetros de tipo \\((a,b)\\) entonces también comparten la probabilidad en cero; esto es: \\[\\begin{eqnarray*} P_{0}^{X}&amp;=&amp;\\left[1+\\displaystyle\\sum_{k=1}^{\\infty}\\displaystyle\\prod_{n=1}^{k}\\left(a_{X}+\\frac{b_{X}}{k-n+1}\\right)\\right]^{-1} = \\left[1+\\displaystyle\\sum_{k=1}^{\\infty}\\displaystyle\\prod_{n=1}^{k}\\left(a_{Y}+\\frac{b_{Y}}{k-n+1}\\right)\\right]^{-1} = P_{0}^{Y}\\\\ \\mbox{Luego: }P_{k}^{X}&amp;=&amp;\\left[\\displaystyle\\prod_{n=1}^{k}\\left(a_{X}+\\frac{b_{X}}{k-n+1}\\right)\\right]P_{0}^{X} = \\left[\\prod_{n=1}^{k}\\left(a_{Y}+\\frac{b_{Y}}{k-n+1}\\right)\\right]P_{0}^{Y} = P_{k}^{Y} \\hspace{0.4em}\\forall k\\in\\mathbb{N}_{1}\\\\ \\therefore P_k^X&amp;=&amp;P_k^Y\\hspace{0.4em}\\forall k\\in\\mathbb{N}_0 \\mbox{ y por lo tanto } X\\overset{d}{\\equiv} Y_{\\hspace{0.5em}\\blacksquare} \\end{eqnarray*}\\] Demostración. Región Poisson \\(X\\in\\mbox{ Tipo} (a=0,b&gt;0) \\Leftrightarrow X \\sim Poi(\\lambda=b) \\forall b&gt;0\\). Entonces tenemos cubierta la región de la derecha. Región Binomial Negativa \\(X\\in BinNeg(r,\\gamma)\\) con \\(r&gt;0\\) y \\(\\gamma\\in(0,1)\\) sii \\(X\\in \\mbox{ Tipo}(a=\\gamma,b=(r-1)\\gamma) \\therefore a\\in(0,1)\\) y \\(b=(r-1)a=ra-a&gt;-a\\) Región Binomial \\(X\\in Bin(n,\\gamma)\\) con \\(n\\in \\mathbb N_{1}\\) y \\(\\gamma\\in(0,1)\\). sii \\(X\\in \\mbox{ Tipo}(a=-\\frac{\\gamma}{1-\\gamma},b=(n+1)\\left(\\frac{\\gamma}{1-\\gamma}\\right)) \\therefore a\\in(-\\infty,0)\\) y \\(b=-a(n+1)\\) con \\(n\\in\\mathbb{N}_{1}\\) Región \\(X\\equiv0 (P_{k}=\\delta_{0}^{(k)})\\)}\\ \\(X\\equiv0\\) sii \\(X\\in\\mbox{ Tipo}(a,b=-a)\\) De tal manera que las regiones que ya tenemos caracterizadas son descritas en el siguiente gráfico. al conjunto puntos \\((a,b)\\) en la unión de estas regiones, lo llamaremos \\(T\\). Veamos que si \\(X\\in Tipo(a,b)\\) con \\((a,b)\\notin T\\) entonces \\(P_{k}^{\\chi}\\) no es función de probabilidad. Veamos entonces que la región I no es válida. \\((a,b)\\in\\) I \\(\\Longleftrightarrow b&lt;-a\\). Si este es el caso \\(\\longrightarrow P_{k}=(a+\\frac{b}{k})P_{k-1} &lt; a(1-\\frac{1}{k})P_{k-q}\\) \\(\\forall k\\in\\mathbb N_{1}\\). En particular si \\(k=1 \\longrightarrow P_{1}&lt;0\\)! Lo cual es imposible para una f.m.p. Ahora, trabajando en la región III, tenemos que \\((a,b)\\in\\) III \\(\\Longleftrightarrow a&lt;0&lt;b\\) y \\(b\\neq -a(n+1)\\) \\(\\forall n\\in\\mathbb N_{0}\\). Para esto veamos una identidad: Cuando \\(a\\neq0\\). Podemos obtener \\(P_{k}\\) mediante la recursión como: \\(P_{k} = P_{0}\\displaystyle\\frac{a^{k}}{k!}\\displaystyle\\prod_{t=1}^{k}\\left(\\displaystyle\\frac{b}{a}+t\\right)\\) para \\(k\\in\\mathbb N_{1}\\) Para esto haremos inducción: Base: \\(P_{1}=(a+b)P_{0}=a\\left(1+\\displaystyle\\frac{b}{a}\\right)P_{0}=P_{0}\\displaystyle\\frac{a^1}{1!}\\left(1+\\displaystyle\\frac{b}{a}\\right)=P_{0}\\displaystyle\\frac{a^1}{1!}\\left(\\displaystyle\\frac{b}{a}+1\\right)=P_{0}\\displaystyle\\frac{a^1}{1!}\\prod_{t=1}^{1}\\left(\\displaystyle\\frac{b}{a}+t\\right)\\) Paso inductivo: \\(P_{k+1}=\\left(a+\\displaystyle\\frac{b}{k+a}\\right)P_{k}=\\displaystyle\\frac{a}{k+1}\\left(k+1+\\displaystyle\\frac{b}{a}\\right)P_{k}=\\displaystyle\\frac{a}{k+1}\\left(\\displaystyle\\frac{b}{a}+k+1\\right)P_{0}\\displaystyle\\frac{a^{k}}{k!}\\prod_{t=1}^k\\left(\\displaystyle\\frac{b}{a}+t\\right)=P_{0}\\displaystyle\\frac{a^{k+1}}{(k+1)!}\\displaystyle\\prod_{t=1}^{k+1}\\left(\\displaystyle\\frac{b}{a}+t\\right)\\) Ahora, regresando a la región III, tenemos que \\(b\\neq-a(n+1)\\) \\(\\forall n\\in\\mathbb N_{0}\\) Por lo que para cada \\((a,b)\\in\\) III $mN_{1} $ tal que \\(-am&lt;b&lt;-a(m+1)\\) (esto por la propiedad Arquimedeana). Luego como \\(a&lt;0\\), tenemos: \\(-am&lt;b&lt;-a(m+1)\\) \\(\\Longleftrightarrow\\) \\(-m = -\\displaystyle\\frac{am}{a}&gt;\\displaystyle\\frac{b}{a}&gt;-\\displaystyle\\frac{a(m+1)}{a}=-(m+1)\\) \\(\\Longleftrightarrow -m+t&gt;\\displaystyle\\frac{b}{a}+t&gt;-(m+1)+t\\) para cualquier \\(t\\). Sin embargo, notemos que \\(-(m+1)+t\\geq0\\) \\(\\Longleftrightarrow t\\geq m+1\\). De tal manera que \\(\\exists N\\in\\mathbb N_{1}\\) tal que \\(\\forall n\\geq N\\), \\(\\displaystyle\\prod_{t=1}^{n}(\\displaystyle\\frac{b}{a}+t)\\) no cambiará su signo, pues las entradas a partir de cierto punto se hacen positivas. Pero: \\(P_{k}=P_{0}\\frac{a^{k}}{k!}\\prod_{t=1}^{k}(\\displaystyle\\frac{b}{a}+t)\\) con \\(a&lt;0\\). Entonces \\(\\exists k\\in \\mathbb N_{1}\\) tal que \\(P_{k}&lt;0\\)!. A menos que justo a partir de este punto \\(P_{k}=0\\) \\(\\Longleftrightarrow \\displaystyle\\frac{b}{a}+k=0\\) \\(\\Longleftrightarrow b=-ak\\) con \\(k\\in\\mathbb N_{1}\\) pero ese es precisamente el caso Binomial, que ya vimos. Por último, veamos que sucede cuando \\((a,b)\\in\\) II. Esto significa que \\(a\\geq1\\) y \\(b\\geq-a\\). Así, \\(b\\geq-a\\) \\(\\Longleftrightarrow a+\\frac{b}{k}\\geq a-\\frac{a}{k}=a(1-\\frac{1}{k}) = a(\\displaystyle\\frac{k-1}{k})\\geq \\displaystyle\\frac{k-1}{k}\\). De esta manera podemos ver que \\(P_{n}\\geq\\frac{1}{n}P_{1}\\) \\(\\forall n \\geq 1\\) inductivamente: Base: \\(P_{1}\\geq\\frac{1}{1}P_{1}\\) Paso inductivo: \\(P_{k+1}=(a+\\frac{b}{k+1})P_{k}\\geq (a+\\frac{b}{k+1})\\frac{1}{k}P_{1}\\geq (\\frac{k+1-1}{k+1})\\frac{1}{k}P_{1}=\\frac{1}{k+1}P_{1}\\) Luego, si \\(P_{x}\\) fuera una f.m.p. entonces \\(1=\\displaystyle\\sum_{k=0}^{\\infty}P_{k}=P_{0}+\\displaystyle\\sum_{k=1}^{\\infty}P_{k}\\geq P_{0}+\\displaystyle\\sum_{k=1}^{\\infty}\\displaystyle\\frac{1}{k}P_{1}\\) Entonces: \\(1\\geq P_{0}+P_{1}\\displaystyle\\sum_{k=1}^{\\infty}\\frac{1}{k}\\)! La suma no está acotada. En conclusión: \\((a,b)\\in\\) I \\(\\cup\\) III \\(\\longrightarrow \\exists k \\in\\mathbb N_{1}\\) con \\(P_{k}&lt;0\\); y si \\((a,b)\\in\\) II entonces \\(\\displaystyle\\sum_{k=0}^{\\infty}P_{k}\\) diverge. De tal manera que si \\(X\\) es v.a. con \\(X\\in Tipo(a,b)\\), entonces \\(X\\) tiene necesariamente, alguna de las distribuciones a.1),a.2), o a.3) \\(\\blacksquare\\) ¡La respuesta que has escrito aquí es ejemplar! "],["severidad-coberturas.html", "Capítulo 5 Severidad Coberturas 5.1 Diferencia entre función de densidad y función de masa de probabilidad 5.2 Coberturas en Seguros / Reaseguros 5.3 La regla de Darth Vader 5.4 Monto máximo de beneficio", " Capítulo 5 Severidad Coberturas 5.1 Diferencia entre función de densidad y función de masa de probabilidad Debemos tener en mente que siempre que hablamos de una v.a. entonces estamos diciendo implícitamente que lo denotamos como \\(f_X(x)\\) es una función de densidad. El detalle importante aquí es que: \\[f_X(x)\\ {\\neq}\\hspace{0.4 em}\\mathbb{P}[X=x]\\] Porque de hecho \\(\\mathbb{P}[X=x]=0\\) ya que \\(X\\) es una v.a continua. La diferencia con una función de masa de probabilidad (f.m.p) es que cuando se menciona se deja claro que su correspondiente variable aleatoria digamos \\(Y\\) sí es discreta y por lo tanto: \\[\\begin{eqnarray*} f_Y(y)\\ = \\ \\mathbb{P}[Y=y] \\end{eqnarray*}\\] Una f.m.p. también es llamada función de densidad pero se usa el término ‘’f.m.p.’’ para dejar claro que su v.a. subyacente es discreta. Lo anterior es una observación importante ya que si estamos hablando de una v.a. continua, no se usa directamente la función de densidad para obtener probabilidades. Es necesario acudir a la función de distribución \\((F_Y(y))\\) para poder acceder a las probabilidades de una v.a del tipo continuo. En concreto,una función de distribución siempre hace referencia a probabilidades. Sin importar si su v.a. subyacente es continua o discreta, siempre sucede que: \\[F_Y(y)\\ \\ddot{=}\\ \\mathbb{P}[Y\\leq y]\\] Nota: Entonces, cuando queramos medir, de forma probabilística, fenómenos que involucran una v.a. continua, vamos a utilizar la función de distribución 5.1.1 Visualización de variables aleatorias mixtas Cuando una v.a. es discreta, su función de distribución puede verse como algo de este estilo: Del gráfico se puede deducir que: \\[\\begin{equation*} F_X(x)\\ \\ddot=\\ \\mathbb{P}[X\\leq x] = \\left \\{ \\begin{matrix} 0 &amp; \\mbox{si }&amp; x &lt;1 \\\\ 0.2 &amp; \\mbox{si }&amp; x\\in[1,2) \\\\ 0.6 &amp; \\mbox{si }&amp; x\\in[2,3) \\\\ 0.8 &amp; \\mbox{si }&amp; x\\in[3,4) \\\\ 1 &amp; \\mbox{si }&amp; x\\geq 4\\end{matrix}\\right. \\end{equation*}\\] Si observamos el gráfico observamos que la función tiene saltos o discontinuidades. Dichos saltos nos indican que en los puntos del soporte (eje X) existe una probabilidad puntual. Además hay partes constantes (planas), lo cual indica que no hay probabilidad de ningún tipo en esos puntos. La función de masa de probabilidad del ejemplo anterior se puede obtener a partir de la diferencia entre los saltos esto pues, si \\(x\\in sop\\{X\\}\\): \\[\\begin{eqnarray*} F_X(x)-F_X(x-1)\\ &amp;\\ddot=&amp;\\ \\mathbb{P}[X\\leq x]-\\mathbb{P}[X\\leq x-1]\\\\ &amp;=&amp; (\\mathbb{P}[X=x]+\\mathbb{P}[X&lt;x])-\\mathbb{P}[X\\leq x-1] \\end{eqnarray*}\\] pero \\(\\mathbb{P}[X&lt;x]=\\mathbb{P}[X\\leq x-1]\\) pues \\(X\\) es discreta (esto asumiendo que \\(sop\\{X\\}\\) tiene números consecutivos). \\[\\begin{eqnarray*} \\Leftrightarrow F_X(x)-F_X(x-1) &amp;=&amp; \\mathbb{P}[X=x]+\\mathbb{P}[X\\leq x-1]-\\mathbb{P}[X\\leq x-1]\\\\ &amp;=&amp; {\\underbrace{\\mathbb{P}[X=x] =\\ f_X(x)}}_{\\text{por ser una v.a. discreta}} \\end{eqnarray*}\\] Calculando las diferencias entre los saltos: \\[\\begin{equation*} f_X(x)\\overset{\\overset{\\text{v.a discreta}}{\\downarrow}} = \\mathbb{P}[X=x] = \\left \\{ \\begin{matrix} 0.2 &amp; \\mbox{si }&amp; x =1 \\\\ 0.4 &amp; \\mbox{si }&amp; x=2 \\\\ 0.2 &amp; \\mbox{si }&amp; x=3 \\\\ 0.2 &amp; \\mbox{si }&amp; x=4 \\\\ 0 &amp; \\mbox{c.o.c} \\end{matrix}\\right. \\end{equation*}\\] De tal manera que cuando vemos la función de densidad de una v.a. discreta, se verá como: Notemos que la función solamente toma valores positivos en puntos específicos. En el resto es continua casi-seguramente como constante igual a cero. En cuanto a las v.a los gráficos de las funciones de distribución son algo de este estilo: Observemos que esta gráfica no tiene saltos, de hecho, \\(\\forall\\hspace{0.3em}p\\in [0,1]\\quad \\exists x \\in \\mathbb{R}\\) tal que \\(F_X(x)=p\\) (considerando aquellos casos donde \\(x\\rightarrow\\infty\\hspace{0.4em} ó\\hspace{0.4em}-\\infty\\)). En otras palabras \\(F_X:\\mathbb{R}\\mapsto[0,1]\\) es suprayectiva. Si nosotros quisiéramos obtener la función de densidad de la v.a. anterior, basta con calcular su derivada. De tal manera que: \\[f_X(t)=\\frac{d}{dt}F_X(t)\\] Haciendo esto y tomando como referencia simplemente el gráfico anterior, su función de densidad podría verse como algo del estilo: Notemos que esta función es continua, al menos en \\((0,x_0)\\) que tiene que ser el \\(sop\\{X\\}\\) pues vemos que la distribución acumula nada (cero) antes del 0 y todo (uno) después de \\(x_0\\). Por las mismas razones, nosotros esperaríamos ver una indicadora en este mismo intervalo para \\(f_X\\). Lo importante a notar de este caso es que la función de distribución de una v.a continua es también continua y suprayectiva al [0,1]. Cuando hablamos de una v.a mixta vamos a tener una función de distribución acumulada que es discontinua, pero cumpliendo siempre las hipótesis esenciales de una f.d.a. Gráficamente puede verse como: Recordemos que una función de distribución acumulada siempre hace referencia a una probabilidad. Entonces los saltos que tiene esta función no pueden pasar desapercibidos. De hecho, lo que sucede es que la variable aleatoria subyacente a \\(F_X\\) del último gráfico, debe ser mixta. Para obtener la función de densidad a partir de la distribución en estos casos, debemos hacer ambas cosas: Derivar y tomar la diferencia en los saltos. De observar el gráfico anterior vemos que hay saltos en los puntos 0 y \\(x_0\\), esto quiere decir que \\(\\mathbb{P}[X]\\equiv 0&gt;0\\) y también \\(\\mathbb{P}[X\\equiv x_0]\\). Lo cual significa que \\(X\\) toma valores puntuales con una probabilidad positiva. Sin embargo, vemos que la función de distribución es continua en el intervalo \\((0,x_0)\\), eso quiere decir que \\(X\\) es continua en los intervalos donde \\(F_X\\) también lo sea. Más aún, si \\(x\\in(0,x_0)\\Rightarrow\\mathbb{P}[X=x]=0\\), precisamente por el efecto de la continuidad. La función de densidad debería verse como: 5.2 Coberturas en Seguros / Reaseguros En esta sección comenzaremos a modelar flujos de efectivo ($) típicos de una compañía aseguradora. Los contratos más comunes que manejan las aseguradoras consideran diversos factores como el coaseguro y la inflación, los cuales son llamados de tipo proporcional. Por otro lado, tenemos el deducible y el monto máximo de beneficio los cuales son considerados del tipo no-proporcional. Comúnmente este tema está muy relacionado con los tipos de reaseguro, sin embargo por ahora vamos a modelar los contratos antes mencionados desde el punto de vista de la aseguradora. Marginalmente, se puede observar que este tipo de contratos están relacionados por lo que el desarrollo teórico de los contratos desde el punto de vista del asegurado quedará como ejercicio para el lector. Para introducir este tema se recomienda ver: Sea \\(X\\) una v.a. que modela la severidad de un riesgo. Cuando ocurre un siniestro, \\(X\\) toma un valor fijo y según lo que se establezca en una póliza podemos ‘’dividir’’ este monto en dos partes: \\(Z\\ \\ddot{=}\\ \\) Monto que paga el asegurado \\(Y\\ \\ddot{=}\\ \\) Monto que paga la aseguradora Para que juntos cubran el siniestro; \\(X\\) = \\(Y\\)+\\(Z\\). A esto nosotros en este curso le llamaremos: Ley de conservación del riesgo: ’’ Un riesgo que no se crea ni se destruye, solo se transfiere.’’ Nuesto objetivo será que para todos los tipos de seguro que tengamos, pongamos a \\(Y\\) en términos de \\(X\\). 5.2.1 Coaseguro Sea \\(X\\) el monto de pérdida asociado a un siniestro, luego, tomemos \\(\\alpha\\) \\(\\in[0,1]\\) un factor de coaseguro*. Este factor representa la proporción de pago que le corresponde a la aseguradora mientras el poseedor de la póliza (contrato) paga la fracción restante \\(1-\\alpha\\). La v.a. de pago por parte de la aseguradora es: \\[Y=\\alpha X\\] Cuya densidad puede obtenerse de la siguiente manera: \\[\\begin{eqnarray*} F_Y(y)\\ \\ddot{=}&amp;\\ \\mathbb{P}[Y\\leq y]\\ \\ddot{=}\\ \\mathbb{P}[\\alpha X\\leq y]=\\mathbb{P}\\left[X\\leq \\frac{y}{\\alpha}\\right]\\ \\ddot{=}\\ F_X\\left(\\frac{y}{\\alpha}\\right) \\end{eqnarray*}\\] \\[\\begin{eqnarray*} \\Rightarrow {f_Y(y)}=\\frac{d}{dy}F_Y(y)=\\frac{d}{dy}F_X\\left(\\frac{y}{\\alpha}\\right)= {\\frac{1}{\\alpha}f_X\\left(\\frac{y}{\\alpha}\\right)} \\end{eqnarray*}\\] Otra manera (quizás la más conocida) de obtener el resultado anterior es con el teorema de cambio de variable: TEOREMA DE CAMBIO DE VARIABLE 1. Sea \\(X\\) una variable aleatoria continua con valores dentro de un intervalo \\((a,b)\\subseteq \\mathbb{R}\\), y con función de densidad \\(f_X(x)\\).Sea \\(\\varphi:(a,b)\\rightarrow\\mathbb{R}\\) una función continua, estrictamente creciente o decreciente y con inversa diferenciable. Entonces la variable aleatoria \\(Y=\\varphi(X)\\) toma valores dentro del intervalo \\(\\varphi(a,b)\\), y tiene función de densidad: \\[\\begin{equation*} f_Y(y)=\\left \\{ \\begin{matrix} f_X(\\varphi^{-1}(y))|\\frac{d}{dy}\\varphi^{-1}(y)| &amp; \\mbox{para }&amp; y\\in \\varphi(a,b) \\\\ 0 &amp; \\mbox{otro caso }&amp; \\end{matrix}\\right. \\end{equation*}\\] Así, podemos entonces hacer lo siguiente: \\[\\begin{eqnarray*} Y&amp;=&amp;\\varphi(X)=\\alpha X \\Rightarrow\\varphi^{-1}(X)=\\frac{X}{\\alpha}\\Rightarrow \\left|\\frac{d}{dx}\\varphi^{-1}(X)\\right|=\\frac{1}{\\alpha} \\end{eqnarray*}\\] \\[\\begin{eqnarray*} \\Rightarrow f_Y(y)=\\left|\\frac{d}{dy}\\varphi^{-1}(y)\\right| f_X(\\varphi^{-1}(y))=\\frac{1}{\\alpha}f_X\\left(\\frac{y}{\\alpha}\\right) \\end{eqnarray*}\\] Por lo tanto: \\[f_Y(t)=\\frac{1}{\\alpha}f_X\\left(\\frac{t}{\\alpha}\\right)\\] Nota: El soporte de \\(Y\\) estará dado por \\[sop(Y)\\hspace{0.4em}\\ddot{=}\\{y|\\frac{y}{\\alpha}\\in sop(X)\\}\\] Obtener la esperanza de esta v.a. es fácil en términos de la esperanza de \\(X\\), debido a la linealidad de la esperanza, se tiene que: \\[\\mathbb{E}[Y]=\\mathbb{E}[\\alpha X]=\\alpha\\mathbb{E}[X]\\] Ejemplo: Suponga que el monto de un siniesto es aleatorio y con distribución \\(X\\sim Unif(100,200)\\). En una póliza de seguros se pacta un factor de coaseguro \\(\\alpha=50\\%\\). De tal manera que lo que cubre la compañía será unicamente el 50% del total del siniestro \\((Y=\\alpha X)\\). \\[\\Rightarrow f_Y(t)=\\frac{1}{50\\%}f_X\\left(\\frac{t}{50\\%}\\right)=2f_X(2t)=2\\left(\\frac{1}{200-100}\\right)\\underset{(100,200)}{\\mathbb{I}}(2t)\\] \\(100\\leq 2t\\leq 200 \\Leftrightarrow 50 \\leq t\\leq100\\) \\[\\begin{eqnarray*} &amp;=&amp; \\frac{1}{50}\\underset{(50,100)}{\\mathbb{I}}(t)=\\frac{1}{100-50}\\underset{(50,100)}{\\mathbb{I}}(t)\\\\ &amp;\\Rightarrow&amp; Y=50\\% X\\sim Unif(50,100) \\end{eqnarray*}\\] En este caso, hemos llegado a que \\(Y\\) tiene otra distribución conocida. Sin embargo, esto no será siempre así, pero dado que en este caso si la tiene entonces podemos calcular la esperanza: \\[\\begin{eqnarray*} \\mathbb{E}[Y]&amp;=&amp; \\frac{b+a}{2}\\\\ &amp;=&amp; \\frac{100+50}{2}\\\\ &amp;=&amp; \\frac{150}{2}\\\\ &amp;=&amp; 75 \\end{eqnarray*}\\] Pero, es fácil ver que también se da que: \\[\\begin{eqnarray*} \\mathbb{E}[Y]&amp;=&amp;\\alpha \\mathbb{E}[X]\\\\ &amp;=&amp; (50\\%) \\left( \\frac{200+100}{2}\\right)\\\\ &amp;=&amp; \\left( \\frac{1}{2} \\right) (150)\\\\ &amp;=&amp; 75 \\end{eqnarray*}\\] De donde podemos observar que la propiedad anterior funciona. NOTA: Un coaseguro entra siempre que la aseguradora tenga que pagar y se paga la fracción del monto toal a cubrir. 5.2.2 Inflación Muchas veces el pago de una suma asegurada se hace a final del año. Pero, si un siniestro ocurre al principio del año hay que considerar que, lo que se valuó al momento del siniestro ya no valga lo mismo por efectos de la inflación. Para considerar la inflación, tomemos \\(r \\geq 0\\) y definamos a \\(X\\) como: El monto asociado a un siniestro. Vamos a pensar que, de materializarse un siniestro, éste sufrirá un cambio en su valor monetario provocado por la inflación a un año. De tal manera que el pago de la aseguradora será: \\[Y= (1+r)X\\] En caso de que el siniestro ocurra y la aseguradora la deba pagar. De manera (muy) similar al coaseguro. \\[\\begin{eqnarray*} F_{Y}(t)&amp;\\ddot{=}&amp;\\mathbb{P}[Y \\leq t]\\\\ &amp;=&amp; \\mathbb{P}[(1+r)X \\leq t]\\\\ &amp;=&amp; \\mathbb{P}\\left[X \\leq \\frac{t}{1+r} \\right]\\\\ &amp;\\ddot{=}&amp; F_{X}\\left( \\frac{t}{1+r} \\right) \\end{eqnarray*}\\] \\[\\begin{eqnarray*} F_{Y}(t)&amp;\\ddot{=}&amp;\\mathbb{P}[Y \\leq t]\\\\ &amp;=&amp; \\mathbb{P}[(1+r)X \\leq t]\\\\ &amp;=&amp; \\mathbb{P}\\left[X \\leq \\frac{t}{1+r} \\right]\\\\ &amp;\\ddot{=}&amp; F_{X}\\left( \\frac{t}{1+r} \\right) \\end{eqnarray*}\\] Entonces, \\[\\begin{eqnarray*} f_{Y}(t)&amp;=&amp; \\frac{d}{dt} F_{Y}(t)\\\\ &amp;=&amp; \\frac{d}{dt} F_{X}\\left( \\frac{t}{1+r} \\right)\\\\ &amp;=&amp; \\frac{1}{1+r} f_{X}\\left( \\frac{t}{1+r} \\right)\\\\ \\end{eqnarray*}\\] Por lo tanto \\[\\begin{eqnarray*} {f_{Y}(t)= \\frac{1}{1+r} f_{X}\\left( \\frac{t}{1+r} \\right)}\\\\ \\end{eqnarray*}\\] Análogamente al caso anterior, la esperanza de esta variable aleatoria estará dada por: \\[\\begin{eqnarray*} \\mathbb{E}[Y]= \\mathbb{E}[(1+r)X]= (1+r) \\mathbb{E}[X] \\end{eqnarray*}\\] Ejemplo: Suponga que el monto de un siniestro es aleatorio y con distribución \\(X \\sim Unif(0,1000)\\). En una póliza de seguros se pacta una inflación con tasa \\(r=10\\%\\). De tal manera que, cuando ocurre un siniestro, este se valuará en cierto monto X, pero como se pagará a final del año, al monto total será de \\(Y=(1+r)X\\). Así: \\[\\begin{eqnarray*} f_{Y}(t)&amp;=&amp; \\frac{1}{1+r} f_{X}\\left( \\frac{t}{1+r} \\right)\\\\ &amp;=&amp; \\frac{1}{1.1} f_{X} \\left( \\frac{t}{1.1} \\right)\\\\ &amp;=&amp; \\frac{1}{1.1} \\left[ \\frac{1}{100} \\underset{(0,1000)}{\\mathbb{I}}\\left(\\frac{t}{1.1} \\right)\\right] \\end{eqnarray*}\\] \\(0\\leq \\frac{t}{1.1}\\leq 1000 \\Leftrightarrow 0 \\leq t \\leq 1100\\) \\[\\begin{eqnarray*} f_{Y}(t)&amp;=&amp; \\frac{1}{1100} \\underset{(0,1100)}{\\mathbb{I}} (t) \\\\ \\end{eqnarray*}\\] Por lo tanto \\[\\begin{eqnarray*} Y&amp;=&amp; (1+r)X \\sim Unif(0,1100)\\\\ \\end{eqnarray*}\\] Al igual que en el ejemplo anterior, tenemos el caso en que Y tiene una distribución conocida. Debido a lo anterior, podemos hacer el cálculo de su esperanza. \\[\\begin{eqnarray*} \\mathbb{E}[Y]&amp;=&amp; \\frac{b+a}{2}\\\\ &amp;=&amp; \\frac{1100}{2}\\\\ &amp;=&amp; 550\\\\ \\end{eqnarray*}\\] Que coincide con la propiedad. \\[\\begin{eqnarray*} \\mathbb{E}[Y]&amp;=&amp; (1+r)\\mathbb{E}[X]\\\\ &amp;=&amp; (1.1)\\left( \\frac{1000}{2} \\right)\\\\ &amp;=&amp; (1.1)500\\\\ &amp;=&amp; 550 \\end{eqnarray*}\\] Por lo tanto \\[\\begin{eqnarray*} \\mathbb{E}[Y]&amp;=&amp; 550 \\\\ \\end{eqnarray*}\\] Debemos tener en mente que este factor inflacionario aumentó el valor esperado del monto original. Ahora, vamos a observar el siguiente diagrama 5.2.3 Deducibles ¿Cómo funciona un deducible? ¿Por qué funciona? Figura 1. https://www.youtube.com/watch?v=sV0mQB42Rf4&amp;feature=youtu.be Cuando ocurre un siniestro, el asegurado llama al seguro. En la póliza (de hecho en la mayoría) se establece un deducible, el cual debe pagar al asegurado para poder ejercer su derecho de cobro a la aseguradora. Esto es muy importante ya que la aseguradora pagará únicamente si el monto del siniestro supera el deducible. Visto de manera gráfica, si suponemos que el monto del siniestro puede ocurrir dentro del intervalo \\([a,b]\\). Sea \\(X\\) el monto de pérdida asociado a un siniestro definido en el intervalo \\([a,b]\\) con \\(a \\geq 0\\). Sea \\(d \\in [a,b]\\) el deducible establecido en la póliza. El pago de la aseguradora tendrá un comportamiento: Esto es debido a que podemos calcular a Y en términos de \\(X\\) como: \\[\\begin{eqnarray*} Y&amp;=&amp; máx\\{ X-d,0\\}\\\\ &amp;=&amp;\\left \\{ \\begin{matrix} 0&amp; \\mbox{si }&amp; a\\leq X \\leq d &amp; \\Leftrightarrow &amp; Y \\equiv 0 \\\\X-d&amp; \\mbox{si }&amp; d &lt;X \\leq b &amp; \\Leftrightarrow &amp; \\quad 0&lt; Y \\leq b-d \\\\ \\end{matrix}\\right. \\end{eqnarray*}\\] Que es el monto que la aseguradora cubrirá en caso de que un siniestro ocurra. Buscamos obtener una medida de probabilidad de esta v.a. Para eso podemos tomar casos. Como \\(X\\) es continua , mediremos probabilidades con la función de distribución. Observación: Noten que \\(Y= máx\\{ X-d, 0 \\}\\geq 0\\) siempre. Caso 1 \\[\\begin{eqnarray*} X \\in [a,d] \\Leftrightarrow Y \\equiv 0\\\\ \\end{eqnarray*}\\] \\[\\begin{eqnarray*} \\mathbb{P}[Y \\equiv 0] &amp;=&amp; \\mathbb{P}[X \\in [a,d]]\\\\ &amp;=&amp; \\mathbb{P}[a \\leq X \\leq d]\\\\ &amp;=&amp; F_{X}(d)- F_{X}(a)\\\\ &amp;=&amp; F_{X}(d) \\end{eqnarray*}\\] Por lo tanto \\[\\begin{eqnarray*} \\mathbb{P}[Y \\equiv 0] &amp;=&amp; F_{X}(d) \\end{eqnarray*}\\] Por lo tanto , vemos que \\(Y\\) acumula probabilidad positiva en un punto. ¿Será entonces que Y es una v.a discreta? Recordemos la siguiente definición y el siguiente teorema. Teorema: Sea \\(A\\) y \\(B\\) dos eventos y supongamos que B tiene probabilidad estrictamente positiva. La del evento \\(A\\) dado el evento \\(B\\) se denota por el símbolo \\(P(A|B)\\) y se define como el siguiente cociente: De donde se sigue que:\\ \\[\\begin{eqnarray*} {P(A|B)} = {P(A\\cap B)}{P(B)} \\end{eqnarray*}\\] Teorema: Sea \\(B_{1},...,B_{n}\\) una partición de \\(\\Omega\\) tal que \\(P(B_{i}) \\neq 0, i=1,...,n\\). Para cualquier evento A. \\[\\begin{eqnarray*} P(A)= \\displaystyle\\sum_{i=1}^{n}P(A|B_{i})P(B_{i})\\\\ \\end{eqnarray*}\\] Caso 2 \\[\\begin{eqnarray*} Si \\quad X \\in (d,b] \\Leftrightarrow 0&lt; \\gamma \\leq b-d \\end{eqnarray*}\\] \\(\\Omega =Y \\geq 0 \\quad \\Leftrightarrow \\quad (Y=0 \\vee Y&gt;0)=\\Omega\\) Tomemos \\(t \\in (0,b-d]\\), ahora midamos probabilidad de \\(\\gamma\\). \\[\\begin{eqnarray*} F_{Y}(t)&amp;=&amp; \\mathbb{P}[Y \\leq t]\\\\ &amp;=&amp; \\mathbb{P}[Y \\leq t| Y \\equiv 0] \\cdot \\mathbb{P}[Y \\equiv 0]+\\mathbb{P}[Y \\leq t| Y &gt; 0] \\cdot \\mathbb{P}[\\ Y &gt; 0] \\quad \\text{Probabilidad total}\\\\ &amp;=&amp; \\mathbb{P}[Y \\equiv 0] + \\mathbb{P} [(0&lt;Y) \\cap (Y \\leq t)]\\quad \\text{Definición de probabilidad condicional}\\\\ &amp;=&amp; \\mathbb{P}[Y \\equiv 0]+\\mathbb{P}[0 &lt; Y \\leq t]\\\\ \\end{eqnarray*}\\] Por lo tanto \\[\\begin{eqnarray*} {F_{Y}(t)}&amp;=&amp; {\\mathbb{P}[Y \\equiv 0]+\\mathbb{P}[0 &lt; Y \\leq t]}\\\\ \\end{eqnarray*}\\] Esto era lógico pues los eventos: \\[\\begin{equation*} A\\ddot{=} (Y \\geq t) \\quad \\quad B\\ddot{=}(Y \\equiv0) \\quad \\quad C\\ddot{=}(0&lt; Y \\geq t)\\\\ \\end{equation*}\\] Cumplían que: \\[\\begin{equation*} A=B\\cup C \\quad\\textit{y además} \\quad B \\cap C= \\varnothing \\quad {\\textit{(significa que son ajenos)}} \\\\ \\end{equation*}\\] Y recordando los axiomas de la probabilidad: Axiomas de probabilidad \\(P(A)\\leq 0\\) \\(P(\\Omega)=1\\) \\(P \\left( \\bigcup_{k=1}^{\\infty} \\right)\\)} \\(=\\) \\(\\displaystyle\\sum_{k=1}^{\\infty}P(A_{k})\\) cuando \\(A_{1}, A_{1},...\\) son ajenos dos a dos Entonces \\[\\begin{eqnarray*} F_{Y}(t)&amp;\\ddot{=}&amp; \\mathbb{P}[Y \\leq t]\\\\ &amp;=&amp; \\mathbb{P}[A]\\\\ &amp;=&amp; \\mathbb{P}[B \\cup C]\\\\ &amp;=&amp; \\mathbb{P}[B]+\\mathbb{P}[C]\\\\ &amp;=&amp; \\mathbb{P}[Y \\equiv 0]+\\mathbb{P}[0 &lt; Y \\leq t] \\quad \\text{Se separó en casos ajenos}\\\\ \\end{eqnarray*}\\] Y ahí tenemos dos formas diferentes de llegar a este mismo resultado. Por otro lado, aún tenemos que encontrar a \\(\\gamma\\) en términos de \\(X\\), así que para eso haremos lo siguiente: \\[\\begin{eqnarray*} F_{Y}(t)&amp;=&amp; { \\mathbb{P}[Y \\equiv 0]}+{\\mathbb{P}[0 &lt; Y \\leq t]}\\\\ &amp;=&amp; {\\mathbb{P}[X\\leq d]}+{\\mathbb{P}[0&lt;X-d\\leq t]} \\end{eqnarray*}\\] Esto pues, como tenemos \\(t \\in (0, b-d]\\) entonces: \\[\\begin{eqnarray*} 0&lt;Y \\leq t \\leq b-d \\quad \\Rightarrow \\quad 0&lt;Y \\leq b-d \\Rightarrow Y =X-d\\\\ \\end{eqnarray*}\\] Entonces \\[\\begin{eqnarray*} F_{Y}(t)&amp;=&amp; F_{X}(t)+\\mathbb{P}[0&lt; X-d \\leq t]\\\\ &amp;=&amp; F_{X}(d)+\\mathbb{P}[d&lt;X\\leq t+d]\\\\ &amp;=&amp; {F_{X}(d)}+(F_{X}(t+d)-F_{X}(d))\\\\ &amp;=&amp; F_{X}(t+d)\\\\ \\end{eqnarray*}\\] Por lo tanto \\[\\begin{eqnarray*} F_{Y}(t) &amp;=&amp; F_{X}(t+d)\\\\ \\end{eqnarray*}\\] Entonces \\[\\begin{eqnarray*} f_{Y}(t)&amp;=&amp; \\displaystyle\\frac{\\partial }{\\partial t}F_{Y}(t)\\\\ &amp;=&amp; \\displaystyle\\frac{\\partial }{\\partial t}F_{X}(t+d)\\\\ &amp;=&amp; f_{X}(t+d) \\quad \\forall \\quad t\\in (0, b-d]\\\\ \\end{eqnarray*}\\] Entonces \\(Y\\) se comporta como una v.a continua en el intervalo (0, b-d]. \\(\\therefore Y\\) es una variable aleatoria mixta. Entonces: Si \\(Y \\ddot{=} máx\\{ X-d,0 \\}\\) es la v.a que mide al monto a pagar de la aseguradora por un siniestro \\(X \\in [a,b]\\) en un contrato con deducible d. La función de densidad de \\(\\gamma\\) en términos de la densidad de \\(X\\) será: \\[\\begin{eqnarray*} f_{Y}(t)&amp;=&amp; \\left \\{ \\begin{matrix} F_{X}(d) &amp; \\mbox{si }&amp; t0 &amp; {\\textit{Parte discreta}}\\\\ f_{X}(t+d)&amp; \\mbox{si }&amp; t\\in t \\in (0,b-d] &amp; {\\textit{Parte continua}}\\\\ 0 &amp; &amp; \\mbox{en otro caso.}\\\\ \\end{matrix}\\right. \\end{eqnarray*}\\] Una vez esto, el cálculo de la esperanza de \\(Y\\) está dado por: \\[\\begin{eqnarray*} \\mathbb{E}[Y]&amp;=&amp; \\underbrace{\\overbrace{0}^{y} \\cdot \\overbrace{F_{X}(d)}^{\\mathbb{P}[Y=y]}}{\\text{Parte discreta}}+ \\int{0}^{b-d}{\\underbrace{\\overbrace{t}^{y}\\overbrace{f_{X}(t+d)}^{f_{Y}(y)} dt}_{\\text{Parte continua}}}\\\\ \\end{eqnarray*}\\] Así podríamos calcular la esperanza “Por definición” de una variable aleatoria mixta. 5.3 La regla de Darth Vader El nombre del siguiente teorema no tiene un origen del todo oficial. Se dice que el nombre surgió por la impresión contraintuitiva, quizás un poco inquietante y surrealista , que el resultado puede evocar un primer encuentro. Considerando una v.a \\(X\\) que es no-negativa casi-seguramente y cuya esperanza existe, entonces: \\[\\begin{eqnarray*} \\mathbb{E}[X]= \\int_{0}^{\\infty}S_{X}(t) \\quad dt\\\\ \\end{eqnarray*}\\] Figura 2: https://www.youtube.com/watch?v=wWC7KFpuPmI&amp;feature=youtu.be Podemos ver un ejemplo de esto, en el vídeo que se muestra a continuación Figura 3: https://www.youtube.com/watch?v=wWC7KFpuPmI Por ahora no vamos a ver la demostración de la regla, pero vamos a deducirla en los casos en que pueda resultar “fácil”. Nosotros vamos a decir que la esperanza está calculada a la Darth Vader cuando tengamos una integración de la función de supervivencia en algún intervalo para su obtención. Otro vídeo que puede ayudar a comprender esta idea lo encontrarán a continuación: Figura 4: https://www.youtube.com/watch?v=ZX2W59Mdaag Inspirados en la regla de Darth Vader, vamos a obtener la esperanza de \\(Y\\) con un cálculo de este estilo. \\[\\mathbb E [Y] = \\int_{0}^{b-d} t f_{x}(t+d) dt = \\int_{d}^{b} (\\alpha - d) f_{x}(\\alpha)d\\alpha\\] Cambio de var: \\(\\alpha = t+d \\longrightarrow dt = d\\alpha\\) \\[=-(\\alpha-d)S_{x}(\\alpha) |_{d}^{b} + \\int_{d}^{b} S_{x}(\\alpha) d\\alpha\\] Por partes: \\[\\begin{array}{lcc} u=\\alpha-d &amp; dv = f_{x}(\\alpha)\\\\\\\\ du = d\\alpha &amp; v = -S_{x}(\\alpha) \\longrightarrow \\frac{\\partial}{\\partial t}S_{x}(t) = -f_{x}(t) \\\\\\\\ \\end{array}\\] \\[=-(b-d){S_{x}(b)}+{(d-d)} S_{x}(d) + \\int_{d}^{b} S_{x}(\\alpha) d\\alpha\\] \\[=\\int_{d}^{b} S_{x}(\\alpha) d\\alpha\\] Entonces, podemos calcular el valor esperado de \\(Y\\) en un contrato con deducible al estilo Darth Vader en términos de \\(X\\) como: \\[\\mathbb E [Y] = =\\int_{d}^{b} S_{x}(t) dt\\] Nota: Recuerden que \\(X\\in[a,b]\\), donde \\(a,v\\geq0.\\) Lo anterior también es válido si \\(b\\longrightarrow\\infty,ie,X\\in[a,\\infty)\\) 5.4 Monto máximo de beneficio Similar a los deducibles, un monto máximo de beneficio es un límite que se fija en una póliza. De tal manera que todo monto producido por un siniestro que exceda cierto umbral, ya no será responsabilidad de la aseguradora. Cuando ocurre un siniestro en un contrato de este estilo, el asegurado llama a la aseguradora y ésta procede a cubrir todos los daños hasta cierto monto pactado. si el siniestro excede este monto, el restante lo deberá cubrir el asegurado. Visto de manera gráfica, si suponemos que el monto del siniestro puede ocurrion dentro del intervalo \\([a,b]\\) tendremos: Sea \\(X\\) el monto de pérdida asociado a un siniestro definido en el intervalo \\([a,b]\\), \\((a\\geq0)\\). Sea u el monto máximo de beneficio definido en la póliza con \\(u\\in[a,b]\\). La v.a. \\(Y\\) tendrá un comportamiento del estilo: Esto es similar al pay off de ir corto en una opción put. “vender una opción de venta.” Esto es debido a que podemos calcular a \\(Y\\) en términos de \\(X\\) como: \\[\\begin{equation*} Y = min\\{ x,u\\}= \\begin{cases} x &amp; si &amp; a\\leq x&lt;u {\\Longleftrightarrow} a\\leq Y &lt; u\\\\\\\\ u &amp; si &amp; u\\leq x \\leq b {\\Longleftrightarrow} Y\\equiv u \\\\\\\\ \\end{cases} \\end{equation*}\\] Nota: \\(Y\\in[a,u]\\) \\(\\forall x\\in[a,b]\\) Una vez ya encontrada la variable aleatoria a modelar, procedemos a buscar su función de densidad. Igual que con el deducible podemos separ casos: Caso 1: \\(X\\in[a,b)\\) \\(\\Longleftrightarrow\\) \\(Y\\in[a,u)\\) Tomemos \\(t\\in[a,u)\\), entonces: \\[\\begin{align*} F_{Y}(t) &amp;\\circeq \\mathbb P [Y\\leq t]\\\\ &amp;= \\mathbb P [a\\leq Y \\leq t]\\hspace{3mm} \\text{pues $y\\geq a$ siempre}\\\\ &amp;= \\mathbb P [a\\leq X \\leq t]\\hspace{3mm} \\text{pues $t&lt;u$}\\\\ &amp;= F_{X}(t) - {F_{X}(a)}\\ \\text{pues $a\\leq X \\leq b$}\\\\ \\end{align*}\\] \\(\\therefore\\) \\(F_{Y}(t) =F_{X}(t)\\) \\(\\Longleftrightarrow\\) \\(f_{Y}(t) = f_{X}(t)\\) \\(\\forall t\\in[a,u)\\) Caso 2: \\(Y\\equiv u\\) \\(\\Longleftrightarrow\\) \\(u\\leq x \\leq b\\), entonces: \\(F_{Y}(u) = \\mathbb P [Y\\leq u] = \\mathbb P [a\\leq Y\\leq u] = 1\\) Vemos que hay probabilidad positiva de que \\(Y\\) tome el valor puntual \\(u\\). De tal manera que: \\[\\begin{align*} f_{Y}(u) &amp;= \\mathbb P[Y\\equiv u] = \\mathbb P[u\\leq x\\leq b] = F_{x}(b)-F_{x}(u)\\\\ &amp;= 1 - F_{x}(u)\\hspace{3mm} {pues\\hspace{2mm}x\\leq b\\hspace{2mm}siempre}\\\\ &amp;= S_{x}(u) \\hspace{7mm} \\\\ \\end{align*}\\] \\(\\therefore\\) \\(f_{Y}(u)=S_{x}(u)\\) Teniendo como resultado: Si \\(Y\\circeq min\\{X,u\\}\\) es la v.a. que mide el monto a pagar de la aseguradora por un siniestro \\(X\\in[a,b]\\) en un contrato con monto máximo de beneficio \\(&quot;u&quot;\\), la función de densidad de \\(Y\\) en terminos de la densidad de \\(X\\) será: \\[\\begin{equation*} f_{Y}(t)= \\begin{cases} f_{x}(t) &amp; si &amp; t\\in[\\alpha,u]\\hspace{2mm} {parte\\hspace{3mm}continua}\\\\\\\\ S_{x}(u) &amp; si &amp; t\\equiv u\\hspace{2mm}{parte\\hspace{3mm}discreta} \\\\\\\\ 0 &amp; &amp; en\\hspace{2mm}otro\\hspace{2mm}caso\\\\ \\end{cases} \\end{equation*}\\] Mostremos el cálculo de la esperanza y obtengámosla a la Darth Vader: \\(\\mathbb E [Y] = \\int_{a}^{u} t f_{Y}(t) dt + uS_{x}(u)\\) \\(\\longrightarrow\\) por definición Por partes: \\[\\begin{equation*} \\begin{cases} g=t &amp; dh = f_{Y}(t)dt\\\\ dg=dt &amp; h = -S_{x}(t) \\end{cases} \\end{equation*}\\] \\[\\mathbb E[Y]= -tS_{x}(t)|_{a}^{u} + \\int_{a}^{u} S_{x}(t)dt + uS_{x}(u) -uS_{x}(u) +a{S_{x}(a)}^{1} +\\int_{a}^{u}S_{x}(t)dt +{uS_{x}(u)} \\] \\[\\mathbb E[Y]= a+\\int_{a}^{u}S_{x}(t)dt \\Longleftrightarrow Darth Vader \\] \\[\\begin{eqnarray*} \\therefore \\mathbb E[Y] &amp;=&amp; a+\\int_{a}^{u}S_{x}(t)dt \\end{eqnarray*}\\] Nota: \\(a\\) es el valor mínimo que puede tomar \\(x\\), si \\(inf\\{sop\\{x\\}\\} = 0\\) \\(\\longrightarrow\\) \\(a=0\\). "],["severidad-combinacion-de-coberturas.html", "Capítulo 6 Severidad combinacion de coberturas 6.1 Contratos con Deducible y monto máximo de beneficio 6.2 Generalización de beneficio y monto máximo", " Capítulo 6 Severidad combinacion de coberturas Así es como hemos visto cada uno de los tipos de seguros por separado. Vamos a ver ahora como modelar combinaciones de estos seguros. 6.1 Contratos con Deducible y monto máximo de beneficio Lo que sucede en este tipo de contratos es que la aseguradora pagará cuando un siniestro rebase cierto deducible d, y cubrirá todos aquellos gastos que no superen un umbral u (monto máximo de beneficio). Dicho de otra forma, si un siniestro ocurre, la aseguradora pagará los gastos que ocurran únicamente entre los montos antes establecidos en la póliza d y u. Todo monto que quede por debajo del deducible o sobre el monto máximo de beneficio será responsabilidad del asegurado. Visto de manera gráfica, si suponemos que el monto del siniestro puede ocurrir dentro del intervalo \\([a,b]\\) tendremos: Consideremos una v.a \\(X \\in [a,b]\\) y tomemos \\(d, u \\in [a,b]\\) con \\(d&lt;u\\), el deducible y monto máximo de beneficio respectivamente. Sea \\(Y\\) la v.a que modela el monto a pagar por parte de la aseguradora en un contrato con estas características para cubrir el siniestro \\(X\\). La gráfica de \\(Y\\) en términos de los posibles valores de \\(X\\) es: Esto sucede ya que el pago está dado por: \\[\\begin{eqnarray*} Y &amp;=&amp; máx\\{ min\\{X-u\\}-d,0 \\}\\\\ &amp;=&amp;\\left \\{ \\begin{matrix} 0&amp; \\mbox{si }&amp; a\\leq X \\leq d &amp; \\Leftrightarrow &amp;Y \\equiv 0\\\\ X-d&amp; \\mbox{si }&amp; d &lt;X \\leq u &amp; \\Leftrightarrow &amp; \\quad 0&lt; Y \\leq u-d\\\\ u-d &amp; {si } &amp; u &lt;X \\leq b &amp; \\Leftrightarrow &amp; \\quad Y \\equiv u-d\\\\ \\end{matrix}\\right. \\end{eqnarray*}\\] Nota: \\(Y \\in [0, u-d] \\quad \\forall \\quad X [a,b]\\). Vamos a obtener ahora la forma de densidad de \\(Y\\). notemos que \\(Y \\in [0, u-d]\\). Podemos separar este intervalo en casos a manera similar a los casos pasados. Recordemos que \\(Y\\) está en función de valores que toma \\(X\\). \\[\\begin{eqnarray*} [0, u-d]&amp;=&amp; \\underbrace{\\{ 0\\}}_{\\text{Caso 1}} \\cup \\underbrace{(0, u-d)}_{\\text{Caso 2} }\\cup \\underbrace{\\{ u-d\\}}_{\\text{Caso 3}} \\end{eqnarray*}\\] Caso 1 Notemos que \\(a\\leq X \\leq d \\quad \\Leftrightarrow \\quad Y \\equiv 0\\) entonces: \\[\\begin{eqnarray*} f_{Y}(t)&amp;=&amp; \\mathbb{P}[Y \\equiv 0]\\\\ &amp;=&amp; \\mathbb{P}[a \\leq X \\leq d]]\\\\ &amp;=&amp; F_{X}(d)-{F_{X}(a)}\\\\ &amp;=&amp; F_{X}(d)\\\\ \\end{eqnarray*}\\] Por lo tanto \\[\\begin{eqnarray*} f_{Y}(t)&amp;=&amp; F_{X}(d)\\\\ \\end{eqnarray*}\\] Caso 2 Notemos que si \\(0&lt; Y &lt; u-d \\quad \\Rightarrow \\quad Y=X-d\\). Sea \\(t \\in (0, u-d)\\) y así: \\[\\begin{eqnarray*} F_{Y}(t)&amp;=&amp; \\mathbb{P}[Y \\leq t]\\\\ &amp;=&amp; \\mathbb{P}[Y \\equiv 0] + \\mathbb{P}[0&lt; Y \\leq t] \\quad {\\textit{Separamos en casos ajenos}}\\\\ &amp;=&amp; \\mathbb{P}[Y \\equiv 0] + \\mathbb{P}[0&lt; X-d \\leq t] \\quad {\\textit{Pues $t&lt;u-d$}}\\\\ \\end{eqnarray*}\\] Entonces \\[\\begin{eqnarray*} F_{Y}(t) &amp;=&amp; F_{X}(d)+\\mathbb{P}[d&lt;X \\leq t+d]\\\\ &amp;=&amp; {F_{X}(d)}+(F_{X}(t+d)-{F_{X}(d)})\\\\ &amp;=&amp; F_{X}(t+d)\\\\ \\end{eqnarray*}\\] Por lo tanto \\[\\begin{eqnarray*} F_{Y}(t)&amp;=&amp; F_{X}(t+d) \\quad \\Leftrightarrow \\quad f_{X}(t)= f_{X}(t+d) \\quad \\forall \\quad t \\in (0, u-d) \\\\ \\end{eqnarray*}\\] Caso 3 Notemos que \\(u \\leq X \\leq b \\Leftrightarrow Y \\equiv u-d\\) entonces: \\[\\begin{eqnarray*} f_{Y}(u-d) &amp;=&amp; \\mathbb{P}[Y \\leq u-d]\\\\ &amp;=&amp; \\mathbb{P}[u\\leq X \\leq b]\\\\ &amp;=&amp; {F_{X}(b)}-F_{X}(u)\\\\ &amp;=&amp; 1-F_{X}(u)\\\\ &amp;=&amp; S_{X}(u)\\\\ \\end{eqnarray*}\\] Por lo tanto \\[\\begin{eqnarray*} f_{Y}(u-d)&amp;=&amp; S_{X}(u)\\\\ \\end{eqnarray*}\\] Nota: \\(Y\\) es discreta en \\(\\{ 0\\}\\) y \\(\\{ u-d \\}\\), continua en \\((0, u-d)\\). Por lo tanto el pago de \\(Y\\) de una aseguradora en un contrato con deducible y monto máximo de beneficio en términos del monto de siniestro \\(X\\) es \\[\\begin{eqnarray*} f_{Y}(t)&amp;=&amp; \\left \\{ \\begin{matrix} F_{X}(d) &amp; \\mbox{si }&amp; t \\equiv 0 &amp; \\text{Parte discreta}\\\\ f_{X}(t+d)&amp; \\mbox{si }&amp; t \\in (0,u-d) &amp; \\text{Parte continua}\\\\ S_{X}(u) &amp; \\mbox{si }&amp; t\\equiv u-d &amp; \\text{Parte discreta}\\\\ 0 &amp; &amp; \\mbox{en otro caso.}\\\\ \\end{matrix}\\right. \\end{eqnarray*}\\] Ahora mostraremos el cálculo de la esperanza por definición y obtengámoslo a la Darth Vader. \\[\\begin{eqnarray*} \\mathbb{E}[Y] &amp;=&amp; \\overbrace{0 \\cdot F_{X}(d)}^{\\text{Discreta}}+ \\overbrace{\\displaystyle\\int_{0}^{u-d} f_{X}(t+d) dt}^{\\text{Continua}}+\\overbrace{(u-d)S_{X}(u)}^{\\text{Discreta}} \\rightarrow \\text{Por definición}\\\\ &amp;=&amp; \\displaystyle\\int_{d}^{u}(\\alpha-d)f_{X}+(u-d)S_{X}(u) \\end{eqnarray*}\\] Haciendo cambio de variable: \\[\\begin{eqnarray*} \\left \\{ \\begin{matrix} \\alpha= y+d &amp; \\Leftrightarrow &amp; y=\\alpha-d\\\\ d\\alpha=dy \\end{matrix}\\right. \\end{eqnarray*}\\] Por partes: \\[\\begin{eqnarray*} \\left \\{ \\begin{matrix} t= \\alpha-d &amp; dg=f_{X}(\\alpha)d\\alpha\\\\ dt=d\\alpha &amp; g= -S_{X}(\\alpha) \\end{matrix}\\right. \\end{eqnarray*}\\] De este modo \\[\\begin{eqnarray*} \\mathbb{E}[Y] &amp;=&amp; -(\\alpha-d)S_{X}(\\alpha) |_{d}^{u}+ \\displaystyle\\int_{d}^{u} S_{X}(\\alpha) d\\alpha +(u-d)S_{X}(u)\\\\ &amp;=&amp;{{-(u-d)S_{X}(u)}}+0+ \\displaystyle\\int_{d}^{u}S_{X}(\\alpha) d\\alpha + {{(u-d)S_{X})(u)}} \\end{eqnarray*}\\] Por lo tanto \\[\\mathbb{E}[Y] = \\displaystyle\\int_{d}^{u}S_{X}(t) d\\alpha\\] 6.2 Generalización de beneficio y monto máximo Acabamos de obtener la función de densidad del pago de una aseguradora cuando hay deducible y monto máximo de beneficio. Resulta que, haciendo un par de ajustes, recuperaremos los casos marginales, es decir, cuando solamente tenemos uno de los dos contratos. En pocas palabras vamos a ver que la última fórmula obtenida, podemos recuperar otras dos que ya vimos. Tenemos entonces la función de densidad con deducible y m.m.b: \\[\\begin{eqnarray*} f_{Y}(t)&amp;= \\left \\{ \\begin{matrix} F_{X}(d) &amp; \\mbox{si }&amp; t\\equiv 0 &amp; \\\\ f_{X}(t+d)&amp; \\mbox{si }&amp; t \\in (0,u-d) =(0,u) \\\\ S_{X}(u) &amp; {si } &amp; t\\equiv u-d &amp; \\\\ \\end{matrix}\\right. \\end{eqnarray*}\\] Para quitar el deducible ponemos d=0. Para quitar el monto máximo de beneficio, \\(u=\\infty\\). Quitando el deducible d=0 \\[\\begin{eqnarray*} f_{Y}(t)&amp;= \\left \\{ \\begin{matrix} F_{X}(d)=F_{X}(0)=0 &amp; \\mbox{si }&amp; t\\equiv 0 &amp; \\\\ f_{X}(t+d)=f_{X}(t)&amp; \\mbox{si }&amp; t \\in (0,u-d) =(0,u)\\\\ S_{X}(u) &amp; {si } &amp; t\\equiv u-d =u&amp; \\\\ 0 &amp; &amp; e.o.c \\end{matrix}\\right. \\end{eqnarray*}\\] \\[\\begin{eqnarray*} = \\left \\{ \\begin{matrix} f_{X}(t) &amp; \\mbox{si } &amp; t \\in (0,u)\\\\ S_{X}(u) &amp; \\mbox{si } &amp; t \\equiv u\\\\ 0 &amp; &amp; e.o.c \\end{matrix}\\right. \\end{eqnarray*}\\] _Pero \\(f_{X}(t)\\) está bien definida en [a,b], entonces: \\[\\begin{eqnarray*} f_{X}(t) &amp;=&amp; 0 \\quad \\forall \\quad t \\in (0,a) \\\\ &amp;=&amp; \\left \\{ \\begin{matrix} f_{X}(t) &amp; \\mbox{si } &amp; t \\in {[a,u)}\\\\ S_{X}(u) &amp; \\mbox{si } &amp; t \\equiv u\\\\ 0 &amp; &amp; e.o.c \\end{matrix}\\right. \\end{eqnarray*}\\] Recuperamos la función de densidad para m.m.b Veamos que sucede con la regla de Darth Vader. \\[\\begin{eqnarray*} {\\mathbb{E}[Y]}&amp;=&amp; \\int_{d}^{u} S_{X}(t) dt\\\\ &amp;=&amp; \\int_{0}^{u} S_{X}(t) dt\\\\ &amp;=&amp; \\int_{0}^{a} S_{X}(t) dt+ \\int_{a}^{u} S_{X}(t) dt\\\\ &amp;=&amp; \\int_{0}^{a} dt+ \\int_{a}^{u} S_{X}(t) dt \\quad {S_{X}(t)=1 \\quad \\forall t \\in (0,a)}\\\\ &amp;=&amp;\\ { a+ \\int_{a}^{u} S_{X}(t) dt} \\quad \\text{Esperanza a la Darth Vader de m.m.b}\\\\ \\end{eqnarray*}\\] Recuperando así la otra fórmula que ya teníamos . Esto nos hace pensar si el deducible necesariamente debe estar en el intervalo \\([a,b]\\). La respuesta es que no, pero \\(d&lt;a\\) el deducible siempre se pagaría cuando hubiese un siniestro. Sería un pago constante que se da cada que \\(X\\) tiene algún valor. Generalmente, esta clase de detalles pasa desapercibida o no se menciona, pero es importante estar consciente de lo que se está haciendo. PARA PENSAR: ¿Qué pasa cuando \\(d \\in [0,a)\\)? Simplemente \\(Y= máx\\{X-d,0 \\}=X-d\\) siempre, pues \\(X\\geq\\) por defición. Entonces \\(Y \\in [a-d,b-d]\\) y se comporta como: \\[\\begin{eqnarray*} F_{Y}(t) &amp;=&amp;\\mathbb{P}[Y \\leq t]\\\\ &amp;=&amp; \\mathbb{P}[X-d \\leq t]\\\\ &amp;=&amp; \\mathbb{P}[X\\leq t+d]\\\\ &amp;=&amp; F_{X}(t+d)\\\\ \\end{eqnarray*}\\] Entonces \\[\\begin{eqnarray*} f_{Y}(t)=f_{X}(t+d) \\quad \\forall \\quad t \\in (a-d,b-d)\\\\ \\end{eqnarray*}\\] Pero \\(Y\\) será una variable aleatoria totalmente continua ¿Por qué se quitó el efecto de la parte discreta? Antes, cuando \\(d\\in [a,b]\\) llevábamos un intervalo con probabilidad de \\(X\\) a un punto: Si hacemos una modificación a esto… Cuando \\(d \\in [0, a)\\) no tomamos probabilidades de \\(X\\) Entonces, a pesar de que \\(d\\) no está en el intervalo \\([a,b]\\), si le otorga un beneficio a la aseguradora, reduciendo así sus pagos. Aunque no tanto a como cuando \\(d \\in [a,b]\\) . Quedará ocmo ejercicio para el lector pensar qué sucede cuando \\(d&gt;b\\) tanto de manera teórica como práctica. ¿Creen que el asegurado estaría dispuesto a contratar un contrato así?, ¿Qué pasa con \\(\\mathbb{E}[Y]\\), con sus momentos en general, sus cuantiles, etc ? Se invita al lector a desarrollar un poco diferentes variantes de este problema pensando siempre en el punto de vista práctico aplicado a la realidad. Quitando Monto máximo de beneficio: \\(u=\\infty\\) \\[\\begin{equation*} f_{Y}{t} = \\begin{cases} F_{X}(d) &amp; si &amp; t\\equiv 0\\\\\\\\ f_{X}(t+d) &amp; si &amp; t\\in (0,u-d) = (0,\\infty)\\\\\\\\ S_{X}(u) = S_{X}(\\infty) = 0 &amp; si &amp; t\\equiv u-d = \\infty\\\\\\\\ 0 &amp; &amp; en\\ otro\\ caso\\\\ \\end{cases} \\end{equation*}\\] \\[\\begin{equation*} = \\begin{cases} F_{X}(d) &amp; si &amp; t\\equiv 0\\\\\\\\ f_{X}(t+d) &amp; si &amp; t\\in (0,\\infty)\\\\\\\\ 0 &amp; &amp; en\\ otro\\ caso\\\\ \\end{cases} \\end{equation*}\\] Pero \\(f_{X}(t)\\) está definida en [a,b] entonces \\(f_{X}(x)=0\\) $x&gt;b $ \\(f_{X}(t+d) =0\\) \\(\\forall t&gt;b-d\\), así \\[\\begin{equation*} = \\begin{cases} F_{X}(d) &amp; si &amp; t\\equiv 0\\\\\\\\ f_{X}(t+d) &amp; si &amp; t\\in (0,b-d]\\\\\\\\ 0 &amp; &amp; en\\ otro\\ caso \\end{cases} \\end{equation*}\\] Veamos qué sucede con la regla de Darth Vader para este caso. \\[\\begin{align*} \\mathbb E[Y] &amp;= \\int_{d}^{u} S_{x}(t)dt = \\int_{d}^{\\infty} S_{x}(t)dt\\\\ &amp;= \\int_{d}^{b} S_{x}(t)dt + \\int_{b}^{\\infty} S_{x}(t)dt\\\\ &amp;= \\int_{d}^{b} S_{x}(t)dt + \\int_{b}^{\\infty} 0dt \\ \\quad{x\\hspace{3mm}definida\\hspace{3mm}en\\hspace{3mm}[a,b]}\\\\ &amp;= \\int_{d}^{b} S_{x}(t)dt \\longrightarrow {Recuperamos\\hspace{2mm} la\\hspace{2mm} regla\\hspace{2mm} de\\hspace{2mm}}\\ {Darth\\hspace{2mm} Vader\\hspace{2mm} para\\hspace{2mm}}\\ {el\\hspace{2mm} caso\\hspace{2mm} solo\\hspace{2mm} con\\hspace{2mm} deducibles} \\end{align*}\\]space{2mm} Vader para} {el caso solo con deducibles} \\end{align*} De igual manera podríamos preguntarnos que sucede moviendo la posición de \\(&quot;u&quot;\\) a lo largo de la recta \\(\\mathbb R^{+}\\cup \\{0\\}\\), esto quedará como ejercicio de razonamiento para el lector. Finalmente, recordemos gráficamente al deducible y el monto máximo de beneficio: Figura: https://www.youtube.com/watch?v=EfmTWu2yn5Q&amp;feature=youtu.be Largo \\(\\approx\\) comprar (espero que el $ del bien \\(\\uparrow\\)). Call = opción de compra. Corto \\(\\approx\\) vender (espero que el $ del bien \\(\\downarrow\\)). Put = opción de venta. La gráfica es muy similar a la de ir largo en un contrato Bull Spread. La similitud que hay con las estrategias de derivadas puede ayudarnos como guía para saber otras maneras de construyr los mismos contratos, al igual que cuando se replica un portafolio en derivadas. Por ejemplo, se sabe la estrategia Bull Spread se puede replicar a partir de opciones call con diferentes precios Strike, tomando \\(u&gt;d\\): i) Llendo largo con un Call con precio Strike d. (+) (comprando) ii) Llendo corto con un Call con precio Strike u. (-) (vendiendo) Los signos son así pues, en el pay-off, lo que vendo me obliga y lo que compro me permite. Esto se traduce a una ecuación como: \\(BullSpread(u,d) = Call(d) - Call(u)\\) Esto sucede exactamente igual con los contratos de deducible (recordemos que estos son como ir largo en un contrato call. Llamamos por un momento: \\(Y_{d}^{u}\\circeq max\\{min\\{X,u\\}-d,0\\}\\) Contrato con deducible = d y Monto máximo de beneficio =u \\(Y_{d}^{u}\\circeq max\\{X-d,0\\}\\) Contrato con deducible = d \\(Y_{d}^{u}\\circeq max\\{X-u,0\\}\\) Monto máximo de beneficio = u Bueno, pues si un Bull Spread se puede replicar como acabamos de menciona, también sucede que: \\[Y_{d}^{u} = Y_{d} - Y_{u}\\] \\[\\Updownarrow\\] \\[max\\{min\\{X,u\\}-d,0\\} = max\\{X-d,0\\} - max\\{X-u,0\\}\\] Es decir podemos modelar un contrato con deducible y monto máximo de beneficio en términos de dos contratos de deducible. La interpretación de esto puede resultar muy interesante. En el contexto en el que estamos \\(Y\\) modela pérdidas (montos) entonces, si decimos que asumir un contrato \\(Y_{d}^{u}\\) es lo mismo que hacer \\(Y_{d} - Y_{u}\\), significa que equivale a asumir un contrato con deducible \\((Y_{d})\\) y que “alguien más” asuma el riesgo hasta cierto punto \\((Y_{u})\\). Tema que nos hace pensar en reaseguro, pero se estudiará más adelante. También se sabe que la estrategia Bull Spread se puede replicar con el siguiente portafolio: i) Ir largo en un put con precio Strike d. (+) (comprar) ii) Ir corto en un put con precio Strike u. (-) (vender) Traduciendolo así en la siguiente igualdad: \\[Bull Spread (u,d) = put(u) - put(d)\\] Y una equivalencia también se da ahora con los contratos de monto máximo de beneficio (recordemos que estos som como ir corto en put). Llamemos momentáneamente: \\(Y_{d}^{u}\\circeq max\\{min\\{X,u\\}-d,0\\}\\) Contrato con deducible = d y Monto máximo de beneficio =u \\(Y_{d}^{u}\\circeq max\\{X,d\\}\\) Contrato con m.m.b = d \\(Y_{d}^{u}\\circeq max\\{X,u\\}\\) Contrato con m.m.b =u Entonces, sin pérdida de generalidad, si \\(Y^{d}\\) es como ir corto en un contrato put sucede que \\(-Y^{d}\\) es como ir largo en un contrato put. Replicando: \\[Y_{d}^{u} = Y_{d} - Y_{u}\\] \\[\\Updownarrow\\] \\[max\\{min\\{X,u\\}-d,0\\} = max\\{X,u\\} - max\\{X,d\\}\\] La verificación de esto quedará como ejercicio para el lector. Asimismo, estas observaciones se meten con temas fuera del alcance de este curso. Se invita al lector a investigar más y a abrir su mente para hacer analogías con estos temas. Como un último comentario, me gustaría hacer una pregunta para el lector. Teniendo conocimiento básicos de finanzas, sabemos que NO debemos valuar derivados con probabilidades reales. en la teoría financiera se sabe que para encontrar el precio de un derivado se hace uso de una medida amortiguada dad por el Lema de Itô. ¿Porqué si los seguros con deducibles y montos máximos de beneficio son similares a algunos productos financieros estos SÍ se valúan con probabilidades reales? Figura: https://www.youtube.com/watch?v=qzFAK1jJKIE Combinando todo: pólizas con deducible, monto máximo de beneficio, coaseguro e inflación. Cada uno de los contratos son diferentes por sí solos. Sin embargo, así como con el deducible y monto máximo de beneficio, también es posible integrar el coaseguro y la inflación. ¡Manos a la obra! Vamos a construir la variable aleatoria del monto de pérdida a partir de modelar su comportamiento práctico. Cuando ocurre un siniestro, se materializa un monto a pagar X, vamos a pensar que el pago por dicho monto se remunerará dentro de un año. Llamemos r a la tasa de inflación anual. Nota: Aquí decimos “un año” pero en general puede ser “un periodo de tiempo”. Debido al efecto inflacionario, el monto a pagar después de un año será: \\[X_r \\circeq {X(1+r})\\] Luego, si éste sinietro \\(X_{r}\\) no supera el deducible \\((d)\\), entonces la aseguradora no pagará algo. Es decir, si denostamos a \\(Y\\) como la pérdida de la aseguradora: \\[{Y} \\equiv 0 \\Longleftrightarrow X_r \\leq {d}\\] Por otro lado; si el monto \\({X_r}\\) supera el deducible, entonces el coaseguro \\({\\alpha}\\) se acciona. Vamos a preguntarnos ahora, ¿Cuanto será lo máximo que pagará la aseguradora?. Como estamos hablando de que existe un monto máximo de beneficio \\(u\\), entonces lo máximo a pagar ocurrirá si \\(X_r \\geq {u}\\). A su vez, como hay un deducible, el pago máximo es: \\[Y\\equiv \\alpha ({u}-{d}) \\Longleftrightarrow X_r \\geq{u}\\] Lo anterior implica que \\(Y\\in[0,\\alpha({u}-{d})]\\). De donde se observa que \\(Y\\) tiene probabilidad positiva de tomar valores puntuales en sus extremos. ¿Qué suscede con el pago de la aseguradora \\(Y\\) si el monto total \\(X_r\\) se encuentra entre el deducible \\(d\\) y el monto máximo de beneficio \\(u\\)?. Se deduce por tricotomía que: \\[Y \\in (0,{\\alpha}({u}-{d})) \\Longleftrightarrow {X_r} \\in ({d},{u})\\] Nota: Es importante observar que ni el monto máximo de beneficio ni el deducible son afectados directamente por la inflación. Proponerlos debe hacerse pensando en que el coaseguro los afecta y que el siniestro con inflación se quede dentro de la cobertura. Cuando \\(X_r \\in ({d},{u})\\) entonces lo que la aseguradora pagará es: \\[{Y} = {\\alpha}[{X_{r}} - {d}] \\Longleftrightarrow {X_r} \\in ({d},{u})\\] En resumen, tenemos que: \\[\\begin{equation*} Y =máx\\{\\alpha(mín\\{X_{r},{u}\\}-d),0\\} = \\left \\{ \\begin{matrix} 0 &amp; \\mbox{sii }&amp; X_{r} \\leq d \\\\ \\alpha[X_{r}-d] &amp; \\mbox{sii }&amp; X_{r}\\in (d,u) \\\\ \\alpha(u-d) &amp; \\mbox{sii }&amp; X_{r}\\geq u \\end{matrix}\\right. \\end{equation*}\\] \\[\\begin{equation*} Y =máx\\{\\alpha(mín\\{X(1+r),u\\}-d),0\\} = \\left \\{ \\begin{matrix} 0 &amp; \\mbox{sii }&amp; X\\leq\\frac{d}{1+r} \\\\ \\alpha[X(1+r)-d] &amp; \\mbox{sii }&amp; X\\in \\left(\\frac{d}{1+r},\\frac{u}{1+r}\\right) \\\\ \\alpha(u-d) &amp; \\mbox{sii }&amp; X\\geq\\frac{u}{1+r} \\end{matrix}\\right. \\end{equation*}\\] Una vez construida nuestra v.a. procedemos a medir probabilidades de ella.\\ Como \\(Y\\in[0,\\alpha({u}-{d})]\\), podemos separar en 3 casos: \\(Y\\) es discreta en: Caso \\({Y\\equiv 0}\\) \\[\\begin{eqnarray*} F_{Y}(0)=f_{Y}(0)&amp;=&amp;\\mathbb{P}[{Y}\\equiv 0]=\\mathbb{P}\\left[{X}\\leq\\frac{d}{1+{r}}\\right]=F_{X}\\left(\\frac{d}{1+{r}}\\right)\\\\ &amp;\\therefore&amp; f_{Y}(0)=F_{X}\\left(\\frac{d}{1+{r}}\\right) \\end{eqnarray*}\\] Caso \\({Y \\equiv {\\alpha}({u}-{d})}\\) \\[\\begin{eqnarray*} {f_Y}{\\alpha}({u}-{d}))=\\mathbb{P}[{Y}\\equiv\\alpha({u}-{d})]=\\mathbb{P}\\left[{X}\\geq\\frac{u}{1+{r}}\\right]=S_{X}\\left(\\frac{u}{1+{r}}\\right) \\end{eqnarray*}\\] \\(Y\\) es continua en: Caso \\({Y\\in (0,{\\alpha}({u}-{d}))}\\) Sea \\(t\\in(0,{\\alpha}({u}-{d}))\\), entonces: \\[\\begin{eqnarray*} F_{Y}(t)\\ &amp; \\ddot{=}\\ &amp; \\mathbb{P}[Y\\leq t]\\\\ &amp;=&amp;\\mathbb{P}[\\{Y\\equiv 0\\}\\cup\\{0&lt;Y\\leq t\\}]\\\\ &amp;=&amp;\\mathbb{P}[Y\\equiv 0]+\\mathbb{P}[0&lt;Y\\leq t]\\quad\\{\\text{Eventos ajenos.}\\\\ &amp;=&amp; F_{X}\\left(\\frac{d}{1+r}\\right)+\\mathbb{P}[0&lt;\\alpha[X(1+r)-d]\\leq t]\\quad\\{\\text{Sustituyendo y porque } t&lt;\\alpha(u-d)\\\\ &amp;=&amp; F_{X}\\left(\\frac{d}{1+r}\\right)+\\mathbb{P}\\left[\\frac{d}{1+r}&lt;X\\leq\\frac{t+d\\alpha}{(1+r)\\alpha}\\right] \\quad\\left \\{ \\begin{matrix} 0 &lt;\\alpha[X(1+r)-d]\\leq t\\\\ \\Leftrightarrow 0 &lt; X(1+r)-d\\leq \\frac{t}{\\alpha}\\\\ \\Leftrightarrow 0&lt;X(1+r)\\leq\\frac{t}{\\alpha}+d\\\\ \\Leftrightarrow 0&lt;X\\leq\\frac{t+d\\alpha}{(1+r)\\alpha} \\end{matrix}\\right.\\\\ &amp;=&amp; F_{X}\\left(\\frac{d}{1+r}\\right)+F_{X}\\left(\\frac{t+d\\alpha}{(1+r)\\alpha}\\right)-F_{X}\\left(\\frac{d}{1+r}\\right)\\\\ &amp;=&amp; F_{X}\\left(\\frac{t+d\\alpha}{(1+r)\\alpha}\\right)\\\\ \\end{eqnarray*}\\] \\[\\begin{eqnarray*} \\therefore&amp;F_{Y}(t)=F_{X}\\left(\\frac{t+d\\alpha}{(1+r)\\alpha}\\right)\\quad\\forall t\\in(0,\\alpha(u-d))\\\\ \\underset{\\downarrow}{\\Rightarrow}&amp; f_{Y}(t)\\frac{1}{(1+r)\\alpha}f_{X}\\left(\\frac{t+d\\alpha}{(1+r)\\alpha}\\right)\\quad\\forall t\\in(0,\\alpha(u-d)) \\end{eqnarray*}\\] asumiendo la continuidad de \\(X\\) Así, la función de densidad de \\(Y\\) es: \\[\\begin{equation*} f_{Y}(t) = \\left \\{ \\begin{matrix} F_{X}(\\frac{d}{1+r}) &amp; \\text{si } &amp; t=0\\ (discreta)\\\\ \\frac{f_{X}\\left(\\frac{t+d \\alpha}{\\alpha (1+r)}\\right)}{\\alpha(1+r)} &amp; \\text{si }&amp; t\\in (0,\\alpha(u-d))\\ (continua)\\\\ S_{X}\\left(\\frac{u}{(1+r)}\\right) &amp; \\text{si} &amp; t=\\alpha(u-d)\\ (discreta)\\\\ 0 &amp; \\text{en otro caso.} \\end{matrix} \\right. \\end{equation*}\\] Nota: Para este proceso siempre pensamos \\(X\\) v.a. continua. Nota: \\(Y\\) es una v.a. mixta Una vez más, ya que tenemos la función de densidad, pasaremos a mostrar el cálculo de su esperanza por definición y a la Darth Vader. Por definición de esperanza: \\[\\begin{eqnarray*} \\mathbb{E}[{Y}]={\\underbrace{{0\\cdotp\\left[F_{{X}}\\left(\\frac{{d}}{1+{r}}\\right)\\right]}}_{\\text{parte discreta}}}+{\\underbrace{{\\int_0^{{\\alpha}({u}-{d})}t\\cdotp\\frac{f_{{X}}\\left(\\frac{t+{d}{\\alpha}}{{\\alpha}(1+{r})}\\right)}{{\\alpha}(1+{r})}dt}}_{\\text{parte continua}}}+{\\underbrace{{{\\alpha}({u}-{d})\\cdotp \\left[S_{{X}}\\left(\\frac{{u}}{1+{r}}\\right)\\right]}}_{\\text{parte discreta}}} \\end{eqnarray*}\\] Notamos que de la parte continua: \\[\\begin{equation*} \\int_0^{\\alpha(u-d)} t\\cdotp \\frac{f_X\\left(\\frac{t+d\\alpha}{(1+r)\\alpha}\\right)}{(1+r)\\alpha}dt = \\quad\\left \\{ \\begin{matrix} \\text{Cambio de Variable}\\\\ \\text{v} =\\frac{t+d\\alpha}{(1+r)\\alpha}\\Rightarrow dv =\\frac{1}{(1+r)\\alpha}dt\\\\ t=\\alpha[(1+r)v-d]\\\\ t=0\\Rightarrow v=\\frac{d}{1+r}\\\\ t=\\alpha(u-d)\\Rightarrow v=\\frac{u}{1+r} \\end{matrix}\\right. \\end{equation*}\\] \\[\\begin{equation*} = \\int_{\\frac{d}{1+r}}^{\\frac{u}{1+r}}(\\alpha[(1+r)v-d])f_X(v)dv = \\quad\\left \\{ \\begin{matrix} \\text{Integrando por partes:}\\\\ h=\\alpha[(1+r)v-d]\\quad dg=f_X(v) dv\\\\ dh=\\alpha(1+r) dv\\quad g=-S_X(v) dv \\end{matrix}\\right.\\\\ \\end{equation*}\\] \\[\\begin{equation*} = \\left.-\\alpha[(1+r)v-d] S_X(v)\\right|{\\frac{d}{1+r}}^{\\frac{u}{1+r}}+\\int{\\frac{d}{1+r}}^{\\frac{u}{1+r}}\\alpha(1+r)S_X(v)dv\\\\ \\end{equation*}\\] \\[\\begin{equation*} = \\alpha\\left[(1+r)\\frac{d}{(1+r)-d}\\right]S_X\\left(\\frac{d}{1+r}\\right)-\\alpha\\left[(1+r)\\left(\\frac{u}{1+r}\\right)-d\\right]S_X\\left(\\frac{u}{1+r}\\right)+...\\\\ . .+\\alpha(1+r)\\int_{\\frac{d}{1+r}}^{\\frac{u}{1+r}}S_X(v)dv\\\\ \\end{equation*}\\] \\[\\begin{equation*} = \\alpha(1+r)\\int_{\\frac{d}{1+r}}^{\\frac{u}{1+r}}S_X(v)dv-\\alpha[u-d]S_X\\left(\\frac{u}{1+r}\\right) \\end{equation*}\\] Sustituyendo la parte continua en la esperanza por definición, obtenemos la esperanza con la regla de Darth Vader: \\[\\begin{equation*} \\mathbb{E}[{Y}]={\\alpha}(1+{r})\\int_{\\frac{{d}}{1+{r}}}^{\\frac{{u}}{1+{r}}}S_{{X}}(t)dt \\end{equation*}\\] Esto sucede para el primer momento, en general, de acuerdo al teorema del estadístico inconciente: Caso discreto Proposición: Sea \\(X\\) una variable aleatoria discreta y sea \\(g:\\mathbb{R}\\rightarrow\\mathbb{R}\\) una función tal que \\(g(X)\\) es una variable con esperanza finita. Entonces: \\[\\mathbb{E}[g(X)]=\\sum_xg(x)f_X(x)\\] Caso Continuo Proposición: Sea \\(X\\) una variable aleatoria continua y sea \\(g:\\mathbb{R}\\rightarrow\\mathbb{R}\\) una función tal que \\(g(X)\\) es una variable con esperanza finita. Entonces: \\[\\mathbb{E}[g(X)]=\\int^\\infty_{-\\infty}g(x)f_X(x)dx\\] En este caso, como \\(Y\\) es una v.a. mixta y tomando \\({g}:\\mathbb{R}\\mapsto\\mathbb{R}\\) tal que \\({g}({Y})\\) es v.a. con esperanza finita: \\[\\begin{equation*} \\mathbb{E}[g(Y)]={\\underbrace{{g(0)\\left[F_{X}\\left(\\frac{d}{1+r}\\right)\\right]}}_{\\text{parte discreta}}}+{\\underbrace{{\\int_0^{\\alpha(u-d)}g(t)\\frac{f_{X}\\left(\\frac{t+d\\alpha}{\\alpha(1+r)}\\right)}{\\alpha(1+r)}dt}}_{\\text{parte continua}}}+{\\underbrace{{g(\\alpha(u-d))\\cdotp\\left[S_{X}\\left(\\frac{u}{1+r}\\right)\\right]}}_{\\text{parte discreta}}} \\end{equation*}\\] Lo cual nos puede decir de forma general cómo calcular momentos de \\(Y\\). Si nosotros queremos eliminar una cobertura en particular basta con sustituir los siguientes valores: Para eliminar el deducible \\(\\rightarrow {d}=0\\) Para eliminar el m.m.b.\\(\\rightarrow{u}=\\infty\\) Para eliminar el coaseguro \\(\\rightarrow{\\alpha}=1\\) Para eliminar la inflación \\(\\rightarrow{r}=0\\) Haciendo esto hemos generalizado en una sola forma todas las coberturas vistas. Por ejemplo, si de esta quisiéramos obtener la función de densidad de una cobertura solo con coaseguro: De la general: \\[\\begin{equation*} f_{Y}(t) = \\left \\{ \\begin{matrix} F_{X}\\left(\\frac{d}{1+r}\\right) &amp; \\mbox{si }&amp; t=0\\quad(discreta) \\\\ \\frac{f_{X}\\left(\\frac{t+d\\alpha}{\\alpha(1+r)}\\right)}{\\alpha(1+r)} &amp; \\mbox{si }&amp; t\\in (0,\\alpha(u-d))\\quad(continua) \\\\ S_{X}\\left(\\frac{u}{(1+r)}\\right)&amp;\\mbox{si}&amp;t=\\alpha(u-d)\\quad(discreta) \\\\ 0 &amp;\\mbox{en otro caso.} \\end{matrix}\\right. \\end{equation*}\\] Tomamos \\(u=\\infty;d=0;r=0\\) \\[\\begin{equation*} = \\left \\{ \\begin{matrix} {F_{X}(0)} &amp; \\mbox{si }&amp; t=0\\quad(discreta) \\\\ \\frac{f_{X\\left(\\frac{t}{\\alpha}\\right)}}{\\alpha} &amp; \\mbox{si }&amp; t\\in (0,\\infty)\\quad(continua) \\\\ {S_{X}(\\infty)}&amp;\\mbox{si}&amp;t=\\infty\\quad(discreta) \\\\ 0 &amp;\\mbox{en otro caso.} \\end{matrix}\\right. \\end{equation*}\\] \\[\\begin{equation*} =\\frac{1}{\\alpha}f_{X}\\left(\\frac{t}{\\alpha}\\right)\\quad\\text{si}\\quad t\\in(0,\\infty)\\quad{\\left \\{\\begin{matrix} \\text{El intervalo se ajustará}\\\\ \\text{con la indicadora que}\\\\ \\text{lleva $f_X $ dentro}\\end{matrix}\\right.} \\end{equation*}\\] Otro ejemplo, si quisiéramos obtener la función de densidad para una cobertura de nada más la inflación: De la general: \\[\\begin{equation*} f_{Y}(t) = \\left \\{ \\begin{matrix} F_{X}\\left(\\frac{d}{1+r}\\right) &amp; \\mbox{si }&amp; t=0\\quad(discreta) \\\\ \\frac{f_{X}\\left(\\frac{t+d\\alpha}{\\alpha(1+r)}\\right)}{\\alpha(1+r)} &amp; \\mbox{si }&amp; t\\in (0,\\alpha(u-d))\\quad(continua) \\\\ S_{X}\\left(\\frac{u}{1+r}\\right)&amp;\\mbox{si}&amp;t=\\alpha(u-d)\\quad(discreta) \\\\ 0 &amp;\\mbox{en otro caso.} \\end{matrix}\\right.\\\\ \\end{equation*}\\] Tomamos \\(u=\\infty;d=0;\\alpha=1\\) \\[\\begin{equation*} = \\left \\{ \\begin{matrix} {F_{X}(0)} &amp; \\mbox{si }&amp; t=0\\quad(discreta) \\\\ \\frac{f_{X}\\left(\\frac{t}{1+r}\\right)}{1+r} &amp; \\mbox{si }&amp; t\\in (0,\\infty)\\quad (continua) \\\\ {S_{X}(\\infty)}&amp;\\mbox{si}&amp;t=\\infty\\quad(discreta) \\\\ 0 &amp;\\mbox{en otro caso.} \\end{matrix}\\right. \\end{equation*}\\] \\[\\begin{equation*} =\\frac{1}{1+r}f_{X}\\left(\\frac{t}{1+r}\\right)\\quad\\text{si}\\quad t\\in(0,\\infty)\\quad{\\left \\{\\begin{matrix} \\text{El intervalo se ajustará}\\\\ \\text{con la indicadora que}\\\\ \\text{lleva $f_X $ dentro}\\end{matrix}\\right.} \\end{equation*}\\] Como último ejemplo, si quisiéramos obtener la función de densidad de una cobertura únicamente con deducible y monto máximo de beneficio: De la general: \\[\\begin{equation*} f_{Y}(t) =\\left \\{ \\begin{matrix} F_{X}\\left(\\frac{d}{1+r}\\right) &amp; \\mbox{si }&amp; t=0\\quad(discreta) \\\\ \\frac{f_{X}\\left(\\frac{t+d\\alpha}{\\alpha(1+r)}\\right)}{\\alpha(1+r)} &amp; \\mbox{si }&amp; t\\in (0,\\alpha(u-d))\\quad(continua) \\\\ S_{X}\\left(\\frac{u}{1+r}\\right)&amp;\\mbox{si}&amp;t=\\alpha(u-d)\\quad(discreta) \\\\ 0 &amp;\\mbox{en otro caso.} \\end{matrix}\\right.\\\\ \\end{equation*}\\] Tomamos \\(\\alpha=1;r=0\\) \\[\\begin{equation*} = \\left \\{ \\begin{matrix} F_{X}(d) &amp; \\mbox{si }&amp; t=0\\quad(discreta) \\\\ f_{X}(t+d) &amp; \\mbox{si }&amp; t\\in (0,(u-d))\\quad(continua) \\\\ S_{X}(u)&amp;\\mbox{si}&amp;t=(u-d)\\quad(discreta) \\\\ 0 &amp;\\mbox{en otro caso.} \\end{matrix}\\right. \\end{equation*}\\] Generalizando así todos los casos que ya vimos y otros particulares. Adicionalmente, si observamos cómo obtuvimos la función de densidad de \\({Y}\\) vamos a observar que también se calculó su función de distribución acumulada: \\[\\begin{equation*} F_{Y}(t)\\ \\ddot{=}\\ \\mathbb{P}[Y\\leq t]= \\left \\{ \\begin{matrix} 0 &amp; \\mbox{si }&amp; t&lt;0 \\\\ F_{X}\\left(\\frac{d}{1+r}\\right) &amp; \\mbox{si }&amp; t=0 \\\\ F_{X}\\left(\\frac{d}{1+r}\\right)+\\int_0^t\\frac{f_{X}\\left(\\frac{x+d\\alpha}{\\alpha(1+r)}\\right)}{\\alpha(1+r)}dx &amp;\\mbox{si}&amp;t\\in(0,\\alpha(u-d)) \\\\ 1 &amp;\\mbox{si}&amp;t\\geq\\alpha(u-d) \\end{matrix}\\right. \\end{equation*}\\] \\[\\begin{eqnarray*} \\int_0^t\\frac{f_X\\left(\\frac{x+d\\alpha}{\\alpha(1+r)}\\right)}{\\alpha(1+r)}dx&amp;=&amp;\\int_{\\frac{d}{1+r}}^{\\frac{t+d\\alpha}{\\alpha(1+r)}}f_X(s)ds\\quad \\begin{matrix} &amp;\\text{Cambio de variable}\\\\ &amp;s=\\frac{s+d\\alpha}{\\alpha(1+r)}\\Rightarrow ds=\\frac{1}{\\alpha(1+r)}dx\\\\ &amp;x=0\\Rightarrow s=\\frac{d}{1+r}\\\\ &amp;x=t\\Rightarrow s=\\frac{t+d\\alpha}{\\alpha(1+r)} \\end{matrix}\\\\ &amp;\\ddot{=}&amp;\\mathbb{P}\\left[\\frac{d}{1+r}\\leq X \\leq \\frac{t+d\\alpha}{\\alpha(1+r)}\\right]\\\\ &amp;=&amp;F_X\\left(\\frac{t+d\\alpha}{\\alpha(1+r)}\\right)-F_X\\left(\\frac{d}{1+r}\\right) \\end{eqnarray*}\\] Por lo tanto: \\[\\begin{equation*} F_{Y}(t)\\ \\ddot{=}\\ \\mathbb{P}[Y\\leq t]=\\left \\{\\begin{matrix} 0 &amp;\\mbox{si}&amp;t&lt;0\\\\ F_{X}\\left(\\frac{t+{d}{\\alpha}}{\\alpha(1+{r})}\\right)&amp;\\mbox{si}&amp;t\\in[0,{\\alpha}({d})]\\\\ 1&amp;\\mbox{si}&amp; t\\geq{\\alpha}({u}-{d}) \\end{matrix}\\right. \\end{equation*}\\] "],["severidad-costo-por-pérdida-y-por-pago.html", "Capítulo 7 Severidad (Costo por pérdida y por pago) 7.1 Costo por pago 7.2 Cuantiles para las coberturas", " Capítulo 7 Severidad (Costo por pérdida y por pago) 7.1 Costo por pago Usando la notación de la SOA (Society of Actuaries), las variables aleatorias del pago de una aseguradora (\\(Y\\)) que hemos visto son denotadas como \\(Y_L\\) refiriéndose al costo por pérdida (cost per loss). Existe una v.a. derivada de \\(Y_L\\) llamada costo por pago (cost per payment) definida como: \\[\\begin{equation*} Y_P \\ \\ddot{=}\\ Y_L| Y_L &gt;0 \\end{equation*}\\] Que se puede interpretar como el pago que la aseguradora haría de verse forzada a pagar pues el siniestro ya alcanzó su umbral de pago. Por ejemplo, en el caso particular de \\(Y_L\\) con cobertura de deducible, entonces: \\[\\begin{equation*} Y_P\\ \\ddot{=}\\ Y_L|Y_L&gt;0=Y_L|X&gt;d \\end{equation*}\\] Que querría decir, condicionado a que el siniestro superó el deducible. Pues \\(Y_L \\equiv 0\\) si \\(X \\leq d\\). Nota: \\(Y_p&gt;0\\) siempre pues \\(Y_L\\) es siempre positiva y más aún, \\(Y_p\\ \\ddot{=}\\ Y_L|Y_L&gt;0\\), es decir, es un valor aleatorio condicionado a que dicho valor es estrictamente positivo. Teniendo definida la variable aleatoria \\(Y_p\\), vamos a obtener su función de densidad. Haremos esto para la versión generalizada de \\(Y_L\\), la cuál es teniendo todas las coberturas. Esto hará que \\(Y_p\\) sea una v.a. mixta ya que, por definición,\\(Y_P\\ \\ddot{=}\\ Y_L|Y_L&gt;0\\) son valores que toma \\(Y_L\\) solo que “asumiendo” que \\(Y_L\\) es ya positiva y recordemos que esta versión generalizada es continua en (\\(0,\\alpha(u-d)\\)) y discreta en \\(\\alpha(u-d)\\). Procedemos aplicando el teorema de probabilidad total y tomando \\(t \\in (0,\\alpha(u-d))\\): \\[\\begin{eqnarray*} \\mathbb{P}[Y_L\\leq t]&amp;=&amp;\\mathbb{P}[\\underbrace{Y_L\\leq t | Y_L&gt;0}_{Y_p\\leq t}]\\mathbb{P}[Y_L&gt;0]+{\\mathbb{P}[Y_L\\leq t|Y_L\\equiv 0]}\\mathbb{P}[Y_L\\equiv 0]\\\\ &amp;=&amp;\\mathbb{P}[Y_p\\leq t]\\mathbb{P}[Y_L&gt;0]+\\mathbb{P}[Y_L\\equiv 0]\\\\ F_{Y_L}(t)&amp;=&amp;F_{Y_p}(t)S_{Y_L}(0)+f_{Y_L}(0)\\Leftrightarrow F_{Y_p}(t)=\\frac{F_{Y_L}(t)-f_{Y_L}(0)}{S_{Y_L}(0)}\\\\ \\therefore F_{Y_p}(t)&amp;=&amp;\\frac{F_{Y_L}(t)-f_{Y_L}(0)}{1-F_{Y_L}(0)}=\\frac{F_{Y_L}(t)-f_{Y_L}(0)}{1-f_{Y_L}(0)}\\quad\\forall t\\in(0,\\alpha(u-d)) \\end{eqnarray*}\\] Como estamos en la parte continua de \\(Y_p\\) podemos tomar la derivada y así: \\[\\begin{eqnarray*} f_{Y_p}(t)=\\frac{f_{Y_L}(t)}{1-f_{Y_L}(0)}\\quad\\forall t \\in(0,\\alpha(u-d)) \\end{eqnarray*}\\] Vamos a ver qué sucede en la parte discreta de \\(Y_p\\), ie, en el punto \\(\\alpha(u-d)\\): \\[\\begin{eqnarray*} f_{Y_p}(\\alpha(u-d))=\\mathbb{P}[Y_p\\equiv \\alpha(u-d)]&amp;\\ddot{=}&amp;\\mathbb{P}[Y_L\\equiv \\alpha(u-d)|Y_L&gt;0]\\\\ &amp;=&amp;\\frac{\\mathbb{P}[\\{Y_L\\equiv \\alpha(u-d)\\}\\bigcap\\{Y_L&gt;0\\}]}{\\mathbb{P}[Y_L&gt;0]}\\\\ &amp;=&amp;\\frac{\\mathbb{P}[Y_L\\equiv\\alpha(u-d)]}{\\mathbb{P}[Y_L&gt;0]}=\\frac{f_{Y_L}(\\alpha(u-d))}{S_{Y_L}(0)} \\end{eqnarray*}\\] De tal manera que podemos unir los dos casos y así escribir que: \\[\\begin{equation*} f_{Y_p}(t)=\\frac{f_{Y_L}(t)}{1-f_{Y_L}(0)}\\mathbb{I}_{(0,\\alpha(u-d)]}(t)\\left\\} \\begin{matrix} \\mbox{Esto sucede si}\\\\ \\mathbb{P}[Y_L\\equiv0]&gt;0.\\\\ \\mbox{En otro caso }\\quad Y_p\\overset{d}{=}Y_L. \\end{matrix}\\right. \\end{equation*}\\] Que en términos del monto del siniestro (\\(X\\)) queda: \\[\\begin{equation*} f_{Y_p}(t)=\\left \\{ \\begin{matrix} \\frac{f_{X}\\left(\\frac{t+d\\alpha}{(1+r)\\alpha}\\right)}{\\alpha(1+r)S_{X} \\left(\\frac{d}{1+r}\\right)}&amp;\\mbox{si}&amp;t\\in(0,\\alpha(u-d))\\quad (continua)\\\\ \\frac{S_{X}\\left(\\frac{u}{1+r}\\right)}{S_{X}\\left(\\frac{d}{1+r}\\right)}&amp;\\mbox{si}&amp;t=\\alpha(u-d)\\quad(discreta)\\\\ 0&amp;\\mbox{en otro caso.}&amp; \\end{matrix}\\right. \\end{equation*}\\] Con base a el costo por pérdida (\\(Y_L\\)), la función de distribución acumulada del costo por pago (\\(Y_p\\)) es: \\[\\begin{equation*} F_{Y_p}(t)=\\left \\{ \\begin{matrix} 0 &amp;\\mbox{si}&amp; t\\leq 0\\\\ \\frac{F_{Y_L}(t)-f_{Y_L}(0)}{1-f_{Y_L}(0)} &amp;\\mbox{si}&amp;t\\in(0,\\alpha(u-d)] \\end{matrix}\\right. \\end{equation*}\\] Que en términos del monto del siniestro () queda: \\[\\begin{equation*} F_{Y_p}(t)\\left \\{ \\begin{matrix} 0 &amp;\\mbox{si}&amp; t\\leq 0\\\\ \\int_0^t\\frac{f_{X}\\left(\\frac{x+d\\alpha}{\\alpha(1+r)}\\right)}{\\alpha(1+r)S_{X}\\left(\\frac{d}{1+r}\\right)}dx&amp;\\mbox{si}&amp; t\\in(0,\\alpha(u-d))\\\\ 1 &amp;\\mbox{si}&amp; t\\geq \\alpha(u-d) \\end{matrix}\\right. \\end{equation*}\\] \\[\\begin{eqnarray*} \\int_0^t\\frac{f_X\\left(\\frac{x+d\\alpha}{(1+r)\\alpha}\\right)}{\\alpha(1+r)S_X(\\frac{d}{1+r})}dx&amp;=&amp;\\frac{1}{S_X\\left(\\frac{d}{1+r}\\right)}\\int_0^t\\frac{f_X\\left(\\frac{x+d\\alpha}{\\alpha(1+r)}\\right)}{\\alpha(1+r)}dx\\\\ &amp;=&amp;\\frac{1}{S_X\\left(\\frac{d}{1+r}\\right)}\\int^{\\frac{t+d\\alpha}{\\alpha(1+r)}}_{\\frac{d}{1+r}}f_X(s)ds \\left\\{ \\begin{matrix} \\mbox{Cambio de variable}\\\\ s=\\frac{x+d\\alpha}{\\alpha(1+r)}\\Rightarrow ds=\\frac{1}{\\alpha(1+r)}dx\\\\ x=0 \\Rightarrow s=\\frac{d}{1+r}\\\\ x=t\\Rightarrow s=\\frac{t+d\\alpha}{\\alpha(1+r)} \\end{matrix}\\right.\\\\ &amp;\\ddot{=}&amp;\\frac{\\mathbb{P}[\\frac{d}{1+r}\\leq X\\leq\\frac{t+d\\alpha}{\\alpha(1+r)}]}{S_X\\left(\\frac{d}{1+r}\\right)}=\\frac{F_X\\left(\\frac{t+d\\alpha}{\\alpha(1+r)}\\right)-F_X\\left(\\frac{d}{1+r}\\right)}{S_X\\left(\\frac{d}{1+r}\\right)} \\end{eqnarray*}\\] Por lo tanto: \\[\\begin{eqnarray*} F_{Y_p}(t)=\\left \\{ \\begin{matrix} 0 &amp;\\mbox{si}&amp; t\\leq 0\\\\ \\frac{F_{X}\\left(\\frac{t+d\\alpha}{\\alpha(1+r)}\\right)-F_{X}\\left(\\frac{d}{1+r}\\right)}{S_{X}\\left(\\frac{d}{1+´ r}\\right)}&amp;\\mbox{si}&amp; t\\in(0,\\alpha(u-d))\\\\ 1 &amp;\\mbox{si}&amp; t\\geq \\alpha(u-d) \\end{matrix}\\right. \\end{eqnarray*}\\] Recordemos que la ley de esperanza iterada establece que tomando \\(X,Y\\) v.a. entonces: \\[\\mathbb{E}[X]=\\mathbb{E}[\\mathbb{E}[X|Y]]\\] Nota: \\(\\mathbb{E}[X|Y]\\) es una v.a. que depende de los valores de \\(Y\\), podríamos decir que \\(\\mathbb{E}[X|Y]=g(Y)\\), su soporte viene dado por una transformación en el soporte de Y. Sea \\(\\mathscr{L}\\) una v.a. auxiliar definida como: \\[\\begin{equation*} \\mathscr{L}=\\left \\{ \\begin{matrix} 1 &amp;\\mbox{sii}&amp;Y_L\\equiv 0\\\\ 2 &amp;\\mbox{sii}&amp; Y_L&gt;0 \\end{matrix} \\right. \\end{equation*}\\] Noten que \\(\\mathscr{L}\\) es v.a. pues depende de una. De hecho, ésta es discreta con \\(sop\\{\\mathscr{L}\\}=\\{1,2\\}\\). Obtengamos ahora la esperanza de \\(Y_p\\) utilizando lo anterior. Llamemos \\(g(x)\\ \\ddot{=}\\ \\mathbb{E}[Y_L|\\mathscr{L}=x]\\), así: \\[\\begin{eqnarray*} \\mathbb{E}[Y_L]&amp;=&amp;\\mathbb{E}[\\mathbb{E}[Y_L|\\mathscr{L}]]=\\mathbb{E}[g(\\mathscr{L})]=\\sum_{k\\in sop\\{\\mathscr{L}\\}}g(k)\\mathbb{P}[\\mathscr{L}=k]\\\\ \\mathbb{E}[Y_L]&amp;=&amp; \\displaystyle\\sum_{k=1}^{2} g(k)\\mathbb{P}[\\mathscr{L}=k]\\\\ &amp;=&amp; \\sum_{k=1}^{2} \\mathbb{E}[Y_L|\\mathscr{L}=k] \\mathbb{P}[\\mathscr{L}=k]\\\\ &amp;=&amp; \\mathbb{E}[Y_L|\\mathscr{L}=1] \\mathbb{P}[\\mathscr{L}=1]+\\mathbb{E}[Y_L|\\mathscr{L}=2] \\mathbb{P}[\\mathscr{L}=2] \\end{eqnarray*}\\] El evento \\(\\mathscr{L}=1\\) es equivalente al evento \\(Y_{L}\\equiv 0\\). El evento \\(\\mathscr{L}=2\\) es equivalente al evento \\(Y_{L}&gt;0\\). \\[\\begin{eqnarray*} \\mathbb{E}[Y_L]&amp;=&amp; \\mathbb{E}[Y_L|Y_L\\equiv 0]\\mathbb{P}[Y_L \\equiv0]+\\mathbb{E}[Y_L|Y_L&gt; 0]\\mathbb{P}[Y_L &gt;0]\\\\ \\end{eqnarray*}\\] El valor esperado de algo que ya toma un valor no aleatorio, es dicho valor. \\[\\begin{eqnarray*} &amp;=&amp;\\underbrace{\\mathbb{E}[Y_L|Y_L&gt; 0]}_{Y_{p}} \\mathbb{P}[Y_L&gt;0]\\\\ &amp;=&amp;\\mathbb{E}[Y_{p}]\\mathbb{P}[Y_L&gt;0]\\\\ \\end{eqnarray*}\\] El resultado general anterior se conoce como “Ley de la Partición” o “Ley de Esperanza Total”. Tomando \\(\\{B_{i}\\}\\) partición de \\(\\Omega\\). \\(\\mathbb{E}[X] = \\sum_{\\forall i} {\\mathbb{E}[X|{B_{i}}]\\mathbb{P}[{B_{i}}]}\\) Por lo tanto: \\[\\begin{eqnarray*} \\mathbb{E}[Y_{p}]&amp;=&amp; \\frac{\\mathbb{E}[Y_{L} ]}{\\mathbb{P}[Y_{L}&gt;0]}\\\\ &amp;=&amp; \\frac{\\alpha(1+r)}{S_{X}\\left( \\frac{d }{1+r} \\right)} \\int_{\\frac{d}{1+r}}^{\\frac{u}{1+r}} S_{X} (t) dt \\end{eqnarray*}\\] En general, dada una función \\(h: \\mathbb{R}\\mapsto \\mathbb{R}\\) ¿Qué significa tomar \\(h(Y_{p})\\)? \\(Y_{p} \\ddot{=} Y_{L}|Y_{L}&gt;0\\), es decir, son valores aleatorios positivos provenientes de una v.a subyacente \\(Y_{L}\\). Entonces, aplicarle una función a \\(Y_{p}\\) (y en general a una v.a condicionadas a algo) significa por definición. \\[\\begin{eqnarray*} h(Y_{p}) &amp;\\ddot{=}&amp; h(Y_{L})| Y_{L}&gt;0\\\\ \\end{eqnarray*}\\] Es decir que es aplicarle ``h”, a los valores positivos que se obtuvieron. Tomando esto en cuenta, ya podemos saber cómo obtener momentos de \\(Y_{p}\\). En una versión “simplificada” de lo anterior, si deseamos obtener momentos de \\(Y_{p}\\): \\[\\begin{eqnarray*} \\mathbb{E}[Y_{L}^{k}]= \\mathbb{E}[\\mathbb{E}[Y_{L}^{k}|Y_{L}]]= \\mathbb{E}[Y_{L}^{k}]\\mathbb{P}[Y_{L} \\equiv 0]+\\mathbb{E}[Y_{L}^{k}|Y_{L}&gt;0]\\mathbb{P}[Y_{L}&gt;0]\\\\ \\end{eqnarray*}\\] \\[\\begin{equation*} \\mathbb{E}[Y_{L}^{k}| Y_{L} \\equiv 0] = \\mathbb{E}[0^{k}] =\\mathbb{E}[0] =0 \\end{equation*}\\] \\[\\begin{equation*} \\mathbb{E}[Y_{L}^{k}| Y_{L} &gt;0]\\ \\ddot{=}\\ \\mathbb{E}[Y_{p}^{k}] \\end{equation*}\\] \\[\\begin{eqnarray*} \\mathbb{E}[Y_{L}^{k}] = \\mathbb{E}[Y_{p}^{k}]\\cdot \\mathbb{P}[Y_{L}&gt;0]\\\\ \\end{eqnarray*}\\] Por lo tanto: \\[\\begin{eqnarray*} \\mathbb{E}[Y_{p}^k] &amp;=&amp; \\frac{\\mathbb{E} [Y_{L}^k] }{\\mathbb{P} [Y_{L}&gt;0]}\\\\ &amp;=&amp; \\frac{\\mathbb{E}[Y_{L}^k]}{ 1-f_{Y_{L}}(0) } \\quad \\quad \\forall k \\in\\mathbb{N} \\end{eqnarray*}\\] De donde ya sabemos obtener momento en general para \\(Y_{L}\\). 7.2 Cuantiles para las coberturas Una vez construido todo en esta sección, es el momento de mostrar un teorema interesante aunque poco mencionado por varios autores: Sea \\(X\\) una v.a y \\(Sop\\){\\(X\\)} su soporte. Tomando \\(\\phi\\) una función no-decreciente al menos \\(\\forall x \\in Sop\\){\\(X\\}\\) , entonces: \\[\\begin{eqnarray*} q_{\\varphi(X)}(\\alpha)= \\varphi ( q_{X}(\\alpha)) \\end{eqnarray*}\\] Nota: \\(\\varphi(X)\\) es una v.a que depende de \\(X\\). Notemos ahora que todas las variables aleatorias de cobertura que construimos son funciones no-decrecientes de un monto de siniestro . Esto por la simple lógica en su construcción de ``A mayor el monto de siniestro, el pago de la aseguradora no puede disminuir”.\\ Aplicando el teorema a la v.a generalizada de perdida por una cobertura completa (coaseguro, inflación, etc): \\[\\begin{eqnarray*} Y_{L} =máx\\{\\alpha(mín\\{ X(1+r), u\\}- d), 0 \\}\\\\ \\end{eqnarray*}\\] Entonces los cuantiles del \\(\\gamma \\in [0,1]\\) de \\(Y_{L}\\) estarán dados por: \\[\\begin{eqnarray*} q_{Y_{L}}(\\gamma)&amp;=&amp; máx \\{ \\alpha (mín\\{q_{X}(\\gamma)(1+r),u\\})- d),0\\} \\quad \\forall \\gamma \\in [0,1] \\end{eqnarray*}\\] Adicionalmente, si quisiéramos obtener los cuantiles de \\(Y_{p}\\) podríamos obtenerlos de los de \\(Y_{L}\\) haciendo: \\[\\begin{eqnarray*} \\gamma&amp;=&amp; F_{Y_{p}}(x)\\\\ &amp;=&amp; \\frac{F_{Y_{L}}(x)-f_{Y_{L}}(0)}{1-f_{Y_{L}}(0)} \\end{eqnarray*}\\] Sí y solo si: \\[\\begin{eqnarray*} F_{Y_{L}}(x)=(1-f_{Y_{L}}(0))\\gamma + f_{Y_{L}}(0) \\end{eqnarray*}\\] Sí y solo si: \\[\\begin{eqnarray*} x&amp;=&amp; q_{Y_{p}}(\\gamma)\\\\ &amp;=&amp; q_{Y_{L}}((1-f_{Y_{L}}(0))\\gamma + f_{Y_{L}})(0)\\\\ \\end{eqnarray*}\\] De donde se deduce que los cuantiles de \\(Y_{p}\\) vienen dados por los de \\(Y_{L}\\) en función del segmento de recta. \\[\\begin{eqnarray*} \\textit{L}&amp;=&amp;\\{\\beta \\in [0,1]: \\beta =(1-f_{Y_{L}}(0)\\gamma + f_{Y_{L}}(0) \\quad \\textit{con} \\quad \\gamma \\in [0,1]) \\}\\\\ \\end{eqnarray*}\\] Esto significa que, mientras \\(Y_{L}\\) tiene un rango de probabilidades \\([0,1]\\) de manera “libre” . \\(Y_{p}\\) se encuentra atrapada en un universo ``más pequeño” que \\(Y_{L}\\) sin siquiera notarlo. De hecho: \\[\\begin{eqnarray*} \\text{Si }\\gamma =0 \\text{, entonces:} \\end{eqnarray*}\\] \\[\\begin{eqnarray*} q_{Y_{p}}(\\gamma)&amp;=&amp;q_{Y_{L}}( (1-f_{Y_{L}}(0))\\gamma + f_{Y_{L}} (0))\\\\ &amp;=&amp; q_{Y_{L}}(f_{Y_{L}}(0))\\\\ &amp;=&amp; q_{Y_{L}}(F_{Y_{L}}(0))\\\\ &amp;=&amp; 0\\\\ \\end{eqnarray*}\\] Nota: \\(0 \\notin Sop\\{ Y_{p}\\}\\) pero sí es ínfimo de su soporte. \\[\\begin{eqnarray*} \\text{Si }\\gamma =1 \\text{, entonces:} \\end{eqnarray*}\\] \\[\\begin{eqnarray*} q_{Y_{p}}(\\gamma)&amp;=&amp;q_{Y_{L}}( (1-f_{Y_{L}}(0))\\gamma + f_{Y_{L}} (0))\\\\ &amp;=&amp; q_{Y_{L}}(1)\\\\ &amp;=&amp; \\alpha (u-d) \\\\ \\end{eqnarray*}\\] Por lo tanto: \\[\\begin{eqnarray*} q_{Y_{p}}(\\gamma)&amp;=&amp;q_{Y_{L}}( (1-f_{Y_{L}}(0))\\gamma + f_{Y_{L}} (0)) \\quad \\forall \\gamma \\in [0,1]\\\\ \\end{eqnarray*}\\] Si ponemos el segmento de recta en función del monto de siniestro (X): \\[\\begin{eqnarray*} (1-f_{Y_{L}}(0))\\gamma + f_{Y_{L}} (0) &amp;=&amp; \\left(1-F_{X}\\left(\\frac{d}{1+r}\\right)\\right)\\gamma + F_{X}\\left(\\frac{d}{1+r }\\right)\\\\ \\end{eqnarray*}\\] Entonces: \\[\\begin{eqnarray*} q_{Y_{p}}(\\gamma) &amp;=&amp; \\left(1-F_{X}\\left(\\frac{d}{1+r }\\right)\\right)\\gamma + F_{X}\\left(\\frac{d}{1+r }\\right) \\quad \\forall \\gamma \\in [0,1] \\\\ \\end{eqnarray*}\\] Finalmente , si ponemos a \\(q_{Y_{L}}\\) con la identidad proveniente del teorema de equivarianza en los cuantiles, obtendremos una identidad para \\(q_{Y_{p}} (\\gamma) \\quad \\forall \\gamma \\in [0,1]\\) en términos únicamente del monto de siniestro (X): \\[\\begin{eqnarray*} q_{Y_{p}}(\\gamma) &amp;=&amp; máx\\{\\alpha (mín\\{q_{X}(\\beta (\\gamma) )( 1+r ), u \\} -d ),0 \\} \\quad \\forall \\gamma \\in [0,1]\\\\ \\end{eqnarray*}\\] Donde: \\[\\beta(\\gamma) \\ddot{=} \\left(1-F_{X}\\left(\\frac{d}{1+r }\\right)\\right)\\gamma + F_{X}\\left(\\frac{d}{1+r }\\right) \\]. Ejemplo Supongamos que el monto de siniestros es \\(X \\sim Unif (100,200)\\). Consideremos con todas las coberturas: \\(\\alpha=75\\% , r=10\\%, d=120\\) y \\(u= 180\\). Para las v.a \\(Y_{L}\\) y \\(Y_{P}\\), obtenga: La función de densidad. La función de distribución acumulada. Valor esperado. Segundo momento. La varianza. El valor esperado del coseno de la v.a. . La mediana. El cuantil del \\(90\\%\\). Sabemos que: \\[\\begin{eqnarray*} f_{X}(t)&amp;=&amp; \\frac{1}{100} \\mathbb{I}_{(100,200)} (t)\\\\ F_{X}(t)&amp;=&amp; \\frac{t-100}{100} \\mathbb{I}_{(100,200)} (t)\\\\ S_{X}(t)&amp;=&amp; \\frac{200-t}{100} \\mathbb{I}_{(100,200)} (t)\\\\ \\end{eqnarray*}\\] Con base en los resultados obtenidos en esta sección del curso, resolveremos primero para \\(Y_{L}\\) y luego para \\(Y_{p}\\). Soluciones para \\(Y_{L}\\): \\(i\\)) La función de densidad. \\[\\begin{eqnarray*} {\\large f_{Y_{L}}(t) = \\left\\{ \\begin{array}{lcc} F_{\\chi}(\\frac{d}{1+r}) &amp; si &amp; t=0\\ (discreta)\\\\\\\\ \\frac{f_{\\chi}(\\frac{t+d\\alpha}{\\alpha(1+r)})}{\\alpha(1+r)} &amp; si &amp; t\\in(0,\\alpha(u-d)) \\ (continua)\\\\\\\\ S_{\\chi}(\\frac{u}{1+r}) &amp; si &amp; t=\\alpha(u-d) \\ (discreta)\\\\\\\\ 0 &amp; en\\ otro\\ caso\\\\ \\end{array} \\right.\\\\\\\\\\\\\\\\ =\\left\\{ \\begin{array}{lcc} \\frac{\\frac{120}{1.1}-100}{100}=\\frac{1}{11} &amp; si &amp; t=0\\\\\\\\ \\frac{1}{0.75(1.1)}(\\frac{1}{100})=\\frac{2}{165} &amp; si &amp; t\\in(0,0.75(180-120)=45)\\\\\\\\ \\frac{200-\\frac{180}{1.1}}{100}=\\frac{4}{11} &amp; si &amp; t=45\\\\\\\\ 0 &amp; en\\ otro\\ caso\\\\ \\end{array} \\right. } \\end{eqnarray*}\\] \\(ii\\)) La función de distribución acumulada. \\[\\begin{eqnarray*} {\\large F_{Y_{L}}(t) = \\left\\{ \\begin{array}{lcc} 0 &amp; si &amp; t&lt;0\\\\\\\\ F_{\\chi}(\\frac{t+d\\alpha}{\\alpha(1+r)}) &amp; si &amp; t\\in[0,\\alpha(u-d))\\\\\\\\ 1 &amp; si &amp; t\\geq\\alpha(u-d)\\\\ \\end{array} \\right.\\\\ =\\left\\{ \\begin{array}{lcc} 0 &amp; si &amp; t&lt;0\\\\\\\\ \\frac{\\frac{t+120(75\\%)}{75\\%(1.1)}-100}{100} = \\frac{\\frac{t}{0.825}+\\frac{100}{11}}{100} &amp; si &amp; t\\in[0,45)\\\\\\\\ 1 &amp; si &amp; t\\geq45\\\\ \\end{array} \\right.\\\\ } \\end{eqnarray*}\\] \\(iii\\)) Valor esperado. \\[\\begin{eqnarray*} \\mathbb E [Y_{L}] &amp;=&amp; \\alpha(1+r) \\int_{\\frac{d}{1+r}}^{\\frac{u}{1+r}} S_{\\chi}(t)dt = 0.75(1.1)\\int_{\\frac{120}{1.1}}^{\\frac{180}{1.1}} \\frac{200-t}{100} dt \\\\ &amp;=&amp; \\frac{315}{11} = 28.636\\bar{3}\\\\ \\end{eqnarray*}\\] \\(iv\\)) Segundo momento. \\[\\begin{eqnarray*} \\mathbb E[g(Y_{L})] = g(0)[F_{\\chi}(\\frac{d}{1+r})]+ \\int_{0}^{\\alpha (u-d)} g(t) \\frac{f_{\\chi}(\\frac{1+d\\alpha}{\\alpha(1+r)})}{\\alpha(1+r)} dt + g(\\alpha(u-d)) \\cdot [S_{\\chi} (\\frac{u}{1+r})]\\\\ \\end{eqnarray*}\\] \\[\\begin{eqnarray*} \\mathbb E[Y_{L}^{2}] = 0^2(\\frac{1}{11})+\\int_{0}^{45} t^{2} (\\frac{2}{165})dt + 45^{2}(\\frac{4}{11}) = \\frac{12150}{11} = 1104.545\\bar{4}\\\\ \\end{eqnarray*}\\] \\(v\\)) La varianza. \\[\\begin{equation*} Var(Y_{L})=\\mathbb E[Y_{L}^{2}] - \\mathbb E^{2}[Y_{L}] = \\frac{34425}{121} \\approx 284.5041322\\\\ \\end{equation*}\\] \\(vi\\)) El valor esperado del coseno de la v.a. \\[\\begin{equation*} \\mathbb E[cos(Y_{L})] = cos(0)(\\frac{1}{11})+\\int_{0}^{45} cos(t)(\\frac{2}{165})dt + cos(45)(\\frac{4}{11}) \\approx 0.29224925\\\\ \\end{equation*}\\] \\(vii\\)) La mediana. \\[\\begin{eqnarray*} q_{Y_{L}}(\\gamma) = max\\{\\alpha(min\\{q_{\\chi}(\\gamma)(1+r),u\\}-d),0\\}\\\\ \\end{eqnarray*}\\] Obtengamos \\(q_{\\chi}(0.5)\\) la medianda de \\(\\chi\\)} \\[\\begin{eqnarray*} 0.5 = F_{\\chi}(\\chi_{0}) = \\frac{\\chi_{0}-100}{100} \\Longleftrightarrow \\chi_{0} = 150 = q_{\\chi}(0.5)\\\\ \\end{eqnarray*}\\] \\[\\begin{eqnarray*} \\longrightarrow q_{Y_{L}}(0.5) &amp;=&amp; max\\{0.75(min\\{q_{\\chi}(0.5)(1.1),180\\}-120),0\\}\\\\ &amp;=&amp; max\\{0.75(min\\{150(1.1),180\\}-120),0\\}\\\\ &amp;=&amp; max\\{0.75(min\\{165,180\\}-120),0\\}\\\\ &amp;=&amp; max\\{0.75(165-120),0\\}\\\\ &amp;=&amp; max\\{0.75(45),0\\}\\\\ &amp;=&amp; max\\{33.75,0\\}=33.75\\\\ \\end{eqnarray*}\\] \\(viii\\)) El cuantil del 90%. Obtengamos el cuantil \\(q_{\\chi}(0.9)\\): \\[\\begin{eqnarray*} 0.9 = F_{\\chi}(\\chi_{0}) = \\frac{\\chi_{0}-100}{100} \\Longleftrightarrow \\chi_{0} = q_{\\chi}(0.9) = 190 \\\\ \\end{eqnarray*}\\] \\[\\begin{eqnarray*} \\longrightarrow q_{Y_{L}}(0.9) &amp;=&amp; max\\{0.75(min\\{q_{\\chi}(0.9)(1.1),180\\}-120),0\\}\\\\ &amp;=&amp; max\\{0.75(min\\{190(1.1),180\\}-120),0\\}\\\\ &amp;=&amp; 45\\\\ \\end{eqnarray*}\\] Soluciones para \\(Y_{p}\\) \\(i\\)) La función de densidad. \\[\\begin{eqnarray*} f_{Y_{p}}(t) &amp;=&amp; \\left\\{ \\begin{array}{lcc} \\frac{f_{\\chi}(\\frac{t+d\\alpha}{(1+r)\\alpha})}{\\alpha(1+r)S_{\\chi}(\\frac{d}{1+r})} &amp; si &amp; t\\in(0,\\alpha(u-d)) \\ (continua)\\\\\\\\ \\frac{S_{\\chi}(\\frac{u}{1+r})}{S_{\\chi}(\\frac{d}{1+r})} &amp; si &amp; t=\\alpha(u-d) \\ (discreta)\\\\\\\\ 0 &amp; en\\ otro\\ caso\\\\ \\end{array} \\right.\\\\\\\\ &amp;=&amp;\\left\\{ \\begin{array}{lcc} \\frac{\\frac{1}{100}}{0.75(1.1)(\\frac{10}{11})} = \\frac{1}{75} &amp; si &amp; t\\in(0,45)\\\\\\\\ \\frac{\\frac{200-\\frac{180}{1.1}}{100}}{\\frac{10}{11}} = \\frac{2}{5} &amp; si &amp; t=45\\\\\\\\ 0 &amp; en\\ otro\\ caso\\\\ \\end{array} \\right.\\\\ \\end{eqnarray*}\\] \\(ii\\)) La función de distribución acumulada. \\[\\begin{eqnarray*} F_{Y_{p}}(t)&amp;=&amp; \\left\\{ \\begin{array}{lcc} 0 &amp; si &amp; t\\leq0\\\\\\\\ \\frac{F_{\\chi}(\\frac{t+d\\alpha}{\\alpha(1+r)})-F_{\\chi}(\\frac{d}{1+r})} {S_{\\chi}(\\frac{d}{1+r})} &amp; si &amp; t\\in(0,\\alpha(u-d))\\\\\\\\ 1 &amp; si &amp; t\\geq\\alpha(u-d)\\\\ \\end{array} \\right.\\\\\\\\ &amp;=&amp;\\left\\{ \\begin{array}{lcc} 0 &amp; si &amp; t\\leq0\\\\\\\\ \\frac{\\frac{\\frac{t}{0.825}+\\frac{100}{11}}{100}-\\frac{1}{11}}{\\frac{10}{11}} = \\frac{\\frac{t}{82.5}}{\\frac{10}{11}} = \\frac{11t}{825} &amp; si &amp; t\\in(0,45)\\\\\\\\ 1 &amp; si &amp; t\\geq45\\\\ \\end{array} \\right.\\\\ \\end{eqnarray*}\\] \\(iii\\)) Valor esperado. \\[\\begin{equation*} \\mathbb E [Y_{p}] = \\frac{\\mathbb E [Y_{L}]} {\\mathbb P [Y_{L}&gt;0]} = \\frac{\\frac{315}{11}}{\\frac{10}{11}}=\\frac{315}{10}=31.4\\\\ \\end{equation*}\\] \\(iv\\)) Segundo momento. \\[\\begin{equation*} \\mathbb E [Y_{p}^{k}] = \\frac{\\mathbb E [Y_{L}^{k}]} {\\mathbb P [Y_{L}&gt;0]}\\\\ \\longrightarrow \\mathbb E [Y_{p}^{2}] = \\frac{\\mathbb E [Y_{L}^{2}]}{\\mathbb P [Y_{L}&gt;0]} = \\frac{\\frac{12150}{11}}{\\frac{10}{11}} = 1215\\\\ \\end{equation*}\\] \\(v\\)) La varianza. \\[\\begin{equation*} Var(Y_{p})=\\mathbb E[Y_{p}^{2}] - \\mathbb E^{2}[Y_{p}] = \\frac{894}{4} = 222.75\\\\ \\end{equation*}\\] \\(vi\\)) El valor esperado del coseno de la v.a. De hecho, en general tomando \\(h:\\mathbb R \\longrightarrow \\mathbb R\\) función tal que las cantidades expresadas existan. Siempre se satisface que cuando \\(\\mathbb P [Y_{L}=0] \\equiv f_{Y_{L}}(0)\\): \\[\\begin{equation*} \\mathbb E [h(Y_{L})] = h(0) f_{Y_{L}}(0) + \\mathbb E[h(Y_{p})](1-f_{Y_{L}}(0)) \\\\ \\end{equation*}\\] La prueba queda como ejercicio para el lector. De donde obtenemos de forma general: \\[\\begin{equation*} \\mathbb E [h(Y_{p})] = \\frac{\\mathbb E [h(Y_{L})] - h(0) f_{Y_{L}}(0)} {1-f_{Y_{L}}(0)} = \\frac{\\mathbb E [h(Y_{L})] - h(0)F_{\\chi}(\\frac{d}{1+r})} {S_{\\chi}(\\frac{d}{1+r})} \\\\ \\end{equation*}\\] Entonces: \\[\\begin{equation*} \\mathbb E [cos(Y_{p})] = \\frac{\\mathbb E [cos(Y_{L})] - cos(0)F_{\\chi}(\\frac{d}{1+r})} {S_{\\chi}(\\frac{d}{1+r})} = \\frac{\\mathbb E [cos(Y_{L})] - \\frac{1}{11}} {\\frac{10}{11}} \\approx 0.2214741759\\\\ \\end{equation*}\\] O bien, por definición de esperanza: \\[\\begin{equation*} \\mathbb E [cos(Y_{p})] = \\int_{0}^{45} \\frac{cos(t)}{75}dt + cos(45)(\\frac{2}{5}) \\approx 0.2214741759\\\\ \\end{equation*}\\] \\(vii\\)) La mediana. \\[\\begin{eqnarray*} q_{Y_{p}}(\\gamma) = max\\{\\alpha(min\\{q_{\\chi}(\\beta(\\gamma))(1+r),u\\}-d),0\\}\\\\ \\end{eqnarray*}\\] \\[\\begin{eqnarray*} \\text{Donde: } \\beta(\\gamma)\\ \\ddot{=}\\ (1-F_{\\chi}(\\frac{d}{1+r}))\\gamma+F_{\\chi}(\\frac{d}{1+r})\\\\ \\end{eqnarray*}\\] \\[\\begin{eqnarray*} \\gamma = 0.5 \\longrightarrow \\beta(\\gamma) = (1-F_{\\chi}(\\frac{d}{1+r}))\\gamma+F_{\\chi}(\\frac{d}{1+r}) = \\frac{10}{11}(0.5)+\\frac{1}{11} = \\frac{6}{11}\\\\ \\end{eqnarray*}\\] \\[\\begin{eqnarray*} \\text{Note que: }q_{\\chi}(p) &amp;=&amp; p(100) +100 \\longrightarrow q_{\\chi}(\\frac{6}{11}) = \\frac{1700}{11} = q_{\\chi}(\\beta(\\gamma))\\\\ \\longrightarrow q_{Y_{p}}(\\gamma) &amp;=&amp;max\\{0.75(min\\{\\frac{1700}{11}(1.1),180\\}-120),0\\}\\\\ &amp;=&amp;max\\{0.75(min\\{170,180\\}-120),0\\}\\\\ &amp;=&amp;max\\{0.75(170-120),0\\}\\\\ &amp;=&amp;max\\{37.5,0\\}\\\\ &amp;=&amp;37.5\\\\ \\end{eqnarray*}\\] \\(viii\\)) El cuantil del 90%. \\[\\begin{eqnarray*} \\gamma = 0.9 \\longrightarrow \\beta(\\gamma) = (1-F_{\\chi}(\\frac{d}{1+r}))\\gamma+F_{\\chi}(\\frac{d}{1+r}) = \\frac{10}{11}(0.9)+\\frac{1}{11} = \\frac{10}{11}\\\\ \\end{eqnarray*}\\] \\[\\begin{eqnarray*} \\longrightarrow q_{\\chi}(\\beta(\\gamma)) = q_{\\chi}(\\frac{10}{11}) = 100(\\frac{10}{11}+1) = \\frac{2100}{11}\\\\ \\end{eqnarray*}\\] \\[\\begin{eqnarray*} \\text{Por lo tanto:}\\\\ q_{Y_{p}}(\\gamma) &amp;=&amp;max\\{0.75(min\\{\\frac{2100}{11}(1.1),180\\}-120),0\\}\\\\ &amp;=&amp;max\\{0.75(min\\{210,180\\}-120),0\\}\\\\ &amp;=&amp;max\\{0.75(180-120),0\\}\\\\ &amp;=&amp;max\\{45,0\\}=45\\\\ \\end{eqnarray*}\\] Script: “Coberturas”. "],["severidad-anexo.html", "Capítulo 8 Severidad Anexo Pago del asegurado con deducible y monto máximo de beneficio: Generalización del cálculo de variables esperadas para \\(Y_p\\). Generalización de la fórmula de Darth Vader. Más deducibles", " Capítulo 8 Severidad Anexo Pago del asegurado con deducible y monto máximo de beneficio: \\[\\begin{equation*} Z\\ \\ddot{=}\\ \\text{Lo que paga el asegurado}\\\\ X\\ \\ddot{=}\\ \\text{Monto del siniestro, }X \\in (a,b) \\end{equation*}\\] \\[\\begin{equation*} Z = \\left\\{ \\begin{array}{lcc} X &amp; si &amp; X&lt;d \\Longleftrightarrow Z\\in [a,d)\\\\\\\\ d &amp; si &amp; X\\in [d,u] \\Longleftrightarrow Z=d\\\\\\\\ X-u+d &amp; si &amp; X&gt;u \\Longleftrightarrow Z\\in(d,b-u+d]\\\\ \\end{array} \\right. \\end{equation*}\\] \\[\\begin{equation*} Z = máx\\{min\\{ X,d\\},X-(u-d)\\}\\\\ \\end{equation*}\\] \\[\\begin{equation*} \\text{Si }X&lt;d \\longrightarrow f_{z}(Z) = f_{X}(Z)\\ \\forall\\ Z \\in [a,d)\\\\ \\end{equation*}\\] \\[\\begin{equation*} \\text{Si }X\\in[d,u] \\longrightarrow f_{z}(d) = F_{X}(u)-F_{X}(d)\\\\\\\\ \\end{equation*}\\] \\[\\begin{equation*} \\text{Si }X&gt;u \\longrightarrow z\\in(u,b-u+d]\\\\\\\\ \\end{equation*}\\] \\[\\begin{eqnarray*} \\longrightarrow F_{z}(Z) &amp;=&amp; \\mathbb P[Z\\leq z]\\\\ &amp;=&amp; \\mathbb P[Z\\leq z | Z\\in[a,d]] \\mathbb P[Z\\in [a,d]]+ \\mathbb P[Z\\leq z | Z = d] \\mathbb P[Z=d]+ .. \\\\ &amp; &amp; ..+\\mathbb P[Z\\leq z | Z\\in(d,b-u+d]] \\mathbb P[Z\\in(d,b-u+d]]\\\\ &amp;=&amp; F_{X}(d) + F_{X}(u) - F_{X}(d) + \\mathbb P[u&lt;Z\\leq b-u+d]\\\\ &amp;=&amp; F_{X}(u) + \\mathbb P [d &lt; X -u +d \\leq Z]\\\\ &amp;=&amp; F_{X}(u) + \\mathbb P [u &lt; X \\leq Z+u-d]\\\\ &amp;=&amp; F_{X}(u) + F_{X}(Z+u-d) - F_{X}(u)\\\\\\\\ \\end{eqnarray*}\\] \\[\\begin{equation*} F_{X}(Z+u-d) \\longrightarrow f_{z}(Z) = f_{X}(Z+u-d) \\forall Z &gt; d\\\\ \\end{equation*}\\] \\[\\begin{equation*} \\therefore f_{z}(z) = \\left\\{ \\begin{array}{lcc} f_{X}(Z) &amp; si &amp; Z\\in [a,d)\\\\\\\\ F_{X}(u) - F_{X}(d) &amp; si &amp; Z=d\\\\\\\\ f_{X}(Z+u-d) &amp; si &amp; Z\\in(d,b-u+d]\\\\ \\end{array} \\right. \\\\ \\end{equation*}\\] Generalización del cálculo de variables esperadas para \\(Y_p\\). Como ya se mencionó en las notas, hay una manera de generalizar el cálculo del valor esperado de cualquier función \\(Y_p\\). Si \\(Y_p\\) tiene probabilidad positiva de tomar el cero, entonces \\(f_{Y_{L}}(0)=\\mathbb{P}[Y_{L} \\equiv 0]&gt;0\\) y así: \\[\\begin{equation*} \\mathbb{E}[h(Y_{L})]=h(0)f_{Y_L}(0)+ \\mathbb{E}[h(Y_p)]\\left(1-f_{Y_L}(0)\\right) \\end{equation*}\\] De donde se obtiene que: \\[\\begin{equation*} \\mathbb{E}[h(Y_{p})] = \\frac{\\mathbb{E}[h(Y_{L})]- h(0)f_{Y_L}(0)}{1-f_{Y_L}(0)} = \\frac{\\mathbb{E}[h(Y_{L})]-h(0)F_{X}\\left(\\frac{d}{1+r}\\right)}{S_{X}\\left(\\frac{d}{1+r}\\right)} \\end{equation*}\\] Por otro lado, si \\(Y_p\\) toma el cero con probabilidad cero, entonces \\(Y_p \\equiv Y_L\\) pues la compañía siempre paga en cualquier escenario. Esto significa que en este caso, calcular valores esperados de \\(Y_p\\) se hace de manera idéntica a los de \\(Y_L\\). Más aún, gracias a estos últimos resultados, y como ya sabemos obtener valores esperados de \\(Y_L\\), ya podemos obtener la esperanza de cualquier transformación de \\(Y_p\\). Generalización de la fórmula de Darth Vader. Lemma 2.2.13. if \\(Y\\geq 0\\) and \\(p&gt;0\\) then \\(E(Y^p)=\\int_{0}^{\\infty}py^{p-1}P(Y&gt;y)dy\\). \\(Proof\\). Using the definition of expected value, Fubini’s theorem (for non-negative random variable), and then calculation the resulting integrals gives: \\[\\begin{eqnarray*} \\int_{0}^{\\infty} py^{p-1}P(Y&gt;y)dy &amp;=&amp; \\int_{0}^{\\infty} \\int_{\\Omega} py^{p-1}1_{(Y&gt;y)}dPy\\\\ &amp;=&amp; \\int_{\\Omega} \\int_{0}^{\\infty} py^{p-1}1_{(Y&gt;y)}dydP\\\\ &amp;=&amp; \\int_{\\Omega} \\int_{0}^{Y} py^{p-1}dydP = \\int_{\\Omega} Y^{p}dP \\\\ &amp;=&amp; EY^{p}\\\\ \\end{eqnarray*}\\] which is the desired result. 2.2.6. (i) Show that if \\(X \\geq 0\\) is integer valued \\(EX = \\sum_{n\\geq1} P(X\\geq n)\\). (ii) Find a similar expression for \\(EX^2\\). Si \\(Y \\geq 0\\), aplicamos al Lema 2.2.13: \\(\\mathbb E Y^{p} = \\int_{0}^{\\infty} Py^{p-1} \\mathbb P[Y &gt; y]dy = \\sum_{n=0}^{\\infty} \\int_{n}^{n+1} Py^{p-1} \\mathbb P[Y&gt;y]dy\\) pero, tomando \\(y\\in[n,n+1)\\) \\(\\longrightarrow\\) \\(\\mathbb P[Y&gt;y] = \\mathbb P[Y&gt;y] \\longrightarrow \\mathbb E Y^{p} = \\sum_{n=0}^{\\infty} \\int_{n}^{n+1} Py^{p-1} P[Y&gt;n]dy\\), sacando constantes: \\[\\begin{eqnarray*} \\mathbb E Y^{p} &amp;=&amp; \\sum_{n=0}^{\\infty} \\int_{n}^{n+1} Py^{p-1} \\mathbb P [Y&gt;n] dy = \\sum_{n=0}^{\\infty} P \\mathbb P[Y&gt;n] \\int_{n}^{n+1} y^{p-1} dy \\\\ &amp;=&amp; \\sum_{n=0}^{\\infty} \\mathbb P[Y&gt;n] ((n+1)^{p}-(n)^{p})\\\\ &amp;=&amp; \\sum_{n=0}^{\\infty} \\mathbb P[Y\\geq n+1] ((n+1)^{p}-n^{p}) \\\\ &amp;=&amp;\\sum_{n=1}^{\\infty} \\mathbb P[Y\\geq n] (n^{p}-(n+1)^{p})\\\\ \\end{eqnarray*}\\] En particular, tenemos: \\(\\mathbb E Y = \\sum_{n=1}^{\\infty} \\mathbb P[Y\\geq n] (n-(n-1)) = \\sum_{n=1}^{\\infty} \\mathbb P[Y\\geq n]\\). Cuando \\(p=2\\) \\(\\longrightarrow\\) \\(n^2-(n-1)^2=n^2-n^2+2n-1\\) \\(=2n-1\\) \\(\\mathbb E Y^2 = \\sum_{n=1}^{\\infty} \\mathbb P[Y\\geq n] (n^2-(n-1)^2) = \\sum_{n=1}^{\\infty} (2n-1) \\mathbb P[Y\\geq n]\\) Recordemos el siguiente resultado para el cálculo de la variable de cobertura. Ejercicio para el Lector: Demuestra que la formula de la derecha es válida para \\(X\\) cualquier v.a. \\[\\begin{equation*} F_{Y}(t) \\ddot{=} \\mathbb P[Y\\leq t] = \\left\\{ \\begin{array}{lcc} 0 &amp; si &amp; t&lt;0\\\\\\\\ F_{\\chi}(\\frac{t+d\\alpha}{\\alpha(1+r)}) &amp; si &amp; t\\in[0,\\alpha(u-d))\\\\\\\\ 1 &amp; si &amp; t\\geq \\alpha(u-d)\\\\ \\end{array} \\right. \\end{equation*}\\] Entonces: \\[\\begin{equation*} S_{Y}(t)\\ \\ddot{=}\\ \\mathbb P[Y &gt; t] = \\left\\{ \\begin{array}{lcc} 1 &amp; si &amp; t&lt;0\\\\\\\\ S_{\\chi}(\\frac{t+d\\alpha}{\\alpha(1+r)}) &amp; si &amp; t\\in[0,\\alpha(u-d))\\\\\\\\ 0 &amp; si &amp; t\\geq \\alpha(u-d)\\\\ \\end{array} \\right. \\\\ \\end{equation*}\\] Usando lo anterior, como \\(Y\\geq 0\\), calculamos a la Darth Vader: \\[\\begin{equation*} \\mathbb E[Y^{p}] = \\int_{0}^{\\infty} pt^{p-1} \\mathbb P[Y &gt; t] dt = \\int_{0}^{\\alpha(u-d)} pt^{p-1} S_{\\chi}(\\frac{t+d\\alpha}{\\alpha(1+r)}) dt \\end{equation*}\\] En particular si \\(p=1\\) tenemos que: \\[\\begin{eqnarray*} \\mathbb E[Y] &amp;=&amp; \\mathbb E[Y^{p}] = \\int_{0}^{\\alpha(u-d)} pt^{p-1} S_{\\chi}(\\frac{t+d\\alpha}{\\alpha(1+r)}) dt \\\\ &amp;=&amp; \\int_{0}^{\\alpha(u-d)} S_{\\chi}(\\frac{t+d\\alpha}{\\alpha(1+r)}) dt \\left\\{ \\begin{array}{lcc} \\chi = \\frac{t+dx}{\\alpha(1+r)} \\longrightarrow dx = \\frac{dt}{\\alpha(1+r)}\\\\ \\end{array} \\right.\\\\ &amp;=&amp; \\alpha(1+r) \\int_{\\frac{d}{1+r}}^{\\frac{u}{1+r}} S_{\\chi}dx \\end{eqnarray*}\\] Que es el resultado que ya teníamos en las notas. 2.2.7. Generalize Lemma 2.2.13 to conclude that if \\(H(x)=\\int_{(-\\infty,x)}h(y)dy\\) with \\(h(y)\\geq 0\\), then \\[\\mathbb{E}[H(X)]=\\int^\\infty_{-\\infty}h(y)P(X\\geq y)dy\\] An important special case is \\(H(x)=exp(\\theta x)\\) with \\(\\theta&gt;0\\). Nota: funciona con \\(\\mathbb{P}[X&gt;y]\\) pues la integral (\\(dy\\)) en un punto es cero. Con la finalidad de aclarar/recordar algunas cosas para probar lo anterior: Let \\((X,\\mathcal{A},\\mu_1)\\) and \\((Y,\\mathcal{B},\\mu_2)\\) be two \\(\\sigma\\)-finite measure spaces. Let \\[\\begin{eqnarray*} \\Omega=X \\times Y=\\{(x,y):x\\in X,y\\in Y\\}\\\\ \\end{eqnarray*}\\] \\[\\begin{eqnarray*} \\mathcal{S}&amp;=&amp;\\{A\\times B:A\\in\\mathcal{A},B\\in\\mathcal{B}\\} \\end{eqnarray*}\\] Sets in \\(S\\) are called rectangles. Let \\(\\mathcal{F}=\\mathcal{A}\\times\\mathcal{B}\\) be the \\(\\sigma\\)-algebra generated by \\(\\mathcal{S}\\). Nota: La notación puede no ser la mejor, pero en este caso, pensándolo en términos de v.a.’s, sin pérdida de generalidad, \\(X\\) denota un soporte, \\(A\\) eventos del soporte y \\(\\mu_1\\) denota una medida \\(\\sigma\\)-finita. Theorem 1.7.1. There is a unique measure \\(\\mu\\) on \\(\\mathcal{F}\\) with \\[\\mu(A\\times B)=\\mu_1(A)\\mu_2(B)\\] Notation. \\(\\mu\\) is often denoted by \\(\\mu_1\\) \\(\\mu_2\\). Nota: Pensando en un caso particular de este teorema, recuerden que puede haber dos funciones de distribución conjunta (acumulada) diferentes con las mismas marginales, pero este garantiza que hay una única dada por el producto de las marginales. De aquí, una pregunta razonable cuando se esta aprendiendo probabilidad es: Dados un par de v.a. digamos \\(X\\) y \\(Y\\); ¿Cuál es su densidad conjunta? La respuesta es, quién sabe… sus marginales no nos permiten observar su comportamiento de manera conjunta. Ejercicio: Muestra un ejemplo de dos funciones de densidad conjunta diferentes, que tengan las mismas marginales. Nota: Tenemos el siguiente resultado: Theorem 1.7.2. Fubini’s theorem If \\(f\\geq 0\\) or \\(\\int|f|d\\mu&lt;\\infty\\) then \\[\\int_X\\int_Y f(x,y)\\mu_2(dy)\\mu_1(dx)=\\int_{X\\times Y}fd\\mu=\\int_Y\\int_X f(x,y)\\mu_1(dx)\\mu_2(dy)\\] Donde s.p.g. \\(\\mu_1(dx)\\) es notación para indicar que la función \\(f\\) se integra sobre \\(x\\) con respecto a la media \\(\\mu_1\\). Procedemos con la prueba del teorema 2.2.7. Considerando un espacio de probabilidad (\\(\\Omega,\\mathscr{F},P\\)), donde \\(P\\) es la función de distribución (acumulada) de una v.a. \\(X\\). \\(P(x)\\hspace{0.4em}\\ddot{=}\\hspace{0.4em}\\mathbb{P}[X\\leq x]\\). \\[\\mathbb{E}[H(X)]\\hspace{0.4em}\\ddot{=}\\hspace{0.4em}\\int_\\Omega H(x)dP=\\int_{\\Omega}\\left(\\int_{(-\\infty,x]}h(y)dy\\right) dP=\\int_\\Omega\\left(\\int_{\\mathbb{R}}\\mathbb{I}_{(-\\infty,x]}h(y)dy\\right)dP\\] Pero gracias a las hipótesis, es claro que \\(\\mathbb{I}_{(-\\infty,x]}(y)h(y)\\geq 0\\) como función de \\(y\\) (¡En serio!). Ergo, podemos invocar el teorema de fubini al resultado anterior: \\[\\begin{eqnarray*} \\mathbb{E}[H(X)]&amp;=&amp;\\int_{\\Omega}\\left(\\int_{\\mathbb{R}}\\mathbb{I}_{(-\\infty,x]}(y)h(y)dy\\right)dP\\\\ &amp;\\overset{\\underset{\\downarrow}{\\text{Fubini}}}{=}&amp;\\int_{\\mathbb{R}}\\left(\\int_{\\Omega}\\mathbb{I}_{(-\\infty,x]}(y)h(y)dP\\right)dy\\quad \\left \\{ \\begin{matrix} &amp;\\mbox{Obs. } dy=\\lambda(dy)\\\\ &amp;\\mbox{donde } \\lambda \\mbox{ es la medida} \\\\ &amp;\\mbox{de Lebesgue.} \\end{matrix}\\right. \\end{eqnarray*}\\] Pero \\(P\\) mide con \\(x\\),i.e., \\(dP=P(dx)\\) entonces \\(y\\) es constante para \\(dP\\): \\[\\begin{eqnarray*} \\Rightarrow \\mathbb{E}[H(X)]&amp;=&amp;\\int_{\\mathbb{R}}\\left(h(y)\\int_\\Omega\\mathbb{I}_{(-\\infty,x]}(y)dP\\right)dy\\\\ &amp;=&amp; \\int_{\\mathbb{R}}\\left(h(y)\\int_\\Omega\\mathbb{I}_{[y,\\infty)}(x)dP\\right)dy\\left\\{\\begin{matrix} \\mbox{El conjunto de la indicadora}\\\\ es:-\\infty&lt;y\\leq x &lt;\\infty \\end{matrix}\\right.\\\\ &amp;=&amp; \\int_{\\mathbb{R}}\\left(h(y)\\int_{[y,\\infty)}dP\\right)dy=\\int_{\\mathbb{R}}h(y)\\mathbb{P}[X\\geq y]dy.\\quad\\blacksquare \\end{eqnarray*}\\] Un ejemplo/caso especial es el que menciona el mismo teorema: Sea \\(H(x)=exp(\\theta x)\\Rightarrow h(x)=H&#39;(x)=\\theta exp(\\theta x)\\) por el teorema fundamental del cálculo. Invocando el último teorema, cualquier generadora de momentos se puede calcular como: \\[\\mu_X(\\theta)\\hspace{0.4em}\\ddot{=}\\hspace{0.4em}\\mathbb{E}[e^{\\theta X}]=\\mathbb{E}[H(X)]=\\int_{\\mathbb{R}}h(y)\\mathbb{P}[X\\geq y]dy=\\int_{\\mathbb{R}}\\theta exp(\\theta y)\\mathbb{P}[X\\geq y]dy\\] a la Darth Vader. Un ejemplo del resultado anterior es tomando \\(X\\sim exp(\\lambda)\\), así: \\[\\begin{eqnarray*}\\mathbb{P}[X\\geq y]=\\mathbb{P}[X&gt;y]\\hspace{0.4em}\\ddot{=}\\hspace{0.4em}S_X(y)=\\left\\{\\begin{matrix} e^{-\\lambda y}&amp;\\mbox{si}&amp; y\\geq 0\\\\ 1 &amp;\\mbox{si}&amp; y&lt;0 \\end{matrix}\\right.\\end{eqnarray*}\\] \\[\\begin{eqnarray*} \\Rightarrow \\int_{\\mathbb{R}}\\theta exp(\\theta y)\\mathbb{P}[X\\geq y]dy &amp;=&amp; \\overset{\\text{¿Por qué es 1?}_{\\hspace{0.2em}\\searrow}}{{\\int^0_{-\\infty}\\theta exp(\\theta y)dy}}+\\int^\\infty_0 \\theta exp(\\theta y)e^{-\\lambda y}dy\\\\ &amp;=&amp; 1+ \\frac{\\theta}{\\lambda}\\mu_X(\\theta)\\hspace{0.4em} \\left\\{\\mu_X(\\theta)=\\frac{\\lambda}{\\lambda-\\theta}\\right. = 1+\\frac{\\theta}{\\lambda-\\theta}=\\frac{\\lambda}{\\lambda-\\theta}=\\mu_X(\\theta). \\end{eqnarray*}\\] Cumpliéndose así lo que acabamos de probar. Hagamos otro con \\(X\\in\\mathbb{N}\\cup\\{0\\}\\), así, haciendo algo similar al ejercicio 2.2.6. podemos tomar \\(n\\in\\mathbb{N}\\cup\\{0\\}\\) y luego notar que: Si \\(y\\in(n,n+1]\\Rightarrow\\mathbb{P}[X\\geq y]=\\mathbb{P}[X&gt;n]=\\sum\\limits_{t=n+1}^\\infty\\mathbb{P}[X=t]\\) Si \\(y\\leq 0\\Rightarrow \\mathbb{P}[X\\geq y]=1\\). Entonces: \\[\\begin{equation*} \\mathbb{P}[X\\geq y]=\\left\\{ \\begin{matrix} \\mathbb{P}[X&gt;n]=\\sum\\limits_{t=\\lceil y \\rceil}^\\infty\\mathbb{P}[X=t]=\\sum\\limits_{t=n+1}^\\infty\\mathbb{P}[X=t]&amp;\\mbox{si}&amp; y\\in(n,n+1]\\quad\\forall n\\in\\mathbb{N}\\cup\\{0\\} \\\\ 1 &amp;\\mbox{si}&amp; y\\leq 0 \\end{matrix}\\right. \\end{equation*}\\] \\[\\begin{eqnarray*} \\Rightarrow \\int_{\\mathbb{R}}\\theta exp(\\theta y)\\mathbb{P}[X\\geq y]dy&amp;=&amp;\\int^0_{-\\infty}\\theta exp(\\theta y)dy+\\int^\\infty_0 \\theta exp(\\theta y)\\mathbb{P}[X\\geq y]dy\\\\ &amp;=&amp;1+\\sum\\limits_{n=0}^\\infty\\int^{n+1}_n\\theta exp(\\theta y)\\mathbb{P}[X\\geq y]dy \\\\ &amp;=&amp;1+\\sum\\limits_{n=0}^\\infty\\int^{n+1}_n\\theta exp(\\theta y)\\mathbb{P}[X&gt;n]dy\\\\ &amp;=&amp;1+\\sum\\limits_{n=0}^\\infty\\mathbb{P}[X&gt;n]\\int^{n+1}_n\\theta exp(\\theta y)dy\\quad\\left\\{\\int^{n+1}_n\\theta exp(\\theta y)dye^{\\theta(n+1)}-e^{\\theta n}\\right.\\\\ &amp;=&amp; 1+\\sum\\limits_{n=0}^\\infty \\mathbb{P}[X&gt;n](e^{\\theta (n+1)}-e^{\\theta n}) \\\\ &amp;=&amp;1+\\sum\\limits_{n=0}^\\infty\\mathbb{P}[X&gt;n]e^{\\theta n}(e^\\theta-1)\\\\ &amp;=&amp;1+(e^\\theta-1)\\sum\\limits_{n=0}^\\infty\\mathbb{P}[X&gt;n]e^{\\theta n}\\\\ &amp;=&amp; 1+ (e^\\theta-1)\\sum\\limits_{n=0}^\\infty\\sum\\limits_{t=n+1}^\\infty\\mathbb{P}[X=t]e^{\\theta n}\\\\ &amp;=&amp; 1+(e^\\theta-1)\\sum\\limits_{t=1}^\\infty\\sum\\limits_{n=0}^{t-1}\\mathbb{P}[X=t]e^{\\theta n}\\quad\\left\\{\\begin{matrix} \\mbox{Estamos sumando }(n,t):\\\\\\begin{matrix} (0,1)&amp; (0,2)&amp;(0,3)&amp;(0,4)&amp;\\cdots \\\\ x&amp;(1,2)&amp;(1,3)&amp;(1,4)&amp;\\cdots \\\\ x&amp;x&amp;(2,3)&amp;(2,4)&amp;\\cdots\\\\ \\vdots &amp;\\ddots\\end{matrix} \\end{matrix}\\right.\\\\ &amp;=&amp;1+(e^\\theta -1)\\sum\\limits_{t=1}^\\infty\\mathbb{P}[X=t]\\sum\\limits_{n=0}^{t-1}(e^\\theta)^n=1+(e^\\theta-1)\\sum\\limits_{t=1}^\\infty\\mathbb{P}[X=t]\\frac{1-e^{\\theta t}}{1-e^\\theta}\\\\ &amp;=&amp;1+\\sum\\limits_{t=1}^\\infty\\mathbb{P}[X=t](e^{\\theta t}-1)\\\\ &amp;=&amp; 1+\\sum\\limits_{t=0}^\\infty\\mathbb{P}[X=t](e^{\\theta t}-1)=1+\\mu_X(\\theta)-\\sum\\limits_{t=0}^\\infty\\mathbb{P}[X=t]=\\mu_X(\\theta) \\end{eqnarray*}\\] Probando de nuevo la propiedad. Con esto ya verificamos la validez de los últimos resultados. Más deducibles Consideremos \\(Y=(X-d)\\) la severidad de un riesgo a asumir \\(0\\leq X\\) (\\(Y\\) es el pago de la compañía por contrato de deducible \\(=d\\)). Proposición En general, si \\(a,b \\in \\mathbb{R}^{+}\\) tal que \\(a\\leq X\\leq b\\) entonces: \\[\\begin{eqnarray*} \\mathbb{E}[X\\wedge d ]&amp;=&amp; \\mathbb{E}[X]-\\mathbb{E}[(X-d)_{+}]\\leq d \\leq b \\end{eqnarray*}\\] Nota: Aquí en general pensemos que \\(\\mathbb{E}[X] \\geq \\mathbf{E}[(X-d)_{+}]\\) para reducir la siniestralidad. Demostración. \\[\\begin{eqnarray*} X-d \\leq (X-d)_{+} \\quad \\forall \\omega \\in \\Omega &amp; \\Rightarrow&amp; \\mathbb{E}[X-d] \\leq \\mathbb{E}[(X-d)_{+}]\\\\ &amp;\\Rightarrow&amp; \\mathbb{E}[X]-\\mathbb{E}[(X-d)_{+}]\\leq d\\\\ \\end{eqnarray*}\\] En general, tomamos \\(d&lt;b\\) pues en otro caso \\((X-d)_{+} \\equiv 0 \\quad \\blacksquare\\). Proposición Sea \\(X\\) v.a tal que \\(X&gt;d\\) c.s. \\(\\Rightarrow d=\\mathbb{E}[X]-\\mathbb{E}[(X-d)_{+}]\\). \\(\\Leftarrow\\) válido si \\(P[X\\equiv d]=0\\) Demostración. \\[\\begin{equation*} \\mathbb{E}[X]=\\displaystyle\\int_{0}^{\\infty} \\mathbb{P}[X&gt;t] dt \\quad \\quad \\mathbb{E}[(X-d)_{+}] = \\displaystyle\\int_{0}^{\\infty} S_{X}(t+d) dt= \\displaystyle\\int_{0}^{\\infty} S_{X}(u) dt \\end{equation*}\\] Revisar Script 4.A.1 \\[\\begin{eqnarray*} \\mathbb{E}[X]-\\mathbb{E}[(X-d)_{+}]&amp;=&amp; \\displaystyle\\int_{0}^{d} \\mathbb{P}[X&gt;t] dt \\\\ &amp;=&amp; \\displaystyle\\int_{0}^{d} (1- \\mathbb{P}[X\\leq t]) dt\\\\ &amp;=&amp; \\displaystyle\\int_{0}^{d} dt- \\displaystyle\\int_{0}^{d} \\mathbb{P}[X\\leq t] dt \\\\&amp;=&amp; d- \\underbrace{\\displaystyle\\int_{0}^{d} \\mathbb{P}[X\\leq t] dt}_{ \\text{¡ Todo depende esto !}}\\\\ \\end{eqnarray*}\\] \\[\\begin{equation*} 0 \\leq \\displaystyle\\int_{0}^{d} \\mathbb{P}[X\\leq t] dt \\leq \\displaystyle\\int_{0}^{d} \\mathbb{P}[X\\leq d] dt =0\\\\ \\end{equation*}\\] \\[\\begin{eqnarray*} d&amp;=&amp;\\mathbb{E}[X]-\\mathbb{E}[(X-d)_{+}]\\\\ &amp;=&amp; d- \\displaystyle\\int_{0}^{d}\\mathbb{P}[X\\leq t] dt \\end{eqnarray*}\\] Sí y solo si: \\[\\begin{eqnarray*} 0&amp;=&amp; \\displaystyle\\int_{0}^{d}\\mathbb{P}[X\\leq t] dt\\\\ \\end{eqnarray*}\\] Como \\(0\\leq \\mathbb{P}[X\\leq t]\\) es no decreciente como función de \\(t\\), entonces: \\(\\mathbb{P}[X\\leq t]\\equiv 0 \\quad \\forall t\\in[0,d] \\Rightarrow \\mathbb{P}[X &lt;d]=0 \\Rightarrow \\mathbb{P}[X \\geq d]=1\\). Donde vemos que si \\(\\mathbb{P}[X\\equiv d]=0\\), el regreso es válido. Como consecuencia. Si \\(\\mathbb{P}[X \\leq d] \\approx0 \\Rightarrow d \\approx \\mathbb{E}[X]-\\mathbb{E}[(X-d)_{+}]\\). En conclusión, lo anterior nos dice que si \\(\\mathbb{E}[X]\\) dista mucho de \\(\\mathbb{E}[(X-d)_{+}]\\), entonces: El deducible debe ser grande. Esto tiene sentido pues en general como \\(\\mathbb{E}[X]&gt;\\mathbb{E}[(X-d)_{+}]\\) entonces quiere decir que un deducible grande, reduce la siniestralidad. Por otro lado que tanto diste “\\(d\\)” de su cota inferior, depende totalmente de \\(\\displaystyle\\int_{0}^{d} \\mathbb{P}[X\\leq t]dt\\), es decir, de que tanta probabilidad hay en la cola izquierda de la distribución. Esto nos da una descripción un poco mas detallada de: \\[\\begin{eqnarray*} \\textit{Si} &amp;&amp; \\mathbb{E}[(X-d)_{+}] \\uparrow \\mathbb{E}[X] \\Rightarrow d \\downarrow \\mathbb{E}[X]-\\mathbb{E}[(X-d)_{+}] \\approx 0 .\\\\ \\textit{Si} &amp;&amp; \\mathbb{E}[(X-d)_{+}]\\downarrow 0 \\Rightarrow d \\uparrow sup\\{x|x \\in Sop {X}\\}&#39;&#39;=&#39;&#39;\\quad\\blacksquare \\end{eqnarray*}\\] Ejemplo muy sencillo de como jugar con el deducible: Sea \\(X\\) v.a tal que \\(SopX=\\{3,12 \\}\\) y \\(\\mathbb{P}[X=x]=1/2 \\quad \\forall x \\in Sop\\{ X\\}\\). Esta represente el monto de un siniestro. Calculamos un deducible tal que \\(\\mathbb{E}[Y_{L}]=3. (Y_{L}= (X-d)_{+})\\). Solución Hagamos algunas observaciones: \\[\\begin{eqnarray*} \\mathbb{E}[X]&amp;=&amp;\\left(\\frac{1}{2} \\right)(3)+ \\left(\\frac{1}{2} \\right)(12)\\\\ &amp;=&amp; 7.5\\\\ \\mathbb{E}[Y_{L}]&amp;=&amp;3\\\\ \\end{eqnarray*}\\] Como \\(\\mathbb{E}[X]&gt; \\mathbb{E}[Y_L]\\), entonces tiene sentido de hablar de un deducible con estas características. Resolvamos por casos: Caso 1: Entonces \\(d &lt; 3\\). Entonces: \\[\\begin{equation*} Y_{L} \\ddot{=} (X-d)_{+}=X-d \\Rightarrow 3=\\mathbb{E}[Y_{L}]= \\mathbb{E}[X]-d = 7.5-d \\end{equation*}\\] Entonces: \\[\\begin{eqnarray*} d&amp;=&amp; 7.5-3\\\\ &amp;=&amp; 4.5\\\\ \\end{eqnarray*}\\] Esto nos hace recordar la cota inferior que hay para \\(d\\), i.e, \\(\\mathbb{E}[X]-\\mathbb{E}[(X-d)_{+}] \\leq d\\). En este caso no tenía sentido buscar a \\(d\\) antes de \\(4.5\\) pues esa era la cota inferior. Caso 2: Entonces \\(d &gt;12\\). \\[\\begin{equation*} Y_{L} \\ddot{=} (X-d)_{+} \\equiv 0 \\Rightarrow 3= \\mathbb{E}[Y_{L}]=0 \\quad \\text{¡ Contradicción !} \\end{equation*}\\] Caso 3: Entonces \\(d\\in(3,12)\\). \\[\\begin{eqnarray*} Y_{L}&amp;\\ddot{=}&amp; (X-d)_{+}\\\\ &amp;=&amp; \\left \\{ \\begin{matrix} 0 &amp; \\mbox{si }&amp; X&lt; d &amp; \\Leftrightarrow &amp; X=3\\\\ X-d &amp;\\mbox{si } &amp; X \\geq d &amp; \\Leftrightarrow &amp; X=12\\\\ \\end{matrix}\\right. \\end{eqnarray*}\\] \\[\\begin{eqnarray*} 3&amp;=&amp; \\mathbb{E}[Y_{L}] \\\\ &amp;=&amp; 0 \\cdot \\mathbb{P}[X=3] + (12-d) \\cdot \\mathbb{P}[X=12]\\\\ &amp;=&amp; (12-d) \\frac{1}{2}\\\\ &amp;=&amp; 6- \\displaystyle\\frac{d}{2}\\\\ &amp; \\Leftrightarrow &amp; 6=12-d\\\\ &amp; \\Leftrightarrow &amp; d= 6 \\\\ \\end{eqnarray*}\\] Okay, esto es una opción, otra es notar que puedo pensar \\(\\mathbb{E}[Y_{L}]\\) como función de \\(d\\) con la fórmula de Darth Vader. \\[\\begin{eqnarray*} \\mathbb{E}[Y_L]&amp;=&amp; \\displaystyle\\int_{d}^{b} S_{X}(t)dt\\\\ &amp;=&amp; f(d)\\\\ \\end{eqnarray*}\\] La cuestión es encontra \\(d\\) tal que \\(f(d)=3\\). "],["modelo-individual-bases.html", "Capítulo 9 Modelo individual bases 9.1 Modelo individual 9.2 Derivación bajo el signo integral 9.3 Teorema de probabilidad total en el caso continuo: 9.4 Teorema de probabilidad total en el caso discreto: 9.5 Aproximación Normal", " Capítulo 9 Modelo individual bases Una vez que ya conocemos la frecuencia y severidad por separado hay que comenzar a unir estos dos conceptos. Para eso vamos a construir una v.a. que no solo combine los temas anteriores sino que los generalice. Comencemos con un caso particular. 9.1 Modelo individual Suponga que tiene un portafolio de \\(n\\) pólizas individuales de seguros válidas por un año como se muestra en la Figura 1.1. Figura 1.1 Sea \\(p_j\\) la probabilidad de que el \\(j\\)-ésimo asegurado no efectúe ninguna reclamación durante el tiempo de vigencia del seguro, y sea \\(q_j\\) la probabilidad de que se observe exactamente una reclamación. Suponga que la igualdad \\(p_j + q_j=1\\) se cumple, ello significa que no puede haber más de una reclamación por cada asegurado.Tal situación puede corresponder, por ejemplo, a los seguros de vida. Defina una variable aleatoria: \\[\\begin{equation*} D_j=\\left\\{\\begin{array}{lcc} 1 \\quad\\mbox{si hay reclamación en la póliza } j,\\\\ 0\\quad \\mbox{si no hay reclamación en la póliza } j. \\end{array}\\right. \\end{equation*}\\] Claramente \\(D_j\\) tiene una distribución Bernoulli con parámetro \\(q_j\\). El uso de la letra \\(D\\) viene del término en inglés. Observe que el número total de reclamaciones está dado por la variable aleatoria \\(N=D_1+\\cdots+D_n\\).Ahora suponga artificialmente que cada póliza efectúa una reclamación, y sea la variable aleatoria \\(C_j&gt;0\\) el monto de la reclamación efectuada por la póliza \\(j\\). Debido a que los siniestros pueden presentarse con características distintas y ello puede derivar en distintos montos de reclamación, consideraremos de manera general a \\(C_j\\) no como una constante sino como una variable aleatoria. La leta \\(C\\) proviene del término en inglés, que se traduce en español como reclamación. La verdadera reclamación de la póliza \\(j\\) está dada por el producto. \\[\\begin{equation*} D_jC_j=\\left\\{\\begin{array}{lcc} C_j &amp; \\mbox{si } D_j=1, \\\\ 0 &amp; \\mbox{si } D_j=0. \\end{array}\\right. \\end{equation*}\\] Observe que esta variable aleatoria puede ser mixta, es decir, no ser continua ni discreta. véase la Figura 1.2 en donde se muestran posibles gráficas de la función de distribución de esta variable aleatoria. De esta forma se considera como datos en este modelo la colección de vectores aleatorios \\((D_1,C_1),...,(D_n,C_n),\\) que supondremos independientes. Consideraremos además que las variables \\(D_j\\) y \\(C_j\\) también son independientes entre sí. Figura 1.2 El monto de reclamaciones agregadas, o también llamado agregado de reclamaciones,en el modelo individual, es la variable aleatoria \\[\\begin{equation} S=\\sum_{j=1}^n D_jC_j \\end{equation}\\] Ecuación 1.1 Esta variable es el monto que afronta una compañía aseguradora por concepto de reclamaciones durante el periodo completo del seguro. La ecuación (1.1) representa el modelo individual para una póliza de seguros de las características señaladas. El modelo tiene este nombre pues supone conocer las probabilidades de reclamación y posible monto de reclamación de todos y cada uno de los asegurados de manera individual.Una posible desventaja de este modelo es que presupone que el número de asegurados en la cartera se mantiene constante durante todo el tiempo de vigencia del seguro. Desde el punto de vista matemático, y también desde la perspectiva del negocio del seguro, nuestro objetivo es conocer las características de la variable \\(S\\), a quien llamaremos riesgo. Si \\(F_j(x)\\) denota la función de distribución del producto \\(D_jC_j\\), entonces la función de distribución \\(F(x)\\) del riesgo \\(S\\) adquiere la siguiente expresión en términos de convoluciones: \\[F(x)=(F_1*\\cdots*F_n)(x)\\] Esta fórmula general y compacta es, sin embargo, un tanto difícil de calcular y no la utilizaremos con frecuencia. Como primeros resultados generales se presentan a continuación algunas características de \\(S\\). Denotaremos por \\(G_j(x)\\) la función de distribución de \\(C_j\\), y como es costumbre,cuando exista, \\(M_X(t)\\) denota la función generadora de momentos de una variable \\(X\\) cualquiera. Proposición: Bajo la notación e hipótesis del modelo individual se tienen los siguientes resultados. i) \\(E(S)=\\displaystyle\\sum_{j=1}^n q_j E(C_j).\\) ii) \\(Var(S)=\\displaystyle\\sum_{j=1}^n\\left[q_j Var(C_j)+q_jp_jE^2(C_j)\\right]\\). iii) \\(F_j(x)=\\left\\{\\begin{array}{lcc} 1+q_j(G_j(x)-1) &amp; \\textit{si }&amp;x\\geq 0, \\\\ 0 &amp; \\textit{si }&amp;x&lt;0. \\end{array}\\right.\\) iv) \\(M_{D_jC_j}(t)=1+q_j(M_{C_j}(t)-1).\\) v) \\(M_S(t)=\\displaystyle\\prod_{j=1}^n[1+q_j(M_{C_j}(t)-1)].\\) Nota: \\(p_j=1-q_j\\) Demostración. i) Por la hipótesis de independencia, \\[E(S)=\\displaystyle\\sum_{j=1}^nE(D_jC_j)=\\displaystyle\\sum_{j=1}^nE(D_j)E(C_j)=\\displaystyle\\sum_{j=1}^nq_jE(C_j).\\] ii) Primeramente tenemos que \\[\\begin{eqnarray*} Var(D_jC_j)&amp;=&amp; E(D^2_jC^2_j)-E^2(D_jC_j)\\\\ &amp;=&amp; q_jE(C^2_j)-q^2_jE^2(C_j)\\\\ &amp;=&amp; q_j[Var(C_j)+E^2(C_j)]-q^2_jE^2(C_j)\\\\ &amp;=&amp; q_jVar(C_j)+q_jp_jE^2(C_j). \\end{eqnarray*}\\] Por lo tanto \\[Var(S)=\\displaystyle\\sum_{j=1}^nVar(D_jC_j)=\\displaystyle\\sum[q_jVar(C_j)+q_jp_jE^2(C_j)].\\] iii) Para cualquier número real \\(x\\geq0,\\) \\[\\begin{eqnarray*} F_j(x) &amp;=&amp; P(D_jC_j\\leq x)\\\\ &amp;=&amp; P(D_jC_j\\leq x | D_j=0)P(D_j=0)+P(D_jC_j\\leq x | D_j=1)P(D_j=1)\\\\ &amp;=&amp; P(0\\leq x | D_j=0)p_j + P(C_j \\leq x | D_j=1)q_j\\\\ &amp;=&amp; p_j+q_jG_j(x)\\\\ &amp;=&amp; 1+ q_j(G_j(x)-1). \\end{eqnarray*}\\] iv) Nuevamente condicionando sobre el valor de \\(D_j\\), \\[\\begin{eqnarray*} M_{D_jC_J}(t)&amp;=&amp;E(e^{tD_jC_j})\\\\ &amp;=&amp; E(e^{tD_jC_J} | D_j=0)P(D_j=0)+E(e^{tD_jC_J}| D_j=1)P(D_j=1) \\\\ &amp;=&amp; p_j+q_jM_{C_j}(t)\\\\ &amp;=&amp; 1+ q_j(M_{C_j}(t)-1). \\end{eqnarray*}\\] v) Esta igualdad se sigue directamente de la anterior usando la hipótesis de independencia\\(._\\blacksquare\\) Nota: \\(S\\geq 0\\) bajo el contexto y definiciones que se mencionaron en esta sección. A continuación se muestran vídeos con la explicación de lo mencionado anteriormente: Link de YouTube: https://youtu.be/rekGEr6sGoQ Link de YouTube: https://youtu.be/uGhUhhZh3Ok Ejemplo: Sean \\(\\{C_i\\}\\sim Exp\\left(\\frac{1}{200}\\right)\\) los montos de reclamación para \\(n=100\\) asegurados, de los cuales la probabilidad de reclamación está dada por la siguiente tabla: \\(\\mathbb{E}[S]=\\displaystyle\\sum_{j=1}^{100}q_j\\mathbb{E}[C_j]=200({\\underbrace{{\\text{45(0.02)}}}_{\\text{Grupo 1}}})+{\\underbrace{{\\text{(37(0.04)}}}_{\\text{Grupo 2}}})+{\\underbrace{{\\text{(18(0.07)}}}_{\\text{Grupo 3}}})=728\\) \\[\\begin{eqnarray*} Var(S)&amp;=&amp;\\displaystyle\\sum_{j=1}^{100}q_jVar(C_j)+q_j{\\overbrace{{(1-q_j)}}^{p_j}}\\mathbb{E}^2[C_j] = 200^2\\displaystyle\\sum_{j=1}^{100}[q_j+q_j(1-q_j)]{Var(C_j)=\\mathbb{E}^2[C_j]=200^2}\\\\ &amp;=&amp;200^2[{\\underbrace{{\\text{(0.02+0.02(0.98))(45)}}}_{\\text{Grupo 1}}}+{\\underbrace{{\\text{(0.04+0.04(0.96))(37)}}}_{\\text{Grupo 2}}}+{\\underbrace{{\\text{(0.07+0.07(0.93))(18)}}}_{\\text{Grupo 3}}}]\\\\ &amp;=&amp;284,584\\\\ \\end{eqnarray*}\\] Observamos que a pesar de contar con ciertas propiedades del riesgo \\(S\\) ninguna de ellas nos dice cómo obtener probabilidades de esta variable aleatoria. Lo que sucede es que en general resulta complicado calcular probabilidades de sumas de variables aleatorias el cual está ligado con una expresión matemática conocida como convoluciones. Para entender más a fondo esto primero veremos algunos resultados. 9.2 Derivación bajo el signo integral Teorema de Leibniz: Sea \\(f:[a,b]\\times[c,d]\\subset\\mathbb{R}^2\\rightarrow\\mathbb{R}\\) una función continua y sean \\(\\alpha,\\beta:[c,d]\\rightarrow\\mathbb{R}\\) funciones derivables tales que \\[a\\leq \\alpha(y)\\leq x\\leq\\beta(y)\\leq b\\quad\\forall y \\in [c,d]\\] supongamos que \\(\\frac{\\partial f}{\\partial y}\\) existe y es continua en el conjunto \\[T=\\{(x,y)\\mathbb{R}^2 | \\alpha(y)\\leq x \\leq\\beta(y),\\quad y \\in [c,d]\\}\\] entonces \\[F(y)=\\displaystyle\\int_{\\alpha(y)}^{\\beta(y)}f(x,y)dx\\] existe es derivable \\(\\forall y\\in [c,d]\\) y \\[F&#39;(y)=\\displaystyle\\int_{\\alpha(y)}^{\\beta(y)}\\frac{\\partial f(x,y)}{\\partial y}dx+f(\\beta(y),y)\\beta&#39;(y)+f(\\alpha(y),y)\\alpha&#39;(y)\\] Nota: Si \\(\\alpha\\) y \\(\\beta\\) son funciones constantes, entonces: \\[\\frac{d}{dy}\\displaystyle\\int_\\alpha^\\beta f(x,y)dx=\\displaystyle\\int_\\alpha^\\beta\\frac{d}{dy}f(x,y)dx\\] 9.3 Teorema de probabilidad total en el caso continuo: Sea \\(X\\) y \\(Y\\) v.a. continuas con \\(f_X(t)\\) y \\(f_Y(t)\\) sus respectivas funciones de densidad. Entonces: \\(F_Y(t)\\hspace{0.4em}\\ddot{=}\\hspace{0.4em}\\mathbb{P}[Y\\leq t]=\\displaystyle\\int_{\\mathbb{R}}\\mathbb{P}[Y\\leq t | X=x]f_X(x)dx\\hspace{0.4em}\\ddot{=}\\hspace{0.4em}\\displaystyle\\int_{\\mathbb{R}}F_{Y|X=x}(t)F_X(x)dx\\) Demostración. Llamemos \\(A\\hspace{0.4em}\\ddot{=}\\hspace{0.4em}Y\\leq t\\) el evento “‘\\(Y\\)’ fue menor o igual a ‘\\(t\\)’”. Entonces: \\[\\mathbb{I}_A(t)\\sim Ber(\\mathbb{P}[A]\\hspace{0.4em}\\ddot{=}\\hspace{0.4em}F_Y(t))\\] Recuerden que \\(\\mathbb{E}[Y|X]\\) es una v.a que depende del valor que toma \\(X\\). Así: \\[\\begin{eqnarray*} {F_Y(t)}&amp;=&amp; \\mathbb{E}[\\mathbb{I}_A(t)]=\\mathbb{E}[\\mathbb{E}[\\mathbb{I}_A(t)|X]]\\quad {\\left\\{\\begin{array}{lcc} \\text{Aplicando esperanza} \\\\ \\text{iterada.} \\end{array}\\right.}\\\\ &amp;=&amp;\\int_{\\mathbb{R}}E[\\mathbb{I}_A(t)|X=x]f_X(x)dx\\quad{\\left\\{\\begin{array}{lcc} \\text{Aplicando el teorema del} \\\\ \\text{estadístico inconsciente.} \\end{array}\\right.}\\\\ {\\mathbb{E}[\\mathbb{I}_A(t)|X=x]}&amp;{=}&amp;{0\\cdotp\\mathbb{P}[\\neg A | X=x]+1\\cdotp\\mathbb{P}[A | X=x]=\\mathbb{P}[A | X=x]}\\\\ &amp;=&amp;\\int_{\\mathbb{R}}\\mathbb{P}[A|X=x]f_X(x)dx\\quad{\\left\\{\\begin{array}{lcc} \\mathbb{I}_A(t)|X=x\\sim Ber(\\mathbb{P}[A|X=x]) \\\\ \\text{esto pues } \\mathbb{I}_A(t)\\in\\{0,1\\}\\text{ siempre.} \\end{array}\\right.}\\\\ &amp;=&amp;\\int_{\\mathbb{R}}\\mathbb{P}[Y\\leq t | X=x]F_X(x)dx\\quad{\\left\\{\\begin{array}{lcc} \\\\ \\text{Por definición de A.}\\\\ \\end{array}\\right.}\\\\ \\ \\ &amp;\\ddot{=}&amp;\\ \\ {\\int_{\\mathbb{R}}F_{Y|X=x}(t)f_X(x)dx} \\end{eqnarray*}\\] Una vez teniendo el resultado anterior con v.a. continuas, recordemos el Teorema de probabilidad total en el caso discreto: 9.4 Teorema de probabilidad total en el caso discreto: Si \\(X,Y\\) son v.a. con soporte en los \\(\\mathbb{N}\\cup\\{0\\}\\) entonces: \\[f_Y(t)=\\mathbb{P}[Y=t]=\\displaystyle\\sum_{x=0}^{\\infty}\\mathbb{P}[Y=t | X=x]\\mathbb{P}[X=x]=\\displaystyle\\sum_{x=0}^\\infty f_{Y|X=x}(t)f_X(x)\\] Pero esta notación con “\\(f\\)” no debe confundirse, sería “muy cómodo” simplemente cambiar la suma por una integral para decir que es válido en el caso continuo, pero estaríamos abusando de la notación y reaccionando de una manera heurística al confundir \\(f\\) con \\(\\mathbb{P}.\\) Link de YouTube: https://youtu.be/pJI8LfnPPB8 Sin embargo, y como ha pasado antes en la historia, la idea anterior es correcta pero no directamente del caso discreto. En el pasado, por ejemplo, la gente afirmaba lo siguiente sin haber realizado una prueba formal de que esto ocurría: \\(\\mathbb E [g(x)] = \\int_{\\mathbb R} g(x) dF_{x} =\\) \\(\\left\\{ \\begin{array}{lcc} \\int_{\\mathbb R} g(x)f_{x}(x)dx &amp; si &amp; x\\ \\ es \\ \\ continua\\\\\\\\ \\sum_{\\forall c} g(x)f_{x}(x) &amp; si &amp; x\\ \\ es\\ discreta\\\\ \\end{array} \\right.\\) Es la fórmula del estadístico inconsciente. De ahí recibe su nombre y la llamada “suerte del estadístico”. El teorema de probabilidad total para el caso continuo se da por que: Gracias al último resultado, tenemos que: \\(F_{y}(t) = \\int_{\\mathbb R} F_{y | x = x} (t) f_{x}(x) dx\\) \\(\\longrightarrow f_{y}(t) \\doteq \\frac{d}{dt} F_{y}(t) = \\frac{d}{dt} \\int_{R} F_{y | x = x}(t)f_{x}(x)dx\\) \\(\\int_{\\mathbb R} \\frac{d}{dt} F_{y|x=x}(x)f(x)dx\\) { \\(\\left\\{ \\begin{array}{lcc} aplicando\\ \\ la\\ \\ regla\\ \\ de\\ \\ derivacion\\ \\ bajo\\\\ el\\ \\ signo\\ \\ integral\\\\ \\end{array} \\right.\\) \\(\\therefore f_{y}(t) = \\int_{\\mathbb R} f_{y|x=x}(t) f_{x}(x)dx\\) Teniendo en mente estos resultados anteriores, podemos seguir con el tema de obtener probabilidad de el riesgo S. Consideremos \\(x,y\\) v.a.i. discretas y tomemos \\(S\\doteq x+y\\), notemos que \\(S\\) es también discreta y además: \\[\\begin{eqnarray*} f_{s}(t) &amp;=&amp; \\mathbb P [S=t] = \\mathbb P[x+y=t] = \\mathbb P [x = t-y]\\\\ &amp;=&amp; \\sum_{\\forall y} \\mathbb P [x=t-y|y=y] \\mathbb[y=y] { \\left\\{ \\begin{array}{lcc} Probabilidad \\\\ total\\\\ \\end{array} \\right.}\\\\ &amp;=&amp; \\sum_{\\forall y} \\mathbb P [x=t-y] \\mathbb[y=y] { \\left\\{ \\begin{array}{lcc} Pues\\\\ X \\perp Y\\\\ y\\\\ además\\\\Y=y \\end{array} \\right.} \\\\ &amp;=&amp; \\sum_{\\forall{y}} f_{x}(t-{y})f_{y}({y}) = \\mathbb E[f_{x}(t-y)]\\\\ \\end{eqnarray*}\\] Por lo tanto, para cualesquiera par de v.a.i. \\(X,Y\\) discretas y tomando \\(S=X+Y\\) entonces: \\[\\begin{eqnarray*} f_{s}(t) = \\underbrace{{ \\sum_{\\forall{y}} f_{x}(t-{y})f_{y}({y}) }}_{\\text{Convolución}} = \\mathbb E[f_{x}(t-y)] \\end{eqnarray*}\\] o bien: \\[\\begin{eqnarray*} f_{s}(t) = \\underbrace{{ \\sum_{\\forall{x}} f_{x}(t-{x})f_{x}({x}) }}_{\\text{Convolución}}\\mathbb E[f_{x}(t-y)] \\end{eqnarray*}\\] Un resultado similar sucede en el caso continuo. Consideremos \\(X,Y\\) v.a.i. continuas y tomemos \\(S\\doteq X+Y\\), notemos que S es también continua y además: \\[\\begin{eqnarray*} F_{S}(t) &amp;\\doteq&amp; \\mathbb P [S\\leq t] = \\mathbb P [X+Y\\leq t]\\mathbb P [X\\leq t-Y] \\\\ &amp;=&amp; \\int_{\\mathbb R} \\mathbb P[X\\leq t-y|Y=y] f_{Y}(y)dy { \\left\\{ \\begin{array}{lcc} Probabilidad\\ \\ Total\\ \\ en\\ \\ el\\\\ caso\\ \\ continuo\\\\ \\end{array} \\right.}\\\\ &amp;=&amp; \\int_{\\mathbb R} \\mathbb P[X\\leq t-y] f_{Y}(y)dy { \\left\\{ \\begin{array}{lcc} X\\perp Y\\ \\ \\\\ \\longrightarrow \\mathbb P[X t-y|Y=y] = P[X\\leq t-y]\\\\ \\end{array} \\right.}\\\\ &amp;\\doteq&amp; \\int_{\\mathbb R} F_{X}(t-y)f_{Y}(y)dy = \\mathbb E[F_{X}(t-Y)]\\\\ \\end{eqnarray*}\\] Por lo tanto, para cualesquiera par de v.a.i. \\(X,Y\\) continuas y tomando \\(S=X+Y\\) entonces: \\[\\begin{eqnarray*} F_{s}(t) = \\underbrace{{ \\int_{\\mathbb R} F_{X}(t-{y})f_{Y}({y})d{y} }}_{\\text{Convolución}}= \\mathbb E[F_{X}(t-Y)] \\end{eqnarray*}\\] o bien: \\[\\begin{eqnarray*} F_{s}(t) = \\underbrace{{ \\int_{\\mathbb R} F_{X}(t-{x})f_{X}({x})d{x} }}_{\\text{Convolución}} = \\mathbb E[F_{Y}(t-Y)] \\end{eqnarray*}\\] Del resultado anterior se sigue que: \\[\\begin{align*} f_{S}(t) &amp;= \\frac{d}{dt} F_{S}(t) = \\frac{d}{dt} \\int_{\\mathbb R} F_{X}(t-y)f_{Y}(y)dy\\\\ &amp;= \\int_{\\mathbb R} \\frac{d}{dt} F_{X}(t-y)f_{Y}(y)dy { \\left\\{ \\begin{array}{lcc} \\\\ Aplicando \\ \\ la \\ \\ regla \\ \\ de \\ \\ Leibniz\\\\ \\ \\ de \\ \\ derivacion \\ \\ bajo \\ \\ el\\ \\ signo \\ \\ integral \\end{array} \\right.}\\\\ &amp;= \\int_{\\mathbb R}f_{X}(t-y)f_{Y}(y)dy = \\mathbb E [f_{X}(t-Y)]\\\\ \\end{align*}\\] Por lo tanto, para culesquiera par de v.a.i. \\(X,Y\\) continuas y tomando \\(S=X+Y\\) entonces: \\[\\begin{align*} F_{s}(t) = \\underbrace{{ \\int_{\\mathbb R} f_{X}(t-{y})f_{Y}({y})d{y} }}_\\text{Convolución} = \\mathbb E[F_{X}(t-Y)]\\\\ \\end{align*}\\] o bien: \\[\\begin{align*} F_{s}(t) = \\underbrace{{ \\int_{\\mathbb R} f_{Y}(t-{x})f_{X}({x})d{x} }}_\\text{Convolución} = \\mathbb E[F_{Y}(t-X)]\\\\ \\end{align*}\\] Que es básicamente el mismo resultado que en el caso discreto. En resumen: Sumas y Convoluciones Si \\(X\\) e \\(Y\\) son variables aleatorias independientes con f.d. \\(F_{X}\\) y \\(F_{Y}\\), respectivamente, entonces la f.d. de la suma \\(Z=X+Y\\) es la convolución de \\(F_{x}\\) y \\(F_{Y}\\) \\[F_{Z} = \\int_{-\\infty}^{\\infty} F_{X}(z-t)dF_{Y}(t) = \\int_{-\\infty}^{\\infty} F_{Y}(z-t)dF_{X}(t)\\] Si \\(X\\) e \\(Y\\) toman valores en los enteros no-negativos con funciones de probabilidad despectivas \\(p_{X}\\) y \\(p_{Y}\\) entonces: \\[p_{z}(n) = P(Z=n) = \\sum_{i=0}^{n} P(X=i) P(Y=n-i) = \\sum_{i=0}^{n} p_{X}(i) p_{Y}(n-i) = \\sum_{i=0}^{n} p_{X}(n-i) p_{Y}(i)\\] Si consideramos la situación en la cual \\(X\\) tienen \\(Y\\) densidades \\(f_{x}\\) y \\(f_{Y}\\), respectivamente, la densidad \\(f_{z}\\) de la suma es la convolución de las densidades \\(f_{x}\\) y \\(f_{Y}\\): \\[f_{z}(z)= \\int_{-\\infty}^{\\infty} f_{X}(z-t)f_{Y}(t)dt = \\int_{-\\infty}^{\\infty} f_{Y}(z-t)f_{X}(t)dt\\] Nota: \\(\\frac{dF_{Y}(t)}{dt} = f_{Y}(t) \\Longleftrightarrow dF_{Y}(t) = f_{Y}(t)dt\\) Ahora, pensando en el modelo individual, definamos \\(X_{j} \\doteq C_{j}D_{j}\\) entonces \\(\\{X_{j}\\}_{j=1}^{n}\\) son v.a.i. \\(\\forall j \\in \\{1,...,n\\}\\). \\[S_{n} \\doteq \\sum_{j=1}^{n} C_{j}D_{j} \\doteq \\sum_{j=1}^{n} X_{j}\\] Luego, notemos que \\(S_{n-1} \\perp X_{n}\\) pues \\(\\{X_{j}\\}_{j=1}^{n-1} \\perp X_{n}\\). De hecho \\(S_{n-k} \\perp X_{m}\\) \\(\\forall m \\in \\{ n-k+1,...,n \\}\\) y variando \\(k\\in\\{ 1,...,n-1 \\}\\). Entonces aplicando los resultados obtenidos anteriormente tendríamos en particular para el caso continuo con la función de distribución: \\[\\begin{eqnarray*} F_{S_{n}}(t) &amp;=&amp; \\int_{\\mathbb R} F_{S_{n-1}}(t-x_{n}) f_{x_{n}}(x_{n}) dx_{n}\\\\ &amp;=&amp; \\int_{\\mathbb R} (\\int_{\\mathbb R} F_{S_{n-2}}(t-x_{n}-x_{n-1}) f_{x_{n-1}}(x_{n-1}) dx_{n-1} ) f_{x_{n}}(x_{n}) dx_{n} \\\\ &amp;=&amp; \\int_{\\mathbb R} (\\int_{\\mathbb R} ( \\int_{\\mathbb R} F_{S_{n-3}}(t-\\sum_{j=0}^{2} x_{n-j}) f_{x_{n-2}}(x_{n-2}) dx_{n-2} ) dx_{n-1} ) f_{x_{n}}(x_{n}) dx_{n} \\\\ &amp;=&amp; ... = \\underbrace{ \\int_{\\mathbb R} \\int_{\\mathbb R}... \\int_{\\mathbb R} }_\\text{n-1 veces} F_{S_{n-3}}(t-\\sum_{j=0}^{n-2} x_{n-j}) f_{x_{2}}(x_{2}) dx_{2}... f_{x_{n-1}}(x_{n-1}) dx_{n-1} f_{x_{n}}(x_{n}) dx_{n} \\\\ \\end{eqnarray*}\\] Estos cálculos obtienen probabilidades exactas del riesgo y así tendríamos una expresión de la probabilidad de \\(S\\) en términos de sus sumandos \\(\\{X_{j}\\}_{j=1}^{n}\\). Como hacer cálculos como el anterior es “demasiado fácil”, se ha optado por alternativas que nos ayudan a calcular probabilidades mediante ciertas aproximaciones o simplemente asumiendo casos particulares un tanto más manejables. 9.5 Aproximación Normal Recordemos el siguiente teorema: TEOREMA CENTRAL DEL LÍMITE Sea \\(X_{1},X_{2},...\\) una sucesión de variables aleatorias independientes e idénticamente distribuidas tales que para cada natural \\(n\\), $E(X_{n}) = $ y \\(Var(X_{n}) = \\sigma^2 &lt; \\infty\\). Entonces \\[\\frac{X_{1}+...+X_{n}-n\\mu}{\\sqrt{n}\\sigma} \\longrightarrow^{d} N(0,1)\\] Cuando n es grande y el portafolio de asegurados es homogéneo en el sentido de que las variables \\(D_{j}C_{j}\\) son idénticamente distribuidas con segundo momento finito, puede usarse el teorema central del límite para aproximar la distribución de \\(S\\) mediante la distribución normal, es decir, \\[P(S\\leq x) = P\\left( \\displaystyle\\frac{S-E(S)}{\\sqrt{Var(S)}}\\leq \\frac{x-E(S)}{\\sqrt{Var(S)}} \\right) \\approx \\Phi\\left(\\displaystyle\\frac{x-E(S)}{\\sqrt{Var(S)}}\\right)\\] Esta aproximación puede ser adecuada para ciertos riesgos pero tiene la desventaja de que asigna una probabilidad positiva al intervalo \\((\\infty,0)\\),lo cual no es consistente con el hecho de que \\(S\\geq 0\\). Sin embargo, dado que la distribución \\(N(\\mu,\\sigma^{2})\\) se concentra principalmente en el intervalo \\((\\mu - 4\\sigma,\\mu + 4\\sigma)\\), cuando la esperanza y la varianza de \\(S\\) son tales que \\(E(S) -4\\sqrt{Var(S)} \\geq 0\\), la probabilidad asignada a la parte negativa del eje es realmente pequeña, ello alivia un poco el hecho de que esta distribución no tenga soporte en el intervalo \\([0,\\infty)\\). Tal vez la situación más comprometedora sea que la función de densidad normal decae muy rápidamente pues existen riesgos cuyas funciones de densidad no cumplen con tal característica. Nota: Si \\(X_{j} \\doteq C_{j}D_{j}\\) y \\(\\{X_{j}\\}_{j=1}^{n}\\) v.a.i.i.d. tomando \\(S \\doteq \\sum_{j=1}^{n} X_{j}\\) entonces: Ejercicio al lector: \\[\\begin{eqnarray*} \\left\\{ \\begin{array}{lcc} \\circ \\mathbb E [S] = n \\mathbb E [X]\\\\\\\\ \\circ Var(S) = n Var(X) \\\\ \\end{array} \\right. \\end{eqnarray*}\\] Ejemplo: Supongamos un grupo homogéneo de asegurados tales que \\(D_{j} \\sim Ber(0.1)\\) y \\(C_{j} \\sim X_{(3)}^{2}\\). Tomando \\(X_{j} \\doteq D_{j} \\bullet C_{j}\\) entonces: \\[\\begin{eqnarray*} \\mathbb E[X_{j}] &amp;=&amp; \\mathbb E[D_{j}] \\mathbb E[C_{j}] \\left\\{ \\begin{array}{lcc} D_{j}\\perp C_{j} \\ \\forall j\\\\ \\end{array} \\right. \\\\ &amp;=&amp; (0.1)(3)\\\\ &amp;=&amp; 0.3 \\ \\forall j \\end{eqnarray*}\\] \\[\\begin{eqnarray*} \\mathbb E[X_{j}^{2}] &amp;=&amp; \\mathbb E[(D_{j}C_{j})^{2}] \\\\ &amp;=&amp; \\mathbb E[D_{j}^{2}] \\mathbb E[C_{j}^{2}] \\left\\{ \\begin{array}{lcc} D_{j}\\perp C_{j}\\\\ \\end{array} \\right. \\\\ &amp;=&amp; [(0.9)(0.1)+(0.1)^{2}][2(3)+3^2]\\\\ &amp;=&amp; 1.5 \\ \\forall j \\end{eqnarray*}\\] \\(\\Longrightarrow Var(X_{j}) = \\mathbb E[X_{j}^{2}] - \\mathbb E^{2}[X_{j}] = 1.5 - 0.3^{2} = 1.41 \\ \\forall j\\) Considerando un portafolio con n=150 pólizas, calculamos la media y varianza del riesgo S. \\(\\circ \\mathbb E[S] = n \\mathbb E[X] = 150 (0.3) = 45\\) \\(\\circ Var(S) = n Var(X) = 150 (1.42) = 211.5\\) Bajo aproximación normal tenemos: \\[\\begin{eqnarray*} F_{S}(t)&amp;=&amp; \\mathbb{P}[S \\leq t]\\\\ &amp;=&amp; \\mathbb{P}\\left[ \\displaystyle\\frac{S- \\mathbb{E}[S]}{\\sqrt{Var(S)}} \\leq \\displaystyle\\frac{t-\\mathbb{E}[S]}{\\sqrt{Var(S)}} \\right]\\\\ &amp;\\approx&amp; \\phi\\left( \\displaystyle\\frac{t-\\mathbb{E}[S]}{\\sqrt{Var(S)}} \\right) \\end{eqnarray*}\\] Entonces \\[\\begin{eqnarray*} F_{S}(t)&amp;\\approx&amp; \\phi\\left( \\displaystyle\\frac{t-\\mathbb{E}[S]}{\\sqrt{Var(S)}}\\right) \\quad \\forall t \\geq 0 \\\\ \\end{eqnarray*}\\] Con lo cual podemos probabilidades del riesgo \\(S\\) y misma herramienta para cuantiles. Por ejemplo si quisiéramos saber cuál es la probabilidad de aproximada de que S sea menor a \\(65\\) entonces: \\[\\begin{eqnarray*} F_{S}(65)&amp;\\approx&amp; \\phi\\left( \\displaystyle\\frac{65-45}{\\sqrt{211.5)}}\\right) \\\\ &amp;=&amp; 0.9154697\\\\ \\end{eqnarray*}\\] También si quisiéramos obtener un cuantil de probabilidad \\(p\\), podríamos estimarlo de forma general: \\[\\begin{equation*} \\phi\\left( \\displaystyle\\frac{t_{0}-\\mathbb{E}[S]}{\\sqrt{Var(S)}}\\right)=p \\Leftrightarrow q_{S}(p) \\approx t_{0} = \\sqrt{Var(S)} \\phi^{-1}(p)+\\mathbb{E}(S) \\\\ \\end{equation*}\\] Que en nuestro ejemplo sería para \\(p=97.5\\%\\) \\[\\begin{equation*} q_{S}(97.5\\%) \\approx t_{0} = \\sqrt{211.5} (1.96)+45 \\ \\approx \\ 73.50383\\\\ \\end{equation*}\\] Un video con otra aplicación relacionada con el tema lo pueden ver a continuación: Link de YouTube: https://www.youtube.com/watch?v=TAjhROWBkiE Ahora, intentemos obtener probabilidades mezclas de un riesgo, pero buscando simplificar el problema con un ejemplo: Supongamos que \\(D_{j} \\sim Ber(0,1)\\) y que \\(C_{j}\\) tiene la siguiente f.m.p. \\[\\begin{eqnarray*} \\mathbb{P}[C_{j}=C] &amp;=&amp; \\left \\{ \\begin{matrix} 0.8 &amp; \\mbox{si }&amp; C=1 &amp; \\forall j \\\\ 0.2 &amp;\\mbox{si } &amp; C=2 \\\\ 0 &amp; &amp; e.o.c \\end{matrix}\\right. \\end{eqnarray*}\\] Tomando un portafolio con \\(n=3\\) pólizas bajo el modelo individual, busquemos probabilidades de \\(S\\). Notemos primero que \\(S \\ddot{=} \\displaystyle\\sum_{i=1}^{n} x_{i} \\in \\{0,1,2,3,4,5,6 \\}\\). Cuando \\(S=0\\) fue porque: \\[\\begin{equation*} { \\overbrace{ \\underbrace{C_{1} D_{1}}_{\\text{asegurado 1}}= \\underbrace{C_{2} D_{2}}_{\\text{asegurado 2}}= \\underbrace{C_{3} D_{3}}_{\\text{asegurado 3}}}^{\\text{Reclamaciones por asegurado}}}= 0 \\quad \\quad \\xrightarrow{\\text{la denotamos}} \\quad \\quad \\overbrace{(0,0,0)}^{\\text{suman cero}} \\end{equation*}\\] Entonces \\(S=0\\). ¡Solo hay un caso posible! Cuando S=1 fue porque: \\[\\begin{equation} \\underbrace{{\\overbrace{{\\{(1,0,0) \\} }}^{{\\text{ evento #1}}}} {\\bigcup} {\\overbrace{{\\{(0,1,0) \\} }}^{{\\text{ evento #2}}}} {\\bigcup} \\overbrace{\\{(0,0,1) \\} }^{\\text{ evento #3}}}_{\\text{Posibles eventos}} \\quad \\longrightarrow \\quad \\text{Hay 3 casos} \\end{equation}\\] Recordemos un poco de combinatoria antes de continuar. ¿Cuantas “palabras” diferentes podemos formar con las letras de la palabra mississippi? \\(\\displaystyle\\frac{m}{1} \\quad \\displaystyle\\frac{i}{2}\\quad \\displaystyle\\frac{s}{3} \\quad \\displaystyle\\frac{s}{4} \\quad \\displaystyle\\frac{i}{5}\\quad \\displaystyle\\frac{s}{6}\\quad \\displaystyle\\frac{s}{7}\\quad \\displaystyle\\frac{i}{8}\\quad \\displaystyle\\frac{p}{9}\\quad \\displaystyle\\frac{p}{10}\\quad \\displaystyle\\frac{i}{11} \\longrightarrow\\) Hay 11 letras. \\(\\displaystyle\\frac{m}{1} \\quad \\displaystyle\\frac{i}{2}\\quad \\displaystyle\\frac{s}{3} \\quad \\displaystyle\\frac{p}{4} \\longrightarrow\\) pero solamente hay 4 letras diferentes. Pero contamos con una “m”, cuatro “i” , cuatro “s” , y dos “p” . Como buscamos ’’palabras” diferentes, buscamos hacer permutaciones. Utilizando el coeficiente multinomial tenemos: \\(\\displaystyle\\frac{11!}{1! 4! 4! 2!}= 34,650\\) palabras diferentes/permutaciones. Una vez visto esto, seguimos sin contar tanto. a. (2,0,0) y este evento puede suceder de \\(\\displaystyle\\frac{3!}{1! 2!}=3\\) formas diferentes. O bien puede pasar que: b. (1,1,0) y este evento puede suceder de \\(\\displaystyle\\frac{3!}{2!1!}=3\\) formas diferentes. Para un total de 6 casos distintos. Cuando \\(S=3\\) fue porque: \\[\\begin{eqnarray*} \\left. \\begin{matrix} (2,1,0); &amp; 3!= 6&amp; \\text{casos} \\\\ (1,1,1); &amp;1 &amp;\\text{caso}\\\\ \\end{matrix}\\right\\} \\text{7 casos} \\end{eqnarray*}\\] Cuando \\(S=4\\) fue porque: \\[\\begin{eqnarray*} \\left. \\begin{matrix} (2,2,0); &amp; \\displaystyle\\frac{3!}{2!}=3&amp; \\text{casos} \\\\ (1,1,2); &amp;\\displaystyle\\frac{3!}{2!}=3 &amp;\\text{casos}\\\\ \\end{matrix}\\right\\} \\text{6 casos} \\end{eqnarray*}\\] Cuando \\(S=5\\) fue porque: \\[\\begin{equation*} (2,2,1); \\quad \\displaystyle\\frac{3!}{2!}= 3 \\quad \\text{casos} \\\\ \\end{equation*}\\] Cuando S=6 fue porque: \\[\\begin{equation*} (2,2,2); \\quad \\text{solo hay un caso} \\\\ \\end{equation*}\\] Ahora que tenemos la cantidad de casos, vamos a calcular probabilidades del riesgo \\(S\\). Denotemos como \\(X_{i}= D_{i} C_{i} \\forall i \\quad \\in \\{1,2,3 \\}\\). Entonces: \\[\\begin{eqnarray*} \\mathbb{P}[S=t]&amp;=&amp; \\mathbb{P}[D_{1}C_{1}+ D_{2}C_{2} +D_{2}C_{2} =t]\\\\ &amp;=&amp; \\mathbb{P}[X_{1}+X_{2}+X_{3}=t] \\forall t \\in \\{0,1,...6\\}\\\\ \\end{eqnarray*}\\] 1. \\(t=0\\) \\[\\begin{equation*} \\left. \\begin{array}{rcl} \\mathbb{P}[S=0]&amp;=&amp; \\mathbb{P}[X_{1}+X_{2} + X_{3}=0]\\\\ &amp;=&amp;\\mathbb{P}[X_{1}=0,X_{2}=0 , X_{3}=0]\\\\ &amp;=&amp;\\mathbb{P}[X_{1}=0]\\mathbb{P}[X_{2}=0]\\mathbb{P}[X_{3}=0]\\\\ &amp;=&amp;\\mathbb{P}[X=0]\\\\ &amp;=&amp;\\mathbb{P}[\\text{No hubo reclamación}]\\\\ &amp;=&amp; 0.9^{3}\\\\ \\end{array} \\right\\} {\\text{Todo pues $ X_{i} \\geq, X_{i} \\perp X_{j}$ si $i \\leq j X_{i} $, son i.d}} \\end{equation*}\\] 2. \\(t=1\\) \\[\\begin{eqnarray*} \\mathbb{P}[S=1]&amp;=&amp; \\mathbb{P}[X_{1}+X_{2} + X_{3}=1]\\\\ &amp;=&amp; \\mathbb{P}[\\{ X_{1}=0,X_{2}=0 , X_{3}=0 \\} {\\cup }\\{ X_{1}=0,X_{2}=1 , X_{3}=0 \\} {\\cup } \\{ X_{1}=0,X_{2}=0 , X_{3}=1 \\} ]\\\\ &amp;=&amp;\\mathbb{P}[\\{ X_{1}=0,X_{2}=0 , X_{3}=0 \\}]+\\mathbb{P}[\\{ X_{1}=0,X_{2}=1 , X_{3}=0 \\} ]+\\mathbb{P}[\\{ X_{1}=0,X_{2}=0 , X_{3}=1 \\}]\\\\ &amp;=&amp; 3\\mathbb{P}[(1,0,0)]\\\\ &amp;=&amp; 3[{\\underbrace{{(0.1)(0.8)}}_{{\\text{ 1 reclamo \\$1}}}}][{\\underbrace{{0.9^{2}}}_{{\\text{ 2 no reclamaron}}}}] \\quad {\\text{Pues cada evento es ajeno y las v.a son i.i.d}}\\\\ \\end{eqnarray*}\\] Nota: Si \\(a \\in \\{ 1,2\\} \\Rightarrow \\mathbb{P}[CD=a]=\\mathbb{P}[D=1, C=a]=\\mathbb{P}[D=1]\\mathbb{P}[C=a]\\) 3. \\(t=2\\) \\[\\begin{eqnarray*} \\mathbb{P}[S=2]&amp;=&amp;[{\\overbrace{{3}}^{{\\text{ # De veces que ocurre el evento}}}}]\\quad \\cdot \\quad {\\underbrace{{\\mathbb{P}[{\\overbrace{{(2,0,0)}}^{\\text{# De veces que ocurre el evento}}}]}}_{{\\text{Evento en probabilidad}}}} \\\\ &amp;=&amp;{\\underbrace{{ 3\\cdot [(0.1)(0.2)][0.9]^{2}}}_{{\\text{Evento en probabilidad}}}} + 3 \\cdot [(0.1)(0.8)]^{2}[0.9] \\end{eqnarray*}\\] 4. \\(t=3\\) \\[\\begin{eqnarray*} \\mathbb{P}[S=3]&amp;=&amp;6\\cdot \\mathbb{P}[(2,1,0)]+\\mathbb{P}[(1,1,1)]\\\\ &amp;=&amp; 6 \\cdot [(0.1)(0.2)][(0.1)(0.8)][0.9]+[(0.1)(0.8)]^{3}\\\\ \\end{eqnarray*}\\] 5. \\(t=4\\) \\[\\begin{eqnarray*} \\mathbb{P}[S=4]&amp;=&amp;6\\cdot \\mathbb{P}[(2,2,0)]+\\mathbb{P}[(1,1,2)]\\\\ &amp;=&amp; 3 \\cdot [(0.1)(0.2)]^{2}[0.9]+3\\cdot [(0.1)(0.8)]^{2}[(0.1)(0.2)]\\\\ \\end{eqnarray*}\\] 5. \\(t=5\\) \\[\\begin{eqnarray*} \\mathbb{P}[S=5]&amp;=&amp;6\\cdot \\mathbb{P}[(2,2,1)]\\\\ &amp;=&amp; 3 \\cdot (0.1)^{3}[(0.2)^{2}(0.8)]\\\\ \\end{eqnarray*}\\] 6. \\(t=6\\) \\[\\begin{eqnarray*} \\mathbb{P}[S=6]&amp;=&amp;6\\cdot \\mathbb{P}[(2,2,2)]\\\\ &amp;=&amp; [(0.1)(0.2)]^{3} \\\\ \\end{eqnarray*}\\] Lo cual nos permite contar con las probabilidades exactas de \\(S\\). Así, su f.m.p es: \\[\\begin{eqnarray*} f_{S}(t)&amp;=&amp; \\mathbb{P}[S=t]\\\\ &amp;=&amp; \\left \\{ \\begin{matrix} 72.9\\% &amp; \\mbox{si } &amp; t=0 &amp; \\\\ 19.44 \\%&amp;\\mbox{si } &amp; t=1 \\\\ 6.588\\% &amp;\\mbox{si } &amp; t=2 \\\\ 0.9152 \\%&amp;\\mbox{si } &amp; t=3 \\\\ 0.1464 \\%&amp;\\mbox{si } &amp; t=7 \\\\ 0.0096 \\%&amp;\\mbox{si } &amp; t=5 \\\\ 0.0008 \\%&amp;\\mbox{si } &amp; t=6 \\\\ 0 &amp; &amp; e.o.c \\end{matrix}\\right. \\end{eqnarray*}\\] "],["modelo-individual-formula-de-pril.html", "Capítulo 10 Modelo individual: formula de Pril 10.1 Formula de Pril", " Capítulo 10 Modelo individual: formula de Pril Nuestro objetivo ahora es encontrar probabilidades exactas de \\(S\\). Para eso, haremos supuesto que puedan facilitar los cálculos. Bajo ciertos supuestos, existe una metodología recursiva muy conocida para calcular probabilidades exactas de \\(S\\). Nosotros nos enfocaremos principalmente en su aplicación 10.1 Formula de Pril Presentaremos a continuación la formula de Pril. Este resultado fue mostrado por Nelson De Pril en 1986 y proporciona una expresión exacta, aunque recursiva de la distribución de probabilidad de un riesgo en el modelo individual. La formula es bastante general aunque presupone que las reclamaciones toman los valores en el conjunto \\(\\{1,2,...\\}\\). Este supuesto no es realmente una restricción fuerte pues en la práctica el pago de siniestros se realiza siempre usando alguna unidad monetaria. Para establecer la fórmula De Pril es necesario dividir el portafolio de \\(n\\) asegurados de acuerdo a la tasa de mortalidad y la suma asegurada. Denotaremos por \\(n_{ij}\\) al número de asegurados que tienen probabilidad de reclamación \\(q_{j}\\) y monto de reclamación \\(i\\), en donde \\(i\\) toma valores en \\(\\{1,2,...,I \\}\\) y \\(j\\) en \\(\\{1,2,...,J \\}\\). De esta forma se tiene el Cuadro 1 en donde la suma de las entradas es \\(n_{i}\\), es decir: \\[\\begin{eqnarray*} n=\\sum_{i=1}^{I}\\sum_{j=1}^{J}n_{ij}\\\\ \\end{eqnarray*}\\] Denotaremos por \\(Y_{ij}\\) el monto real reclamado por un asegurado cuya probabilidad de reclamación es \\(q_{j}\\) y posible monto reclamado \\(i\\), es ,decir, \\[\\begin{eqnarray*} Y_{ij}= \\left \\{ \\begin{matrix} 0&amp; \\text{con probabilidad}&amp; 1-q_{j} \\\\ i&amp;\\text{con probabilidad} &amp; q_{j} \\\\ \\end{matrix}\\right. \\end{eqnarray*}\\] Cuadro 1. Probabilidad de reclamación - Monto de la reclamación Teorema: Formula De Pril (i) Sea \\(n_{ij}\\) el número de pólizas cuyos asegurados tienen tasa de mortalidad \\(q_{j}\\) y suma asegurada \\(i\\). Suponga que \\(j =1,2,...,J\\) e \\(i=1,2,...,I\\). Entonces las probabilidades \\(g_{x}=\\mathbb{P}(S=x)\\) están dadas por: \\[\\begin{eqnarray*} g_{x}&amp;=&amp; \\displaystyle\\frac{1}{x}\\displaystyle\\sum_{i=1}^{x\\wedge I} \\displaystyle\\sum_{k=1}^{\\left \\lfloor x/i \\right \\rfloor} g_{x-ik}\\ h(i,k), \\quad \\text{para } x \\geq 1 \\\\ g_{0}&amp;=&amp; \\displaystyle\\prod_{i=1}^{I}\\displaystyle\\prod_{j=1}^{J}(1-q_{j})^{n_{ij}}\\\\ \\end{eqnarray*}\\] En donde: \\[\\begin{eqnarray*} h(i,k)&amp;=&amp; i(-1)^{k-1} \\displaystyle\\sum_{j=1}^{J} n_{ij} \\left ( \\displaystyle\\frac{q_{j}}{1-q_{j}} \\right)^{k} \\end{eqnarray*}\\] Nota: \\[\\begin{equation*} x\\wedge I \\ddot{=} mín \\{ x, I\\} \\end{equation*}\\] Demostración. La función generadora de probabilidad del monto reclamado \\(Y_{ij}\\) por un asegurado con probabilidad de reclamación \\(q_{j}\\), y monto reclamado \\(i\\) es: \\[\\begin{eqnarray*} \\mathbb{E}(t^{Y_{ij}})&amp;=&amp; (1-q_{j})+q_{j}t^{i}\\\\ \\end{eqnarray*}\\] Por lo tanto, usando la hipótesis de independencia, la función generadora de probabilidad de la cartera completa es:\\ \\[\\begin{eqnarray*} G(t)&amp;=&amp;\\mathbb{E}(t^{S})\\\\ &amp;=&amp; \\displaystyle\\sum_{r=0}^{\\infty} t^{r}g_{r}\\\\ &amp;=&amp; \\displaystyle\\prod_{i=1}^{I} \\displaystyle\\prod_{j=1}^{J} (1-q_{j}+q_{j}t^{i})^{n_{ij}}\\\\ \\end{eqnarray*}\\] En donde \\(q_{r}=\\mathbb{P}(S=r)\\). Tomando logaritmo y después derivando. \\[\\begin{eqnarray*} \\ln(G(t))&amp;=&amp; \\displaystyle\\sum_{i=1}^{I}\\displaystyle\\sum_{j=1}^{J} n_{ij} \\quad \\ln(1-q_{j}+q_{j} t^{i})\\\\ \\displaystyle\\frac{d}{dt}\\ln(G(t))&amp;=&amp;\\displaystyle\\frac{G&#39;(t)}{G(t)} \\\\ &amp;=&amp; \\displaystyle\\sum_{i=1}^{I}\\displaystyle\\sum_{j=1}^{J} n_{ij} \\displaystyle\\frac{iq_{j}t^{i-1}}{1-q_{j}+q_{j}t^{i}}\\\\ \\end{eqnarray*}\\] Por lo tanto: \\[\\begin{eqnarray*} t G&#39;(t)&amp;=&amp; G(t) \\displaystyle\\sum_{i=1}^{I}\\displaystyle\\sum_{j=1}^{J} n_{ij} \\displaystyle\\frac{iq_{j}t^{i}}{1-q_{j}+q_{j}t^{i}}\\\\ &amp;=&amp; G(t) \\displaystyle\\sum_{i=1}^{I}\\displaystyle\\sum_{j=1}^{J} n_{ij} i \\displaystyle\\frac{q_{j}t^{i}}{1-q_{j}} \\left( 1+\\displaystyle\\frac{q_{j}t^{i}}{1-q_{j}} \\right)^{-1}\\\\ &amp;=&amp; G(t) \\displaystyle\\sum_{i=1}^{I}\\displaystyle\\sum_{j=1}^{J} n_{ij} i \\displaystyle\\frac{q_{j}t^{i}}{1-q_{j}} \\displaystyle\\sum_{k=1}^{\\infty}(-1)^{k-1} \\left( \\displaystyle\\frac{q_{j}t^{i}}{1-q_{j}} \\right)^{k-1} \\\\ \\end{eqnarray*}\\] En donde hemos usado la expansión \\((1-x)^{-1}= \\displaystyle\\sum_{k=0}^{\\infty} x^{k}\\), válida para \\(|x| &lt;1\\). Por lo tanto, para valores suficientemente pequeños de \\(t\\). \\[\\begin{eqnarray*} t G&#39;(t)&amp;=&amp; G(t) \\displaystyle\\sum_{i=1}^{I}\\displaystyle\\sum_{j=1}^{J} n_{ij} i \\displaystyle\\sum_{k=1}^{\\infty}(-1)^{k-1} \\left( \\displaystyle\\frac{q_{j}}{1-q_{j}} \\right)^{k}t^{ik}. \\end{eqnarray*}\\] Defina ahora la función: \\[\\begin{eqnarray*} h(i,k)&amp;=&amp; i(-1)^{k-1} \\displaystyle\\sum_{j=1}^{J} n_{ij} \\left( \\displaystyle\\frac{q_{j}}{1-q_{j}} \\right)^{k} \\end{eqnarray*}\\] La doble suma respecto de los índices \\(j\\) y \\(k\\) es absolutamente convergente en cualquiera de los dos órdenes que se efectúen en estas sumas y el resultado es el mismo. Por lo tanto es válido el intercambio en el orden de las sumas y la expresión anterior puede escribirse como sigue: \\[\\begin{eqnarray*} t G&#39;(t)&amp;=&amp; G(t) \\displaystyle\\sum_{i=1}^{I} \\displaystyle\\sum_{k=1}^{\\infty}t^{ik} h(i,k) \\end{eqnarray*}\\] Sustituyendo de las expresiones \\(G&#39;(t)\\) y \\(G(t)\\) en sus correspondientes series de potencias se obtiene: \\[\\begin{eqnarray*} \\displaystyle\\sum_{r=1}^{\\infty}rt^{r} g_{r} &amp;=&amp; \\displaystyle\\sum_{r=0}^{\\infty} t^{r} g_{r} \\displaystyle\\sum_{i=1}^{I} \\displaystyle\\sum_{k=1}^{\\infty}t^{ik} h(i,k)\\\\ \\end{eqnarray*}\\] Para \\(x\\geq 1\\), el coeficiente de \\(t^{x}\\) en el lado izquierdo es \\(xg_{x}\\), mientras que en el lado derecho es la suma de los términos \\(g_{x-ik}h(i,k)\\) para aquellos valores de \\(i\\) y \\(k\\) tales que $ I ik x$. Se pueden establecer primero los posibles valores para \\(i\\) de la siguiente forma \\(i=1,...,x \\wedge I\\), y por lo tanto los valores para \\(k\\) son \\(k=1,...,[x/i]\\), en donde \\(x\\wedge I\\) es el valor mínimo entre \\(x\\) e \\(I\\), y \\(\\left \\lfloor x/i \\right \\rfloor\\) es la parte entera del cociente \\(x/i\\). Igualando estos coeficientes se tiene que: \\[\\begin{eqnarray*} xg_{x}&amp;=&amp; \\displaystyle\\sum_{i=1}^{x \\wedge I} \\displaystyle\\sum_{k=1}^{\\left \\lfloor x/i \\right \\rfloor} g_{x-ik} h(i,k)\\\\ \\end{eqnarray*}\\] De esta forma se llega a la siguiente expresión, para \\(x \\geq 1\\): \\[\\begin{eqnarray*} g_{x}&amp;=&amp; \\displaystyle\\frac{1}{x}\\displaystyle\\sum_{i=1}^{x\\wedge I} \\displaystyle\\sum_{k=1}^{\\left \\lfloor x/i \\right \\rfloor} g_{x-ik} h(i,k)\\\\ \\end{eqnarray*}\\] Por otro lado, como \\(S=0\\) sólo cuando ningún asegurado efectúa ninguna reclamación, para \\(x=0\\) se tiene que: \\[\\begin{eqnarray*} g_{0}&amp;=&amp;\\displaystyle\\prod_{i=1}^{I}\\displaystyle\\prod_{j=1}^{J}(1-q_{j})^{n_{ij}}\\\\ \\end{eqnarray*}\\] Notemos que lo que hace este modelo, es agrupar a los asegurados por monto de reclamación (suma asegurada) \\(i\\) y probabilidad de reclamación \\(q_{j}\\) (grupo (\\(i,j\\))). Observe que la v.a \\(Y_{ij}\\) indica el monto que reclamó un individuo del grupo \\((i,j)\\), sin embargo hay \\(n_{ij}\\) de ellos; ergo, necesitamos denotar a \\(Y_{ijk}\\) como el monto real que puede reclamar el k-ésimo asegurado del grupo \\((i,j)\\) para poder ser más específicos. De esta manera, podemos ver al riesgo \\(S\\) como: \\[\\begin{eqnarray*} S&amp;=&amp; \\sum_{i=1}^{I}\\sum_{j=1}^{J}\\sum_{k=1}^{n_{ij}} Y_{ijk}\\\\ &amp;=&amp; \\underbrace{\\sum_{k=1}^{n_{11}}Y_{11k}}_{\\text{Grupo (1,1)}}+ \\underbrace{\\sum_{k=1}^{n_{21}}Y_{21k}}_{\\text{Grupo (2,1)}}+...+ \\underbrace{\\sum_{k=1}^{n_{I1}}Y_{I1k}}_{\\text{Grupo (I,1)}}+ \\underbrace{\\sum_{k=1}^{n_{12}}Y_{12k}}_{\\text{Grupo (1,2)}}+...+\\underbrace{\\sum_{k=1}^{n_{I2}}Y_{I2k}}_{\\text{Grupo (I,2)}}+...+\\underbrace{\\sum_{k=1}^{n_{IJ}}Y_{IJk}}_{\\text{Grupo (I,J)}}\\\\ \\end{eqnarray*}\\] No olvidemos que estamos hablando del modelo individual. Observemos que \\(Y_{ij}= B_{j}(i)\\) donde \\(B_{j} \\sim Ber (q_{j})\\). Ahora vamos a desagrupar a los individuos; lo que tenemos es un portafolio con \\(n\\) individuos donde algunos tienen características diferentes entre si. Sea \\(X_{t}\\ddot{=}D_{t}C_{t}\\) con \\(D_{t} \\sim Ber(\\gamma_{t})\\) y \\(C_{t}\\) una constante que indica el monto que reclama el t-ésimo asegurado del portafolio con n-individuos. Entonces existen \\(t\\) y \\(k\\) tales que \\(X_{t}=Y_{ijk}\\) en cuyo caso sucede que \\(\\gamma_{t}=q_{j}\\) y \\(C_{t}=i\\). Observe que esto no es más que renombrar variables por grupo y sin grupos. Entonces podríamos escribir también al riesgo \\(S\\) como: \\[\\begin{equation*} S= \\displaystyle\\sum_{t=1}^{n} C_{t}D_{t} =\\displaystyle\\sum_{i=1}^{I}\\displaystyle\\sum_{j=1}^{J}\\displaystyle\\sum_{k=1}^{n_{ij}} Y_{ijk}\\\\ \\end{equation*}\\] Con lo que podemos notar que si seguimos hablando del modelo individual, solo que con ciertas etiquetas. En consecuencia cada \\(Y_{ijk}\\) es independiente una de otra (esto puesto que los individuos son independientes entre si) y son idénticamente distribuidos por grupo(i, j). Ejemplo Tomando un portafolio del estilo: En el fondo tenemos el riesgo: \\[\\begin{eqnarray*} S&amp;=&amp; \\displaystyle\\sum_{i=1}^{I}\\displaystyle\\sum_{j=1}^{J}\\displaystyle\\sum_{k=1}^{n_{ij}} Y_{ijk}\\\\ &amp;=&amp; \\displaystyle\\sum_{k=1}^{2} Y_{11k} + \\displaystyle\\sum_{k=1}^{1} Y_{12k}+ \\displaystyle\\sum_{k=1}^{3} Y_{21k}+ 0\\\\ &amp;=&amp; (Y_{111} +Y_{112} )+ (Y_{121})+( Y_{211}+ Y_{212} + Y_{213})\\\\ \\end{eqnarray*}\\] Definiendo: \\[\\begin{eqnarray*} - D_{1} \\sim Ber(q_{1}) \\quad \\text{y} \\quad C_{1}=1 \\hspace{1cm} - D_{4} \\sim Ber(q_{2}) \\quad \\text{y} \\quad C_{4}=1\\\\ - D_{2} \\sim Ber(q_{1}) \\quad \\text{y} \\quad C_{2}=1 \\hspace{1cm} - D_{5} \\sim Ber(q_{2}) \\quad \\text{y} \\quad C_{5}=1\\\\ - D_{3} \\sim Ber(q_{1}) \\quad \\text{y} \\quad C_{3}=2 \\hspace{1cm} - D_{6} \\sim Ber(q_{2}) \\quad \\text{y} \\quad C_{6}=1 \\end{eqnarray*}\\] \\[\\begin{eqnarray*} S &amp;=&amp; ( D_1 C_1 + D_2 C_2 )+(D_3 C_3)+(D_4 C_4 + D_5 C_5 +D_6 C_6 )\\\\ &amp;=&amp; \\displaystyle\\sum_{t=1}^{6} D_{t} C_{t} \\end{eqnarray*}\\] Otra observación importante es que \\(S\\) está acotada. Como \\(D_{t} \\in \\{ 0,1\\}\\) y \\(C_{t}&gt;0\\), entonces en el mejor de los escenarios \\(S=0\\) que ocurre cuando nadie reclama. Pero si todos reclaman: \\[\\begin{eqnarray*} S&amp;=&amp; \\displaystyle\\sum_{i=1}^{I}\\displaystyle\\sum_{j=1}^{J}\\displaystyle\\sum_{k=1}^{n_{ij}} Y_{ijk}\\\\ &amp;=&amp; \\displaystyle\\sum_{i=1}^{I}\\displaystyle\\sum_{j=1}^{J}\\displaystyle\\sum_{k=1}^{n_{ij}} i \\quad \\text{Cuando reclaman vale i la suma asegurada}\\\\ &amp;=&amp; \\displaystyle\\sum_{i=1}^{I}\\displaystyle\\sum_{j=1}^{J}n_{ij} (i)\\\\ &amp;=&amp; \\displaystyle\\sum_{i=1}^{I}i \\displaystyle\\sum_{j=1}^{J}n_{ij} \\end{eqnarray*}\\] Que teniendo el cuadro: Se traduce a simplemente tomar: Viendo esto, haremos el cálculo de la esperanza del riesgo \\(S\\). \\[\\begin{equation*} \\mathbb E [S] \\ \\doteq \\mathbb E \\left[\\sum_{i=1}^{I} \\sum_{j=1}^{J} \\sum_{k=1}^{n_{ij}} Y_{ijk}\\right] = \\sum_{i=1}^{I} \\sum_{j=1}^{J} \\sum_{k=1}^{n_{ij}} \\mathbb E [Y_{ijk}]\\\\ = \\sum_{i=1}^{I} \\sum_{j=1}^{J} \\sum_{k=1}^{n_{ij}} iq_{j} \\left\\{ \\begin{array}{lcc} \\mathbb E [Y_{ijk}]\\\\\\\\ =0\\cdot(1-q_{i})+iq_{j}\\\\\\\\ =iq_{j}\\\\ \\end{array} \\right. \\\\ = \\sum_{i=1}^{I} \\sum_{j=1}^{J} iq_{j}n_{ij} = \\sum_{i=1}^{I} i \\sum_{j=1}^{J} q_{j} n_{ij} \\end{equation*}\\] Que es muy similar al cálculo anterior solo que ahora debemos multiplicar cada \\(n_{ij}\\) por su correspondiente \\(q_{j}\\). \\[\\begin{eqnarray*} \\mathbb E [S] &amp;=&amp; (1) \\times [q_{1}n_{11} + q_{2}n_{12} + ... + ... + ... + q_{J}n_{1J} ]\\\\ &amp;&amp; + ( 2 ) \\times [ q_{1}n_{21} + q_{2}n_{22} + ... + ... + ... + q_{J}n_{2J} ]\\\\ &amp;&amp; + ( ... ) \\times [ ... + ... + ... + ... + ... + ... ]\\\\ &amp;&amp; + ( i ) \\times [ ... + ... + ... + q_{j}n_{ij} + ... + ... ]\\\\ &amp;&amp; + ( ... ) \\times [ ... + ... + ... + ... + ... + ... ]\\\\ &amp;&amp; + ( I ) \\times [ ... + ... + ... + q_{j}n_{Ij} + ... + q_{J}n_{IJ} ]\\\\ \\end{eqnarray*}\\] Equivalentemente es multiplicar cada número dentro del cuadro, multiplicarlo por su \\((SA,q_{j})\\) y sumar todo. El resultado anterior se puede deducir de la fórmula general del modelo individual simplemente agrupando por \\((i,j)\\). Haremos el cálculo de la varianza de esta manera para ejemplificarlo. Con base en los resultados obtenidos para el modelo individual: \\[\\begin{eqnarray*} Var(S) &amp;=&amp; \\sum_{t=1}^{n} [ \\gamma_{t} Var(C_{t}) + \\gamma_{t} (1-\\gamma_{t}) \\mathbb E^{2} [C_{t}] ]\\\\ &amp;=&amp; \\sum_{t=1}^{n} \\gamma_{t} (1-\\gamma_{t}) C_{t}^{2} \\left\\{ \\begin{array}{lcc} Como\\hspace{2mm}C_{t}\\hspace{2mm}es\\hspace{2mm}constante\\\\\\\\ Var(C_{t})=0\\hspace{2mm}y\\hspace{2mm}\\mathbb E[C_{t}]=C_{t}\\\\ \\end{array} \\right. \\\\ \\end{eqnarray*}\\] La suma anterior la podemos separar en los grupos \\((i,j)\\) pues \\(n=\\sum_{i=1}^{I} \\sum_{j=1}^{J} n_{ij}\\), al separarla, tendremos una suma de sumas de grupos y al mismo tiempo \\(\\gamma_{t}\\) coincidirá con \\(q_{j}\\) y \\(C_{t}\\) con \\(i\\) para cada grupo \\((i,j)\\): \\[\\begin{eqnarray*} &amp;=&amp; \\underbrace{ \\sum_{t=1}^{n_{11}} q_{1}(1-q_{1})(1)^{2} }_{Grupo(1,1)} + \\underbrace{ \\sum_{t=1}^{n_{12}} q_{2}(1-q_{2})(1)^{2} }_{Grupo(1,2)} + ... + \\underbrace{ \\sum_{t=1}^{n_{1J}} q_{J}(1-q_{J})(1)^{2} }_{Grupo(1,J)} + \\underbrace{ \\sum_{t=1}^{n_{21}} q_{1}(1-q_{1})(2)^{2} }_{Grupo(2,1)} \\\\ &amp;&amp; +\\underbrace{ \\sum_{t=1}^{n_{22}} q_{2}(1-q_{2})(2)^{2} }_{Grupo(2,2)}+ \\underbrace{ \\sum_{t=1}^{n_{2J}} q_{J}(1-q_{J})(2)^{2} }_{Grupo(2,J)}+...+...+...+...+...+...+...+...+...+...\\\\ &amp; &amp; + ...+...+...+ \\underbrace{ \\sum_{t=1}^{n_{I1}} q_{1}(1-q_{1})(I)^{2} }_{Grupo(I,1)}+ \\underbrace{ \\sum_{t=1}^{n_{I2}} q_{2}(1-q_{2})(I)^{2} }_{Grupo(I,2)}+ ... + \\underbrace{ \\sum_{t=1}^{n_{IJ}} q_{J}(1-q_{J})(I)^{2} }_{Grupo(I,J)}\\\\ &amp;=&amp; \\sum_{i=1}^{I} \\sum_{j=1}^{J} \\sum_{k=1}^{n_{ij}} q_{j} (1-q_{j}) i^{2} = \\sum_{i=1}^{I} \\sum_{j=1}^{J} q_{j} (1-q_{j}) i^{2} n_{ij}\\\\ &amp;=&amp; \\sum_{i=1}^{I} i^{2} \\sum_{j=1}^{J} q_{j} (1-q_{j}) n_{ij}\\\\ \\end{eqnarray*}\\] Que análogo al último cálculo no es más que, tomando como referencia la tabla con frecuencias: \\[\\begin{eqnarray*} Var(S) &amp;=&amp; ( 1)^{2} \\times [ (1-q_{1})q_{1}n_{11} + (1-q_{2})q_{2}n_{12} + ... + ... + ... + (1-q_{J})q_{J}n_{1J} ]\\\\ &amp;&amp; + ( 2 )^{2} \\times [ (1-q_{1})q_{1}n_{21} + (1-q_{2})q_{2}n_{22} + ... + ... + ... + (1-q_{J})q_{J}n_{2J} ]\\\\ &amp;&amp; + ( ... ) \\times [ ... + ... + ... + ... + ... + ... ]\\\\ &amp;&amp; + ( i )^{2} \\times [ ... + ... + ... + (1-q_{j})q_{j}n_{ij} + ... + ... ]\\\\ &amp;&amp; + ( ... ) \\times [ ... + ... + ... + ... + ... + ... ]\\\\ &amp;&amp; + ( i )^{2} \\times [ ... + ... + ... + (1-q_{j})q_{j}n_{Ij} + ... + (1-q_{J})q_{J}n_{IJ} ]\\\\ \\end{eqnarray*}\\] Que es lo mismo que la esperanza pero multiplicando \\((1-q_{j})q_{j}\\) y no solo \\(q_{j}\\) para cada \\(j\\). Con lo anterior ya tenemos maneras para calcular probabilidades de \\(S\\), así como varianza y esperanza. Los ejemplos los veremos en R. Para un mejor entendimiento de la fórmula recursiva de \\(DePril [i]\\) escribiremos a continuación de manera explícita los primeros términos de este desarrollo. \\[\\begin{eqnarray*} g_{0} &amp;=&amp; \\prod_{i=1}^{I} \\prod_{j=1}^{J} (1-q_{j})^{n_{ij}}\\\\ g_{1} &amp;=&amp; g_{0} h(1,1)\\\\ g_{2} &amp;=&amp; \\frac{1}{2} \\{ g_{0} [h(1.2) + h(2,1)] + g_{1} h(1,1) \\}\\\\ g_{3} &amp;=&amp; \\frac{1}{3} \\{ g_{0} [h(1.3) + h(3,1)] + g_{1} [h(1.2) + h(2,1)] + g_{2} h(1,1) \\}\\\\ ... \\end{eqnarray*}\\] Ejemplo Para los datos que se muestran en la tabla de la Figura 1.4 en donde se tienen 48 pólizas de seguros con las probabilidades de reclamación y los montos de reclamaciones indicados, la correspondiente función de densidad para este riesgo es la que se muestra en la Figura 1.5 Debe tenerse cuidado en la implementación numérica de esta fórmula pues dado su caracter recursivo y que algunas de las probabilidades involucradas pueden ser muy pequeñas, pueden generarse resultados incorrectos debido al inevitable redondeo de cifras en una computadora. La fórmula que hemos denominado de \\(De Pril [i]\\) y que se encuentra expresada en el contexto de un portafolio de asegurados individuales puede escribirse como un resultado teórico de la teoría de probabilidad. Este es el contenido de la siguiente proposición. La fórmula tiene una expresión más simple y la demostración sigue los mismo lineamientos que la que hemos presentado, sin embargo, escribiremos nuevamente los detalles de la prueba en esta versión simplificada. Proposición (Fórmula de De Pril [ii]) Sean \\(X_{1},X_{2},...,X_{n}\\) v.a.i.i.d. con valores en el conjunto \\(\\{0,1,2,...\\}\\). Para cada entero \\(j\\geq0\\), defina la probabilidad \\(f_{j} = P(X=j)\\), y suponga \\(f_{0} \\neq 0\\). Sea \\(S = X_{1} + ... + X_{n}\\). Entonces las probabilidades \\(g_{x} = P(S=x)\\) se pueden calcular recursivamente mediante la siguiente fórmula: \\[\\begin{equation*} g_{0} = (f_{0})^{n},\\\\ g_{x} = \\frac{1}{f_{0}} \\sum_{j=1}^{x} \\left[ \\frac{j(n+1)}{x} - 1 \\right] f_{j}g_{x-j}, \\hspace{2mm}para\\hspace{2mm}x\\geq1. \\\\ \\end{equation*}\\] Demostración. Primeramente observemos que el evento \\((S=0)\\) ocurre si y sólo si todos los sumandos de \\(S\\) son cero, de modo que por independencia, \\(g_{0} = (f_{0})^{n}\\). Ahora veamos la forma de obtener la fórmula recursiva. Sean \\(P_{X}(t)\\) y \\(P_{S}(t)\\) las funciones generadoras de probabilidad de las variables discretas \\(X\\) y \\(S\\) respectivamente, es decir: \\[\\begin{equation*} P_{X}(t) = E(t^{X}) = \\sum_{k=0}^{\\infty} t^{k} f_{k},\\\\ P_{S}(t) = E(t^{S}) = \\sum_{k=0}^{\\infty} t^{k} g_{k}. \\end{equation*}\\] Por independencia e idéntica distribución, \\(P_{S}(t) = [P_{X}(t)]^{n}\\). Derivando respecto de t: \\[\\begin{equation*} P&#39;_{S}(t) = n[P_{X}(t)]^{n-1} P&#39;_{X}(t) \\end{equation*}\\] Multiplicando ambos lados por \\(tP_{X}(t)\\): \\[\\begin{equation*} P_{X}(t)tP&#39;_{S}(t) = nP_{S}(t) t P&#39;_{X}(t), \\end{equation*}\\] que en términos de sumas se escribe como sigue: \\[\\begin{equation*} \\sum_{j=0}^{\\infty} t^{j}f_{j} \\sum_{k=1}^{\\infty} kt^{k}g_{k} = n\\sum_{k=0}^{\\infty} t^{k}g_{k} \\sum_{j=1}^{\\infty} jt^{j}f_{j}. \\end{equation*}\\] El siguiente paso es identificar el coeficiente del término \\(t^{x}\\) en cada lado de la ecuación, para \\(x\\geq1\\). Por ejemplo, para el lado izquierdo el coeficiente es el término \\(f_{j}kg_{k}\\) para todos aquellos valores de \\(j\\geq0\\) y \\(k\\geq1\\) tales que \\(j+k = x\\). Esta doble suma puede escribirse como \\(\\sum_{j=0}^{x-1} f_{j}(x-j) g_{x-j}\\). De manera similar se encuentra el coeficiente del lado derecho. Igualando estos coeficientes se llega a la identidad: \\[\\begin{equation*} \\sum_{j=0}^{x-1} (x-j) f_{j} g_{x-j} = n\\sum_{j=1}^{x} j f_{j} g_{x-l}. \\end{equation*}\\] Separando el primer sumando del lado izquierdo y añadiendo en esa misma suma el término correspondiente a \\(j=x\\), es es cero, se obtiene: \\[\\begin{equation*} xf_{0}g_{x} + \\sum_{j=1}^{x} (x-j) f_{j} g_{x-j} = n\\sum_{j=1}^{x} j f_{j} g_{x-l}. \\end{equation*}\\] Finalmente se despeja el término \\(g_{x}\\) para llegar a la fórmula anunciada: \\[\\begin{equation*} g_{x} = \\frac{1}{f_{0}} \\sum_{j=1}^{x} \\left[ \\frac{j(n+1)}{x} - 1 \\right] f_{j}g_{x-j}, x\\geq1. \\end{equation*}\\] Los primeros términos de la fórmula de De Pril [ii] se muestran a continuación: \\[\\begin{eqnarray*} g_{0} &amp;=&amp; (f_{0})^{n},\\\\ g_{1} &amp;=&amp; \\frac{1}{f_{0}} (n f_{1} g_{0}) = \\begin{pmatrix} n \\\\ 1 \\end{pmatrix} f_{1}(f_{0})^{n-1},\\\\ g_{2} &amp;=&amp; \\frac{1}{f_{0}} \\left(\\frac{n-1}{2} f_{1} g_{1} + nf_{2}g_{0}\\right) = \\begin{pmatrix} n \\\\ 2 \\end{pmatrix}(f_{1})^{2}(f_{0})^{n-2} + \\begin{pmatrix} n \\\\ 1 \\end{pmatrix} f_{2}(f_{0})^{n-1},\\\\ g_{3} &amp;=&amp; \\frac{1}{f_{0}} \\left(\\frac{n-1}{3} f_{1} g_{2} + \\frac{2n-1}{3} f_{2} g_{1} + nf_{3}g_{0}\\right)\\\\ &amp;=&amp; \\begin{pmatrix} n \\\\ 3 \\end{pmatrix}(f_{1})^{3}(f_{0})^{n-3} + 2! \\begin{pmatrix} n \\\\ 2 \\end{pmatrix}f_{2}f_{1}(f_{0})^{n-2} + \\begin{pmatrix} n \\\\ 1 \\end{pmatrix} f_{3}(f_{0})^{n-1}.\\\\ \\end{eqnarray*}\\] Observe que las expresiones simplificadas tienen una interpretación natural en términos combinatoriales. Por ejemplo, la expresión para \\(g_{2}\\) involucra dos situaciones: la primera cuando dos sumandos distintos de \\(S\\) toman cada uno el valor uno y el resto toma el valor cero, y la segunda situación cuando uno de los sumandos toma el valor dos y el resto es cero. Los coeficientes binomiales dan cuenta de las distintas formas en las que se pueden presentar estos arreglos. Ejemplo Sean \\(X_{1}.X_{2},X_{3}\\) variables aleatorias independientes con idéntica distribución dada por la tabla que aparece abajo y cuya gráfica se muestra en la Figura 1.6(a). Usando la fórmula de De Pril [ii] encontraremos la distribución de \\(S =X_{1} + X_{2} +X_{3}\\). Observe que la variable suma puede tomar cualquiera de los valores \\(0,1,...,6\\). Usando la misma notación que en la fórmula de De Pril se muestran a continuación los cálculos para encontrar la función de probabilidad de \\(S\\) y la gráfica correspondiente aparece en la Figura 1.6(b). \\[\\begin{eqnarray*} g_{0} &amp;=&amp; (f_{0})^{3} = \\textit{0.125},\\\\ g_{1} &amp;=&amp; \\frac{1}{f_{0}} (3f_{1}g_{0}) = \\textit{0.15},\\\\ g_{2} &amp;=&amp; \\frac{1}{f_{0}} (f_{1}g_{1} + 3f_{2}g_{0}) = \\textit{0.285},\\\\ g_{3} &amp;=&amp; \\frac{1}{f_{0}} \\left(\\frac{1}{3} f_{1}g_{2} + \\frac{8}{3} f_{2}g_{1}\\right) = \\textit{0.188},\\\\ g_{4} &amp;=&amp; \\frac{1}{f_{0}} (f_{2}g_{2}) = \\textit{0.171},\\\\ g_{5} &amp;=&amp; \\frac{1}{f_{0}} \\left(-\\frac{1}{5} f_{1}g_{4} + \\frac{3}{5} f_{2}g_{3}\\right) = \\textit{0.054},\\\\ g_{6} &amp;=&amp; \\frac{1}{f_{0}} \\left(-\\frac{1}{3} f_{1}g_{5} + \\frac{1}{3} f_{2}g_{4}\\right) = \\textit{0.027}. \\end{eqnarray*}\\] Nosotros mostraremos la implementación de esta fórmula en los scripts de R. Debemos observar la diferencia que existe entre los supuestos que se manejan en la fórmula de De Pril (\\(i\\)) y (\\(ii\\)). En el caso de De Pril (\\(i\\)) el portafolio se asume como: \\[S=\\displaystyle\\sum_{t=1}^{n} C_tD_t=\\displaystyle\\sum_{i=1}^I\\displaystyle\\sum_{j=1}^J\\displaystyle\\sum_{k=1}^{n_{ij}}Y_{ijk}\\] Donde las \\(C_tD_t\\) no tienen la misma distribución \\(\\forall t\\) necesariamente. Esto se ve más claro cuando vemos el cuadro que nos muestra el número de individuos por grupo \\((i,j)\\).\\ De aquí podemos observar que, sin pérdida de generalidad, uno de los \\(n_{11}\\) miembros del grupo (1,1), tiene una probabilidad \\(q_1\\neq q_2\\) para alguno de los miembros del grupo (1,2) por ejemplo. Por otro lado, los supuestos que maneja la versión simplificada (De Pril (\\(ii\\))) son que, asumiendo un portafolio con \\(n\\)-pólizas y tomando \\(\\{X_t\\}_{t=1}^n\\) v.a.i.i.d. entonces el riesgo será: \\[\\begin{equation*} S\\displaystyle\\sum_{t=1}^n X_t\\qquad \\end{equation*}\\] Si meditamos un poco la relación, observemos que esta puede modelar uno de los grupos que están en los supuestos de De Pril (\\(i\\)). Si tomamos a \\(n=n_{ij}\\) y \\(X_t=Y_{ij}=iB_j\\) estaríamos modelando todo el grupo (\\(i,j\\)) con esta v.a. La simplificación en los supuestos de la fórmula de De Pril(\\(ii\\)) nos abre un mundo de posibilidades pues ahora, la suma asegurado no es constante necesariamente y no pide más que el soporte de su severidad (\\(X_t\\)) esté contenido en el conjunto \\(\\mathbb{N}\\cup\\{0\\}\\). Ahora el asegurado número \\(t\\) puede reclamar \\(X_t\\in\\{0,1,...\\}\\). Nota: \\(X_t=0\\Rightarrow\\) no hubo reclamación. Recordemos la siguiente proposición: Proposición: Sean \\(X\\) y \\(Y\\) independientes, y sean \\(g\\) y \\(h\\) dos funciones de \\(\\mathbb{R} \\text{ en } \\mathbb{R}\\), Borel medibles. Entonces las variables aleatorias \\(g(X)\\) y \\(h(Y)\\) también son independientes. Una de las ventajas más importantes que tiene este modelo es en cuando al cálculo de momentos. Notemos que, definiendo al riesgo \\(S\\) como en las hipótesis de De Pril(\\(ii\\)): \\[\\begin{eqnarray*} M_S(t)&amp;=&amp;\\mathbb{E}\\left[e^{St}\\right]=\\mathbb{E}\\left[exp\\left(t\\displaystyle\\sum_{i=1}^n X_i\\right)\\right]=\\mathbb{E}\\left[exp\\left(\\displaystyle\\sum_{i=1}^n tX_i\\right)\\right]\\\\ &amp;=&amp; \\mathbb{E}\\left[\\prod_{i=1}^n e^{tX_i}\\right]=\\prod_{i=1}^n\\mathbb{E}[e^{tX_i}] \\quad \\left\\}\\begin{array}{lcc} \\text{Por la independencia de} \\\\ \\text{las $X_i&#39;s$ y la proposición}\\\\ \\text{anterior.} \\end{array}\\right.\\\\ &amp;=&amp; \\mathbb{E}^n[e^{tX}]=\\mu_X^n(t)\\quad \\left\\}\\begin{array}{lcc} \\\\ \\text{Por ser v.a.i.i.d.}\\\\ \\end{array}\\right. \\end{eqnarray*}\\] Por tanto, utilizando las hipótesis de De Pril (\\(ii\\)) tenemos que la generadora de momentos de \\(S\\) es: \\[\\begin{equation*} \\mu_S(t)=\\mu_X^n(t) \\end{equation*}\\] Con lo cual llegamos a los otros dos resultados importantes: \\(\\mu&#39;_S(t)=n\\mu_X^{n-1}(t)\\cdotp \\mu&#39;_X(t)\\Rightarrow\\mu&#39;_S(0)=n(1)\\mu&#39;_X(0)\\) \\[\\begin{equation*} \\therefore \\mathbb{E}[S]=n\\mathbb{E}[X] \\end{equation*}\\] Para obtener la varianza es más fácil ver que: \\[\\begin{eqnarray*} Var(S)&amp;=&amp;Var(\\sum_{i=1}^n X_i)\\\\ &amp;=&amp;\\sum_{i=1}^{n} Var(X_i)\\quad \\left\\}\\begin{array}{lcc} \\text{Pues al haber independencia,}\\\\ \\text{la covarianza vale cero.} \\end{array}\\right.\\\\ &amp;=&amp; nVar(X)\\quad \\left\\}\\begin{array}{lcc} \\text{Pues son idénticamente distribuidas}\\\\ \\end{array}\\right. \\end{eqnarray*}\\] \\[\\begin{equation*} \\therefore Var(S)=nVar(X) \\end{equation*}\\] Los resultados anteriores se hicieron bajo el supuesto de que el riesgo \\(S\\) sigue las hipótesis que se manejan en la fórmula de De Pril (\\(ii\\)). Sin embargo, las demostraciones de estas propiedades no utilizaron el supuesto de que la severidad tenía un soporte discreto. De hecho, estas últimas propiedades son válidas en general para cualquier riesgo \\(S=\\displaystyle\\sum_{i=1}^n X_i\\) donde cada \\(X_i\\) es v.a.i.i.d. no importando su soporte o distribución. Pueden encontrar los vídeos con parte de la información anterior en los siguientes enlaces: De Pril (\\(i\\)) https://youtu.be/bFPe9cODvD4 https://youtu.be/2hX1OB88BlU De Pril (\\(ii\\)) https://youtu.be/2ZiBGxG_gFg Inspirados en la fórmula de De Pril (\\(ii\\)), recordemos el siguiente ejemplo: Supongamos que \\(D_j\\sim Ber(0.1)\\) y que \\(C_j\\) tiene la siguiente f.m.p: \\[\\begin{eqnarray*} \\mathbb{P}[C_j=c]=\\left\\{\\begin{matrix} \\text{0.8} &amp;\\mbox{si }&amp; c=1\\\\ \\text{0.2} &amp;\\mbox{si }&amp; c=2\\\\ 0 &amp;\\mbox{e.o.c.}&amp; \\end{matrix} \\right. \\qquad\\forall j. \\end{eqnarray*}\\] Tomando un portafolio con \\(n=3\\) pólizas bajo el modelo individual, busquemos probabilidades de \\(S_3=\\displaystyle\\sum_{i=1}^3 D_i C_i\\). Resulta que podemos resolver esto de manera rápida ahora utilizando la fórmula de De Pril (\\(ii\\)). Tomando \\(X_i=D_i C_i\\) entonces: \\[\\begin{eqnarray*} \\mathbb{P}[X=x]=\\left\\{\\begin{matrix} \\text{0.9} &amp;\\mbox{si }&amp; x=0\\\\ \\text{(0.1)(0.8)=0.08} &amp;\\mbox{si }&amp; x=1\\\\ \\text{(0.1)(0.2)=0.02} &amp;\\mbox{si }&amp; x=2\\\\ 0 &amp;\\mbox{e.o.c.}&amp; \\end{matrix} \\right. \\end{eqnarray*}\\] Como tenemos \\(X_i&#39;s\\) v.a.i.i.d. con soporte contenido en \\(\\mathbb{N}\\cup\\{0\\}\\), podemos usar la recursión. Sin embargo, un ejemplo de desarrollar De Pril (\\(ii\\)) con esto ya se tocó anteriormente.Vamos a retomar el resultado al que habíamos llegado: \\[\\begin{eqnarray*} f_{S_3}(t)=\\mathbb{P}[S_3=t]\\approx\\left\\{\\begin{matrix} 72.9\\% \\ \\mbox{si }\\ t=0\\\\ 19.44\\% \\ \\mbox{si }\\ t=1\\\\ 6.588\\% \\ \\mbox{si }\\ t=2\\\\ 0.9152\\% \\ \\mbox{si }\\ t=3\\\\ 0.1464\\% \\ \\mbox{si }\\ t=4\\\\ 0.0096\\% \\ \\mbox{si }\\ t=5\\\\ 0.0008\\% \\ \\mbox{si }\\ t=6\\\\ 0 \\ \\mbox{e.o.c.} \\end{matrix} \\right. \\end{eqnarray*}\\] Teniendo en mente lo anterior, vamos a definir ahora un modelo más general primero con un ejemplo. Sea \\(S\\) un riesgo tal que: \\[S=\\displaystyle\\sum_{i=1}^N X_i\\] Donde \\(N\\) es v.a. con f.m.p.: \\[\\begin{eqnarray*} \\mathbb{P}[N=n]=\\left\\{\\begin{matrix} \\text{0.75} &amp;\\mbox{si }&amp; n=0\\\\ \\text{0.25} &amp;\\mbox{si }&amp; n=3 \\end{matrix} \\right. \\end{eqnarray*}\\] Y además, \\(\\{X_i\\}_{i=1}^3\\) son v.a.i.i.d. con f.m.p.: \\[\\begin{eqnarray*} \\mathbb{P}[X=x]=\\left\\{\\begin{matrix} \\text{0.9} &amp;\\mbox{si }&amp; x=0\\\\ \\text{0.08} &amp;\\mbox{si }&amp; x=1\\\\ \\text{0.02} &amp;\\mbox{si }&amp; x=2\\\\ 0 &amp;\\mbox{e.o.c.}&amp; \\end{matrix} \\right. \\end{eqnarray*}\\] Nota: Si \\(N=0\\Rightarrow S=0\\) Observe que \\(S\\in\\{0,1,2,3,4,5,6\\}\\),además: \\[\\begin{eqnarray*} \\mathbb{P}[S=0]&amp;=&amp;\\mathbb{P}[S=0 | N=0]\\mathbb{P}[N=0]+\\mathbb{P}[S=0|N\\neq 0]\\mathbb{P}[N\\neq 0]\\\\ &amp;=&amp; \\text{0.75}+\\mathbb{P}[S=0|N=3]\\mathbb{P}[N=3]\\\\ &amp;=&amp; \\text{0.75}+\\underbrace{f_{S_3}(0)}_{\\substack{\\text{probabilidad}\\\\\\text{antes obtenida}}}(\\text{0.25})\\\\ \\mathbb{P}[S=1]&amp;=&amp;\\mathbb{P}[S=1 | N=0]\\mathbb{P}[N=0]+\\mathbb{P}[S=1 | N\\neq 0]\\mathbb{P}[N\\neq 0]\\\\ &amp;=&amp;\\text{0.25}\\mathbb{P}[S=1|N=3]\\\\ &amp;=&amp;\\text{0.25}f_{S_3}(1) \\end{eqnarray*}\\] Y haciendo esto sucesivamente, la f.m.p. de \\(S\\) será: \\[\\begin{eqnarray*} f_S(t)=\\mathbb{P}[S=t]=\\left\\{\\begin{matrix} \\text{0.75+0.25}f_{S_3}(0) &amp;\\mbox{si }&amp; t=0\\\\ \\text{0.25}f_{S_3}(t) &amp;\\mbox{si }&amp; t\\in\\{1,2,3,4,5,6\\}\\\\ 0 &amp;\\mbox{e.o.c.}&amp; \\end{matrix} \\right. \\end{eqnarray*}\\] Luego observamos los siguientes cálculos: \\[\\begin{eqnarray*} \\mathbb{E}[S]=(\\text{0.25})\\sum_{t=1}^6 tf_{S_3}(t)=\\text{0.9} \\end{eqnarray*}\\] \\[\\begin{eqnarray*} \\mathbb{E}[S^2]=(\\text{0.25})\\sum_{t=1}^6 t^2f_{S_3}(t)\\approx\\text{0.1416} \\end{eqnarray*}\\] \\[\\begin{eqnarray*} \\Rightarrow Var(S)\\approx\\text{0.1335} \\end{eqnarray*}\\] Pero además, se puede calcular la esperanza de \\(S\\) sin conocer su función de densidad: \\[\\begin{eqnarray*} \\mathbb{E}[S]&amp;=&amp;\\mathbb{E}[\\mathbb{E}[S|N]]=\\underbrace{\\mathbb{E}[S|N=0]}_{N=0\\Rightarrow S=0}\\mathbb{P}[N=0]+\\mathbb{E}[S|N=3]\\mathbb{P}[N=3]\\\\ &amp;=&amp;\\mathbb{E}\\left[\\sum_{i=1}^NX_i|N=3\\right]\\mathbb{P}[N=3]=\\mathbb{E}\\left[\\sum_{i=1}^3X_i\\right]\\mathbb{P}[N=3]\\\\ &amp;=&amp; 3\\cdotp\\mathbb{E}[X]\\mathbb{P}[N=3]=\\mathbb{E}[X](3\\cdotp\\mathbb{P}[N=3]+0\\cdotp\\mathbb{P}[N=0])\\\\ &amp;=&amp; \\mathbb{E}[X]\\mathbb{E}[N] \\end{eqnarray*}\\] Veremos estos cálculos en R. "],["modelo-colectivo-bases.html", "Capítulo 11 Modelo colectivo: Bases Modelo Colectivo Modelo Binomial Compuesto Modelo binomial negativo compuesto Modelo Poisson Compuesto Distribución de la convoluación de Poisson compuestas Aproximaciones de probabilidad del Modelo Colectivo", " Capítulo 11 Modelo colectivo: Bases Resulta ser que pensando a \\(N\\) como una v.a. que mide el número de reclamaciones las propiedades en general que presenta S son manejables. Es el momento de mezclar todos los temas que hemos desarrollado para crear una variable aleatoria que puede generalizar en cierto sentido a todas las demás. Desde el principio se habló de dos conceptos por separado, la frecuencia y la severidad. Veremos que estos dos se pueden Unificar. En la vida práctica es necesario estudiar y modelar por separado estos conceptos para que una vez bien identificados además de modelados se puedan mezclar en uno de los modelos más populares cuando se habla de riesgo: El Modelo colectivo o Modelo de pérdidas agregadas. Modelo Colectivo Considere un conjunto de un número no determinado de contratos de seguros con vigencia en un periodo de tiempo \\([0,T]\\) . Este periodo puede corresponder a un año por ejemplo. Sea \\(N\\) la variable aleatoria que denota el número de reclamaciones ocurridas en este intervalo, y sean las variables positivas \\(Y_1,...,Y_N\\) los montos de estas reclamaciones. Gráficamente una posible realización de tal esquema se muestra en la Figura 1.7. Nota: \\(Y\\to\\) frecuencia \\(\\gamma\\to\\) severidad Consideraremos que el número de reclamaciones y los montos de éstas son variables aleatorias independientes. Más aún, supondremos que las reclamaciones mismas son independientes entre sí, y que comparten la misma distribución de probabilidad. Definición: El monto agregado o monto acumulado de todas las reclamaciones efectuadas es la variable aleatoria \\(S\\), llamado riesgo y definida como sigue: \\(S=\\sum_{j=1}^N Y_j\\) ~~~~~~~~~~ (1.2) Observe que cada sumando es una variable aleatoria y que el número de sumandos es también aleatorio. La suma (1.2) se define como cero cuando \\(N=0\\)}. Observe además que \\(S\\) puede ser una variable aleatoria mixta, es decir, no ser discreta ni continua, pues cuando los montos de las reclamaciones \\(Y\\) son variables continuas estrictamente positivas, la variable \\(S\\) puede tomar el valor 0 con probabilidad \\(P( S=0)= P( N =0)&gt; 0\\), y puede además tomar cualquier valor en el intervalo \\((0,\\infty)\\) La ecuación (1.2) representa el modelo colectivo para un contrato de seguros, cuyas posibles realizaciones **como función del tiempo tienen la forma de la gráfica de la Figura 1.8: A la función de distribución de cada reclamación Y la denotaremos por la letra \\(G\\). Se asume naturalmente que \\(G(0)=0\\), ello equivale a decir que la variable \\(Y\\) es positiva. Adicionalmente usaremos la notación \\(\\mu_n :\\mathbb{E}[Y^n]\\), en particular se escribe \\(\\mu\\) en lugar de \\(\\mu_1:= \\mathbb{E}(Y)\\). Nuevamente el problema central es encontrar la distribución de probabilidad de \\(S\\), la cual depende de la distribución de \\(Y\\) y de \\(N\\). Un primer resultado general al respecto es el que aparece a continuación. Antes de enunciarlo recordemos que la 0-convolución de una función de distribución G se define como: \\[G^{*0}(x)= \\begin{cases} 1~~~si~~~x\\geq0\\\\ 0~~~si~~~x&lt;0 \\end{cases}\\] Proposición: La función de distribución del riesgo \\(S\\) en el modelo colectivo es: \\[F(x)=\\sum_{n=0}^{\\infty}G^{*n}(x)P(N=n)\\] Demostración. \\[\\begin{eqnarray*} F(x)&amp;=&amp;\\sum_{n=0}^{\\infty}P(S\\leq x| N=n)P(N=n)\\\\ &amp;=&amp;P(S\\leq x| N=0)P(N=0)+\\sum_{n=1}^{\\infty} P(Y_1, \\dots , Y_n\\leq x)P(N=n)\\\\ &amp;=&amp;G^{*0}(x)P(N=0)+\\sum_{n=1}^{\\infty}G^{*n}(x)P(N=n)\\\\ &amp;=&amp;\\sum_{n=0}^{\\infty}G^{*n}(x)P(N=n)\\\\ \\end{eqnarray*}\\] Algunas características numéricas de la variable \\(S\\) se muestran a continuación: Proposición 1.4: Suponiendo que las cantidades y funciones indicadas existen, el riesgo \\(S\\) en el modelo colectivo cumple las siguientes propiedades. 1. \\(\\mathbb{E}[S]=\\mathbb{E}[N]\\mathbb{E}[Y]\\) 2. \\(\\mathbb{E}[S^2]=Var(N)\\mathbb{E}[Y^2]+\\mathbb{E}[(N(N-1))\\mathbb{E}^2[Y]\\) 3. \\(Var(S)=Var(N)\\mathbb{E}^2[Y]+Var(Y)\\mathbb{E}[Y]\\) 4. \\(M_s(t)=M_N(ln(M_Y(t)))\\) Nota: Estos resultados son válidos para \\(\\gamma &#39;s\\) discretas, continuas, mixtas y hasta con soporte en \\(\\mathbb{R}\\) Demostración. 1. Condicionaremos sobre le valor de N y después usaremos la hipótesis de independencia. El resultado del cálculo es el mismo cuando la variable \\(N\\) inicia en el valor 0 o en valor 1 \\[\\begin{eqnarray*} E(S)&amp;=&amp;\\sum_{n=0}^{\\infty} E(\\sum_{j=1}^{N}Y_j|N=n)P(N=n)\\\\ &amp;=&amp;\\sum_{n=0}^{\\infty} E(\\sum_{j=1}^{n}Y_j|N=n)P(N=n)\\\\ &amp;=&amp;\\sum_{n=0}^{\\infty} nE(Y)P(N=n)\\\\ &amp;=&amp;E(N)E(Y)\\\\ \\end{eqnarray*}\\] 2. Nuevamente condicionando sobre el valor de \\(N\\) \\[\\begin{aligned} E\\left(S^{2}\\right) &amp;=\\sum_{n=0}^{\\infty} E\\left(\\left(\\sum_{j=1}^{N} Y_{j}\\right)^{2} \\mid N=n\\right) P(N=n) \\\\ &amp;=\\sum_{n=0}^{\\infty} E\\left(\\left(\\sum_{j=1}^{n} Y_{j}\\right)^{2} \\mid N=n\\right) P(N=n) \\\\ &amp;=\\sum_{n=0}^{\\infty} E\\left(\\left(\\sum_{j=1}^{n} Y_{j}\\right)^{2}\\right) P(N=n) \\\\ &amp;=\\sum_{n=0}^{\\infty}\\left[\\sum_{j=1}^{n} E\\left(Y_{j}^{2}\\right)+\\sum_{j, k=1 \\atop j \\neq k}^{n} E\\left(Y_{j} Y_{k}\\right)\\right] P(N=n) . \\end{aligned}\\] Observe que segunda suma es nula cuando \\(n=0\\), y a su vez la tercera suma se anula cuando \\(n=0\\) o 1 . Así, por la idéntica distribución tenemos que \\[ \\begin{aligned} E\\left(S^{2}\\right) &amp;=\\sum_{n=0}^{\\infty} n E\\left(Y^{2}\\right) P(N=n)+\\sum_{n=0}^{\\infty} n(n-1) E^{2}(Y) P(N=n) \\\\ &amp;=E(N) E\\left(Y^{2}\\right)+E(N(N-1)) E^{2}(Y) \\end{aligned} \\] 3. Por las fórmulas anteriores, \\[ \\begin{aligned} \\operatorname{Var}(S) &amp;=E\\left(S^{2}\\right)-E^{2}(S) \\\\ &amp;=E(N) E\\left(Y^{2}\\right)+E(N(N-1)) E^{2}(Y)-E^{2}(N) E^{2}(Y) \\\\ &amp;=E(N)\\left[E\\left(Y^{2}\\right)-E^{2}(Y)\\right]+\\left[E\\left(N^{2}\\right)-E^{2}(N)\\right] E^{2}(Y) \\\\ &amp;=E(N) \\operatorname{Var}(Y)+\\operatorname{Var}(N) E^{2}(Y) \\end{aligned} \\] 4. De manera análoga a los dos primeros incisos, \\[ \\begin{aligned} M_{S}(t) &amp;=\\sum_{n=0}^{\\infty} E\\left(e^{r\\left(Y_{1}+\\cdots+Y_{N}\\right)} \\mid N=n\\right) P(N=n) \\\\ &amp;=\\sum_{n=0}^{\\infty} E\\left(e^{r\\left(Y_{1}+\\cdots+Y_{n}\\right)}\\right) P(N=n) \\\\ &amp;=\\sum_{n=0}^{\\infty}\\left(M_{Y}(t)\\right)^{n} P(N=n) \\\\ &amp;=E\\left(\\left(M_{Y}(t)\\right)^{N}\\right) \\\\ &amp;=E\\left(e^{N \\ln \\left(M_{Y}(t)\\right)}\\right) \\\\ &amp;=M_{N}\\left(\\ln \\left(M_{Y}(t)\\right)\\right) \\end{aligned} \\] Modelo Binomial Compuesto Cuando el número de reclamaciones \\(N\\) tiene una distribución \\(Bin\\sim(n,p)\\) se dice que el riesgo \\(S\\) tiene una distribución binomial compuesta, y se escribe \\(S\\sim BinComp(n,p,G)\\) donde \\(G\\) es la función de distribución de cada sumando en la definición de \\(S\\). Bajo esta hipótesis se tienen los siguientes resultados. Proposición: Si \\(N\\) tiene distribución \\(Bin(n,p)\\) entonces a) \\(E(S)=n p \\mu\\). b) \\(E\\left(S^{2}\\right)=n p \\mu_{2}+n(n-1) p^{2} \\mu^{2}\\). c) \\(\\operatorname{Var}(S)=n p\\left(\\mu_{2}-p \\mu^{2}\\right)\\). d) \\(M_{S}(t)=\\left(1-p+p M_{Y}(t)\\right)^{n}\\). Nota: \\(\\mathbb{E}[\\gamma^n]=\\mu_n\\) Estas expresiones se siguen fácilmente de las fórmulas generales demostradas antes, basta recordar que si \\(N\\) tiene distribución \\(bin(n,p)\\), entonces \\(E(N)=np\\), \\(Var(N)=np(1-p)\\) y \\(M_N(t)=(1-p+pe^t)^n\\) Modelo binomial negativo compuesto Cuando el número de reclamaciones \\(N\\) tiene una distribución binomial negativa se dice que el riesgo S tiene una distribución binomial negativa compuesta. Esto es, si \\(N \\sim bin neg (k, p)\\) entonces \\(S \\sim bin neg comp (k, p, G)\\) donde nuevamente \\(G\\) hace referencia a la función de distribución Proposición: Si \\(N\\) tiene distribución bin \\(n e g(k, p)\\), entonces a) \\(E(S)=k(1 / p-1) \\mu\\). b) \\(E\\left(S^{2}\\right)=\\). c) \\(\\operatorname{Var}(S)=k(1 / p-1)(1 / p) \\mu^{2}+k(1 / p-1)\\left(\\mu_{2}-\\mu^{2}\\right)\\). d) \\(M_{S}(t)=\\left(\\frac{p}{1-(1-p) M_{Y}(t)}\\right)^{k}\\). Para encontrar estas fórmulas es suficiente recordar que si \\(N\\) tiene distribución \\(bin ~neg (k, p)\\), entonces \\(E(N)=\\frac{k(1-p)}{p},~~ Var(N)=\\frac{k(1-p)}{p^2}~~y~~ M_N(t)=\\left[ \\frac{p}{(1-p)e^t} \\right]^k\\) En el caso particular cuando \\(k=1\\), la distribución de \\(N\\) se reduce a la distribución geométrica de parámetro \\(p\\), y se dice que \\(S\\) tiene distribución geométrica compuesta. Modelo Poisson Compuesto Cuando el número de reclamaciones \\(N\\) tiene una distribución Poisson se dice que el riesgo \\(S\\) tiene una distribución Poisson compuesta, y se escribe \\(S \\sim Poisson ~comp (\\lambda, G)\\) , en donde \\(\\lambda\\) es el parámetro de la distribución Poisson y \\(G\\) es la función de distribución de cada sumando de \\(S\\). Para este modelo se tienen los siguientes resultados: Proposición: Si \\(N\\) tiene distribución \\(\\operatorname{Poisson}(\\lambda)\\), entonces a) \\(E(S)=\\lambda\\mu\\). b) \\(E\\left(S^{2}\\right)=\\lambda\\mu_{2}+\\lambda^{2} \\mu^{2}\\). c) \\(\\operatorname{Var}(S)=\\lambda\\mu_{2}\\). d) \\(M_{S}(t)=\\exp\\left[\\lambda\\left(M_{Y}(t)-1\\right)\\right]\\). Nuevamente estas expresiones son consecuencia de las fórmulas generales demostradas antes, \\(\\mathrm{y}\\) del hecho de que si \\(N\\) tiene distribución Poisson \\((\\lambda)\\) entonces \\(E(N)=\\lambda, \\operatorname{Var}(N)=\\lambda\\), y \\(M_{N}(t)=\\exp \\left(\\lambda\\left(e^{t}-1\\right)\\right)\\). Véase la sección de ejercicios para los terceros momentos de este modelo. Observe que el parámetro \\(\\lambda\\) y la distribución de la variable \\(Y\\) determinan por completo al modelo Poisson compuesto. Estudiaremos con más detalle este modelo en la siguiente sección. Proposición: Si \\(N\\) tiene distribución Poisson(\\(\\lambda\\)) entonces. a) \\(\\mathbb{E}(S)= \\lambda\\mu\\) b) \\(\\mathbb{E}(S^{2})= \\lambda \\mu_{2}+\\lambda^{2}\\mu^{2}\\) c) \\(Var(S)=\\lambda \\mu_{2}\\) d) \\(M_{S}(t)= exp[\\lambda(M_{Y}(t)-1)]\\) Nuevamente estas expresiones son consecuencia de las fórmulas generales demostradas antes, y del hecho que si \\(N\\) tiene distribución Poisson(\\(\\lambda\\)), entonces \\(\\mathbb{E}(N)=\\lambda, Var(N) \\quad \\text{y}\\quad M_{N}(t)=exp[\\lambda(e^{t}-1)]\\). Véase la sección de ejercicios para los terceros momentos de este modelo. Observe que el parámetro \\(\\lambda\\) y la distribución de la variable \\(Y\\) determinan por completo al modelo Poisson compuesto. Estudiaremos con más detalle este modelo en la siguiente sección. Distribución de la convoluación de Poisson compuestas Una característica muy útil para nuestros fines, es que la Poisson compuesta es cerrada bajo convolución. Específicamente: Supongase que \\(S_{j}\\) tiene una distribución Poisson compuesta con parametros \\(\\lambda_{j}\\) y función de distribución para severidades \\(F_{j}(x)\\) para \\(j=1,2,...,n\\). Además que \\(S_{1},S_{2},...,S_{n}\\) son independientes. Entonces \\(S=S_{1}+S_{2}+...+S_{n}\\) tiene una distribución Poisson compuesta con parametro: \\(\\lambda= \\displaystyle\\sum_{j=1}^{n} \\lambda_{j}\\) y función de distribución de severidad \\(F(x)= \\displaystyle\\sum_{j=1}^{n}\\displaystyle\\frac{\\lambda_{j}}{\\lambda}F_{j}(x)\\) Demostración. Sea \\(M_{j}(t)\\) la f.g.m de \\(F_{j}(x)\\) para \\(j=1,2,...,n\\). Entonces \\(S_{j}\\) tiene f.g.m dada por: \\(M_{S_{j}}(t)=\\mathbb{E}(e^{tS_{j}})= e^{\\lambda_{j}(M_{j}(t)-1)}\\) y por la independencia de las \\(S_{j}´s\\). S tiene f.g.m: \\[\\begin{eqnarray*} M_{S}(t)&amp;=&amp; \\displaystyle\\prod_{j=1}^{n}M_{S_{j}}(t)\\\\ &amp;=&amp; \\displaystyle\\prod_{j=1}^{n} exp(\\lambda_{j}[M_{j}(t)-1])\\\\ &amp;=&amp; exp \\left( \\left[ \\displaystyle\\sum_{j=1}^{n} \\lambda_{j}M_{j}(t) - \\displaystyle\\sum_{j=1}^{n} \\lambda_{j}\\right] \\right)\\\\ &amp;=&amp; exp\\left( \\left[ \\displaystyle\\sum_{j=1}^{n} \\lambda_{j}M_{j}(t) -\\lambda\\right] \\right)\\\\ &amp;=&amp; exp \\left( \\lambda \\left[ \\displaystyle\\sum_{j=1}^{n} \\displaystyle\\frac{\\lambda_{j}}{\\lambda}M_{j}(t) -\\lambda\\right] \\right)\\\\ \\end{eqnarray*}\\] Debido a que \\(\\displaystyle\\sum_{j=1}^{n}\\displaystyle\\frac{\\lambda_{j}}{\\lambda}M_{j}(t)\\) es la f.g.m de \\(F(x)= \\displaystyle\\sum_{j=1}^{n}\\displaystyle\\frac{\\lambda_{j}}{\\lambda}F_{j}(x)\\) entonces \\(M_{S}(t)\\) tiene la forma de la f.g.m de una distribución Poisson compuesta. Nota: Al igual que los resultados anteriores, la severidad en este resultado puede ser discreta, continua, mixta o con soporte en los reales. Este último resultado se puede enunciar de la siguiente manera: Supongamos una muestra de riesgos \\(\\{S_{j} \\}_{j=1}^{n}\\) v.a.i.i.d con \\(S_{j} \\sim PoiComp(\\lambda_{j}, F_{Y_{j}})\\), entonces: \\[\\begin{eqnarray*} S &amp;\\ddot{=} &amp;\\displaystyle\\sum_{j=1}^{n}S_{j} \\sim PoiComp\\left(\\lambda= \\displaystyle\\sum_{j=1}^{n} \\lambda_{j},F_{Y_{j}}= \\displaystyle\\sum_{j=1}^{n} \\displaystyle\\frac{\\lambda_{j}}{\\lambda}F_{Y_{j}}(x) \\right) \\end{eqnarray*}\\] De este resultado una de las partes interesantes es la severidad resultante de esta acción (\\(Y^{*}\\)). Principalmente porque, a pesar de que el resultado está dado en términos de la d.f.a, se deriva que: \\[\\begin{eqnarray*} f_{Y^{*}}(t)&amp;=&amp; \\displaystyle\\sum_{j=1}^{n} \\displaystyle\\frac{\\lambda_{j}}{\\lambda} f_{Y_{j}}(t) \\end{eqnarray*}\\] Sin importar que haya \\(Y_{j}´s\\) discretas, continuas, mixtas; este resultado quedará como ejercicio para el lector. Una demostración del resultado anterior, se puede dar si suponemos tener \\(n_{1}\\) v.a continuas y \\(n_{2}\\) v.a discretas con \\(n=n_{1}+n_{2}\\). Llamemos a \\(\\{ Y_{1i}\\}_{i=1}^{n_{1}}\\) a las v.a´s de severidad continuas y llamemos \\(\\lambda_{1i}\\) a sus correspondientes parámetros de frecuencia. Análogamente, llamaremos \\(\\{ Y_{2k}\\}_{k=1}^{n_{2}}\\) a las v.a´s de severidad discretas y \\(\\lambda_{2k}\\) a sus correspondientes parámetros de frecuencia. De esta manera, tendremos que: \\[\\begin{eqnarray*} F_{Y^{*}}(t) &amp;=&amp; \\displaystyle\\sum_{j=1}^{n} \\displaystyle\\frac{\\lambda_{j}}{j} F_{Y_{j}}(t)\\\\ &amp;=&amp; \\underbrace{ \\displaystyle\\sum_{i=1}^{n_{1}} \\displaystyle\\frac{\\lambda_{1i}}{\\lambda} F_{Y_{1i}}(t) }_\\text{continuas} + \\underbrace{{ \\displaystyle\\sum_{k=1}^{n_{2}} \\displaystyle\\frac{\\lambda_{2k}}{\\lambda} F_{Y_{2k}}(t) }}_\\text{discretas}\\\\ \\end{eqnarray*}\\] Entonces: \\[\\begin{eqnarray*} f_{Y^{*}}(t)&amp;=&amp;\\displaystyle\\frac{d}{dt}\\displaystyle\\sum_{i=1}^{n_{1}} \\displaystyle\\frac{\\lambda_{1i}}{\\lambda} F_{Y_{1i}}(t) \\quad + \\underbrace{ \\displaystyle\\sum_{k=1}^{n_{2}} \\displaystyle\\frac{\\lambda_{2k}}{\\lambda} F_{Y_{2k}}(t)- F_{Y_{2k}}(t-1)}_\\text{Asumiendo que las discretas tienen un soporte consecutivo}\\\\ &amp;=&amp; \\underbrace{\\displaystyle\\sum_{i=1}^{n_{1}} \\displaystyle\\frac{\\lambda_{1i}}{\\lambda} f_{Y_{1i}}(t) + \\displaystyle\\sum_{k=1}^{n_{2}} \\displaystyle\\frac{\\lambda_{2k}}{\\lambda} f_{Y_{2k}}(t)}_\\text{por la linealidad de la derivada y la probabilidad puntual de las discretas }\\\\ &amp;=&amp; \\displaystyle\\sum_{j=1}^{n} \\displaystyle\\frac{\\lambda_{j}}{\\lambda} f_{Y_{j}}(t) \\quad \\text{Juntando todo en un solo índice}\\\\ \\end{eqnarray*}\\] Notemos que entonces la severidad resultante de la suma de modelos Poisson compuestos, resulta ser una mezcla de las severidades de los riesgos sumados. Nota: \\(\\displaystyle\\frac{\\lambda_{i}}{\\lambda}\\in (0,1]\\) y \\(\\displaystyle\\sum_{i=1}^{n}\\displaystyle\\frac{\\lambda_{i}}{\\lambda}=1\\) Esto nos da pie a que, en general, los momentos de la severidad de la suma (\\(Y^{*}\\)) vendrán dados por: \\[\\begin{eqnarray*} \\mathbb{E}[(Y^{*})^{m}]&amp;=&amp; \\displaystyle\\frac{1}{\\lambda} \\displaystyle\\sum_{j=1}^{n} \\lambda_{j} \\mathbb{E}[(Y_{i})^{m}]\\\\ \\end{eqnarray*}\\] Nuevamente, esto se da sin importar el soporte de los \\(Y_{i}´s\\) pues una demostración con las hipótesis y notación anteriores puede verse como: \\[\\begin{eqnarray*} \\mathbb{E}[Y^{*m}] &amp;=&amp;\\displaystyle\\sum_{i=1}^{n_{1}} \\frac{\\lambda_{1i}}{\\lambda} \\displaystyle\\int_{\\mathbb{R}} t^{m} f_{Y_{1i}}(t) dt + \\frac{\\lambda_{2k}}{\\lambda} \\displaystyle\\sum_{\\forall t} t^{m} f_{Y_{2k}}(t) \\\\ &amp;=&amp; \\displaystyle\\sum_{i=1}^{n_{1}} \\frac{\\lambda_{1i}}{\\lambda} \\mathbb{E}[Y_{1i}^{m}] + \\frac{\\lambda_{2k}}{\\lambda} \\mathbb{E}[Y_{2k}^{m}]\\\\ &amp;=&amp; \\displaystyle\\sum_{j=1}^{n} \\frac{\\lambda_{i}}{\\lambda} \\mathbb{E}[Y_{j}^{m}] \\end{eqnarray*}\\] Ejemplo: \\(S_{1}\\) y \\(S_{2}\\) son distribuciones Poisson compuestas con parámetros \\(\\lambda_{1}=3\\) y \\(\\lambda_{2}=2\\), y función de severidad individual; asumiendo \\(S_{1} \\perp S_{2}\\). Determine la media y la varianza de \\(S\\). \\(S=S_{1}+S_{2}\\) tiene una distribución Poisson compuesta con media \\(\\lambda=3+2=5\\), y con función de severidad. Solución: Sea \\(X_{1}\\) \\(X_{2}\\) las severidades de \\(S_{1}\\) \\(S_{2}\\) respectivamente. \\[\\begin{align*} \\mathbb{E}[X_{1}]&amp;= (1)(0.25)+(2)(0.75)=1.75\\\\ \\mathbb{E}[X_{1}^{2}]&amp;= (1^{2})(0.25)+(2^{2})(0.75)=3.75\\\\ \\mathbb{E}[X_{2}]&amp;= (1)(0.1)+(2)(0.4)+(3)(0.4)+(4)(0.1)=2.5\\\\ \\mathbb{E}[X_{2}^{2}]&amp;= (1^{2})(0.1)+(2^{2})(0.4)+(3^{2})(0.4)+(4^{2})(0.1)=6.9\\\\ \\end{align*}\\] Solución 1: Por propiedades básicas \\[\\begin{eqnarray*} \\mathbb{E}[S] &amp;=&amp; \\mathbb{E}[S_{1}+ S_{2}]\\\\ &amp;=&amp; \\mathbb{E}[S_{1}] +\\mathbb{E} [S_{2}]\\\\ &amp;=&amp; \\lambda_{1} \\mathbb{E}[X_{1}] +\\lambda_{2} \\mathbb{E}[X_{2}]\\\\ &amp;=&amp; 3(1.75)+2(2.5)\\\\ &amp;=&amp; 10.25\\\\ \\end{eqnarray*}\\] \\[\\begin{eqnarray*} Var[S] &amp;=&amp; Var[S_{1}+ S_{2}]\\\\ &amp;=&amp; Var[S_{1}] +Var[S_{2}] + {2Cov(S_{1},S_{2})}\\\\ &amp;=&amp; \\lambda_{1} \\mathbb{E}[X_{1}^{2}] +\\lambda_{2} \\mathbb{E}[X_{2}^{2}]\\\\ &amp;=&amp; 3(3.75)+2(6.9)\\\\ &amp;=&amp; 25.05\\\\ \\end{eqnarray*}\\] Solución 2: Por propiedades de convolución de Poisson compuestas \\[\\begin{eqnarray*} \\mathbb{E}[S] &amp;=&amp; \\lambda \\mathbb{E}[Y^{*}]\\\\ &amp;=&amp; \\lambda \\left( \\displaystyle\\frac{\\lambda_{1}}{\\lambda} \\mathbb{E}[X_{1}] + \\displaystyle\\frac{\\lambda_{2}}{\\lambda} \\mathbb{E}[X_{2}]\\right)\\\\ &amp;=&amp; 5 \\left( \\displaystyle\\frac{3}{5} (1.75) + \\displaystyle\\frac{2}{5} (2.5) \\right)\\\\ &amp;=&amp; 10.25 \\end{eqnarray*}\\] \\[\\begin{eqnarray*} Var[S] &amp;=&amp; \\lambda \\mathbb{E}[(Y^{*})^{2}]\\\\ &amp;=&amp; \\lambda \\left( \\displaystyle\\frac{\\lambda_{1}}{\\lambda} \\mathbb{E}[X_{1}^{2}] + \\displaystyle\\frac{\\lambda_{2}}{\\lambda} \\mathbb{E}[X_{2}^{2}]\\right)\\\\ &amp;=&amp; 5 \\left( \\displaystyle\\frac{3}{5} (3.75) + \\displaystyle\\frac{2}{5} (6.9) \\right)\\\\ &amp;=&amp; 25.05\\\\ \\end{eqnarray*}\\] Esas son dos maneras de obtener el mismo resultado aplicando las propiedades básicas de la probabilidad vistas en cursos anteriores y los resultados a los que acabamos de llegar. Lo siguiente que nos interesa buscar es la manera de obtener probabilidades del riesgo \\(S\\). Para esto podemos deducir que las probabilidades exactas de \\(S\\) son difíciles de calcular , por tanto, en la siguiente sección veremos algunas metodologías para estimar dichos valores. A continuación facilitamos algunos vídeos que ayuden al entendimiento del tema anterior. Link de YouTube: https://www.youtube.com/watch?v=YFKFsSIHod4 Link de YouTube: https://www.youtube.com/watch?v=uNZiUUW6VaA Link de YouTube: https://youtu.be/z73RugHd_cU Link de YouTube: https://youtu.be/4g0qQG2gvbU Aproximaciones de probabilidad del Modelo Colectivo Este tipo de aproximaciones se utilizan generalmente cuando la severidad es una v.a. continua o con modelos más sofisticados de riesgo. 11.0.1 Aproximación Normal Sea \\(S\\) un riesgo con media y varianza finitas, entonces, si la variable aleatoria de frecuencia toma en general valores grandes, para cualquier \\(x\\geq 0\\) se tiene: \\[F_S(t)\\hspace{0.4em}\\ddot{=}\\hspace{0.4em}\\mathbb{P}[S\\leq t]\\approx \\Phi\\left(\\frac{t-\\mathbb{E}[S]}{\\sqrt{Var(S)}}\\right)\\] De donde se obtiene el siguiente resultado: \\[f_S(t)\\approx\\frac{1}{\\sqrt{Var(S)}}\\phi\\left(\\frac{t-\\mathbb{E}[S]}{\\sqrt{Var(S)}}\\right)\\] Recordando que \\(\\Phi(t)\\) es la función de distribución de una normal estándar y \\(\\phi(t)\\) la densidad de la misma. 11.0.2 Aproximación Gamma Trasladada Observemos lo siguiente: Ejemplo de densidades de Gamma Ejemplo de densidad de S Existen algunos riesgos \\((S)\\) en modelos colectivos que presentan un comportamiento similar al de una densidad Gamma. Es por eso que suena razonable intentar ajustar una densidad Gamma a nuestro modelo. Para esto, intentaremos ajustar una densidad Gamma trasladada para buscar ser más exactos en nuestro modelo. Entonces, definiremos \\(Z\\sim Gamma({\\beta},{\\lambda})\\) y tomaremos \\({c}\\in \\mathbb{R}\\), de tal manera que se buscará ajustar la variable \\(G\\hspace{0.4em}\\ddot{=}\\hspace{0.4em}Z+{c}\\sim Gamma T({\\beta},{\\alpha},{c})\\) a nuestro riesgo \\(S\\). Para lograr esto emplearemos un método similar al de momentos, necesitamos estimar 3 parámetros: \\({\\beta},{\\alpha}\\mbox{ y }{c}\\).Supongamos conocidos o estimadas las siguientes cantidades: \\(\\mathbb{E}[S]=\\mu\\quad\\rightarrow\\quad\\) la media \\(Var(S)=\\sigma^2\\quad\\rightarrow\\quad\\) la varianza \\(\\frac{\\mathbb{E}[(S-\\mathbb{E}[S])^3]}{\\sqrt{Var^3(S)}}=\\alpha\\quad\\rightarrow\\) el coeficiente de asimetría Con base en estas 3 cantidades estimaremos los parámetros. Haciendo los cálculos, las cantidades correspondientes para nuestra variable aleatoria \\(G\\) en términos de los parámetros de interés son las siguientes: \\(\\mathbb{E}[G]=\\mathbb{E}[{c}+Z]={c}+\\frac{\\beta}{\\lambda}\\) \\(Var(G)=Var({c}+Z)=\\frac{{\\beta}}{{\\lambda}^2}\\) \\(\\frac{\\mathbb{E}[(G-\\mathbb{E}[G])^3]}{Var(G)^{\\frac{3}{2}}}=\\frac{\\mathbb{E}[(({c}+Z)-\\mathbb{E}[{c}+Z])^3]}{Var{c}+Z)^{\\frac{3}{2}}}=\\frac{2}{\\sqrt{{\\beta}}}\\) Análogo al método de momentos tenemos el siguiente sistema de ecuaciones: \\[\\begin{eqnarray*} \\left\\{ \\begin{array}{lcc} -\\hspace{0.4em} \\mathbb{E}[S]={\\mu}={c}+\\frac{{\\beta}}{{\\lambda}}=\\mathbb{E}[G] \\\\ -\\hspace{0.4em} Var(S)={\\sigma}^2=\\frac{{\\beta}}{{\\lambda}^2}=Var(G)\\\\ -\\hspace{0.4em}\\frac{\\mathbb{E}[(S-\\mathbb{E}[S])^3]}{\\sqrt{Var^3(S)}}={\\alpha}=\\frac{2}{\\sqrt{{\\beta}}}=\\frac{\\mathbb{E}[(G-\\mathbb{E}[G])^3]}{Var(G)^{\\frac{3}{2}}} \\end{array} \\right. \\end{eqnarray*}\\] Resolviendo el sistema de ecuaciones: \\[\\begin{eqnarray*} \\left\\{ \\begin{array}{lcc} {\\left.{c}={\\mu}{-\\frac{2{\\sigma}}{{\\alpha}}}\\right\\}\\text{Parámetro de traslación}}\\\\ {\\left.\\begin{array}{lcc} {\\beta}={\\frac{4}{{\\alpha}^2}}\\\\ {\\lambda}={\\frac{2}{{\\sigma}{\\alpha}}}\\end{array}\\right\\} \\text{Parámetros de la Gamma}} \\end{array} \\right. \\end{eqnarray*}\\] Para más de la aproximación Gamma-T: Link de YouTube: https://youtu.be/veGk-C-m_sk La distribución del riesgo \\(S\\) en el modelo colectivo puede aproximarse mediante la distribución de la variable aleatoria \\(G={c}+Z={\\mu}-\\frac{2{\\sigma}}{{\\alpha}}+z\\) donde \\(Z\\sim Gamma\\left({\\beta}=\\frac{4}{{\\alpha}^2},{\\lambda}=\\frac{2}{{\\sigma}{\\alpha}}\\right)\\). Es decir: \\[ F_S(t)\\hspace{0.4em}\\ddot{=}\\hspace{0.4em}\\mathbb{P}[S\\leq t]\\approx\\mathbb{P}[G\\leq t]=\\mathbb{P}\\left[z\\leq t-{\\mu}+\\frac{2{\\sigma}}{{\\alpha}}\\right]\\hspace{0.4em}\\ddot{=}\\hspace{0.4em}F_Z\\left(t-{\\mu}+\\frac{2{\\sigma}}{{\\alpha}}\\right) \\] \\(\\mathbb{E}[S]=\\mu\\) \\(\\hspace{0.4em}\\) \\(\\hspace{0.4em}\\) \\(\\hspace{0.4em}\\) \\(\\hspace{0.4em}\\) \\(Var(S)=\\sigma^2\\) \\(\\hspace{0.4em}\\) \\(\\hspace{0.4em}\\) \\(\\hspace{0.4em}\\) \\(\\hspace{0.4em}\\) \\(\\frac{\\mathbb{E}[(S-\\mathbb{E}[S])^3]}{\\sqrt{Var^3(S)}}=\\alpha\\) Cuando la severidad al igual que la frecuencia del modelo son discretas entonces la distribución del riesgo será también discreta. Por lo cual, si se desea utilizar estos métodos de aproximación en el caso discreto, es necesario aplicar antes una corrección por continuidad. En general: Suponiendo que se desea aproximar \\(\\mathbb{P}[n\\leq S \\leq m]\\) con \\(S\\) discreta la corrección por continuidad será expandiendo el intervalo \\([n,m]\\) al intervalo \\(\\left[n-\\frac{1}{2},m+\\frac{1}{2}\\right]\\): \\[ \\mathbb{P}[n\\leq S\\leq m]\\approx \\mathbb{P}\\left[n-\\frac{1}{2}\\leq S\\leq m+\\frac{1}{2}\\right] \\] Ejemplo Gamma Trasladada: Vamos a estimar en R con una muestra de \\(S\\) los parámetros de la Gamma Trasladada y veamos que en efecto la distribución obtenida ajusta a los datos. "],["modelo-colectivo-formula-de-panjer.html", "Capítulo 12 Modelo colectivo: Formula de Panjer 12.1 Casos especiales de Panjer Momento de S para Panjer", " Capítulo 12 Modelo colectivo: Formula de Panjer Figura 1: Harry Panjer La fórmula de Panjer es un resultado que proporciona una expresión exacta, aunque recursiva, de la función de masa de probabilidad de un riesgo en modelo de pérdidas agregadas. Este modelo tiene ciertas hipótesis que de no cumplirse se puede recurrir a las aproximaciones antes mencionadas para el modelo colectivo. Primeramente, supondremos que el número de reclamaciones de un riesgo (\\(S\\)) en el modelo colectivo, es decir, su frecuencia (\\(N\\)) es de clase (a,b,0) y recordemos las distribuciones provenientes de esta clase: Cudro 1: Distribuciones de la clase (a,b,0) Link de YouTube: https://www.youtube.com/watch?v=ul2j6FhifCw Otro supuesto es que la severidad (\\(Y\\)) del modelo será discreta con soporte en \\(\\mathbb{N}\\ \\{ 0\\}\\), lo cual implica que el riesgo (\\(S\\)) tendrá también un soporte discreto. Específicamente , la densidad del riesgo sí representará probabilidades puntuales. Esto finalmente nos lleva a algunos resultados preliminares a enunciar la fórmula de Panjer, estos resultados son importantes para comprender la demostración de la fórmula. A pesar de esto y debido a la finalidad de esta sección , estos resultados únicamente se comentarán en el vídeo a continuación y nos enfocaremos más en la aplicación de este resultado. Una notación muy habitual para este tema es la siguiente: Notación: \\[\\begin{align*} p_{k}&amp;= P(N=k) \\ \\ &amp;k=0,1,...\\\\ f_{r}&amp;=P(Y=r) \\ \\ &amp;r=1,2,...\\\\ f_{r}^{*k}&amp;= P(Y_{1}+...+Y_{k}=r) \\ \\ &amp;1\\leq k \\leq r=1,2,...\\\\ g_{r}&amp;=P(S=r) \\ \\ &amp;r=0,1,...\\\\ \\end{align*}\\] Resultados preliminares: Link de YouTube: https://www.youtube.com/watch?v=vVBwC-oLnqg Proposición: Formula de Panjer Supondremos que \\(S\\) es un modelo colectivo con frecuencia \\(N\\) de clase (a,b,0) y severidad \\(Y\\) con soporte tal que \\(Sop\\{Y\\} \\subseteq \\mathbb{N}\\diagdown \\{ 0\\}\\). Las probabilidades puntuales exactas de \\(S\\) están dadas por: \\[\\begin{eqnarray*} f_{S}(t)&amp;=&amp; \\mathbb{P}[S=t]\\\\ &amp;=&amp; \\left \\{ \\begin{matrix} \\mathbb{P}[N=0] &amp; \\mbox{si }&amp; t=0 \\\\ \\displaystyle\\sum_{j=1}^{t} \\left(a+ \\displaystyle\\frac{b(j)}{t} \\right)\\mathbb{P}[Y=j]\\mathbb{P}[S=t-j]&amp;\\mbox{si } &amp; t \\in \\mathbb{N}\\diagdown \\{ 0\\} \\\\ 0 &amp; &amp; e.o.c \\end{matrix}\\right. \\end{eqnarray*}\\] Nota: Bajo la notación anterior, el resultado se expresa como: \\[\\begin{eqnarray*} g_{t}&amp;=&amp; \\left \\{ \\begin{matrix} P_{0} &amp; \\mbox{si }&amp; t=0 \\\\ \\displaystyle\\sum_{j=1}^{t} \\left(a+ \\displaystyle\\frac{b(j)}{t} \\right)\\mathbb{P}[Y=j]f_{j}g_{t-j}&amp;\\mbox{si } &amp; t \\in \\mathbb{N} \\diagdown \\{ 0\\} \\\\ 0 &amp; &amp; e.o.c \\end{matrix}\\right. \\end{eqnarray*}\\] La demostración de esta fórmula se muestra también en el siguiente vídeo: Link de YouTube: https://www.youtube.com/watch?v=r52-snnbVNU A continuación escribimos explícitamente los primeros términos de la formula recursiva de Panjer: \\[\\begin{eqnarray*} g_{0}&amp;=&amp; p_{0}= P(N=0)\\\\ g_{1}&amp;=&amp; \\left( a + \\displaystyle\\frac{b}{1} f_{1}g_{0} \\right)\\\\ g_{2}&amp;=&amp;\\left( a + \\displaystyle\\frac{b}{2} f_{1}g_{1} \\right) +\\left( a + \\displaystyle\\frac{2b}{3} f_{2}g_{0} \\right)\\\\ g_{3}&amp;=&amp; \\left( a + \\displaystyle\\frac{b}{3} f_{1}g_{2} \\right)+\\left( a + \\displaystyle\\frac{2b}{3} f_{2}g_{1} \\right) +\\left( a + \\displaystyle\\frac{3b}{3} f_{3}g_{0} \\right)\\\\ \\vdots \\end{eqnarray*}\\] Como un ejemplo consideremos el caso cuando \\(N\\) sigue una distribución Poisson de parámetro \\(\\lambda=3.5\\), y el monto de las reclamaciones tiene la siguiente función de densidad. Entonces la formula de Panjer produce la función de probabilidad para \\(S\\) que se muestra en la Figura a continuación: 12.1 Casos especiales de Panjer Recordemos primero que supuestos necesitaba la fórmula original de Panjer: 1. \\(N\\) (frecuencia) de clase (a,b,0) 2. \\(Y_{j}\\) (severidad) \\(\\in \\mathbb{N} \\diagdown \\{ 0\\}\\quad \\forall j\\) Teniendo en mente que hablamos del modelo colectivo de Riesgo: \\[\\begin{eqnarray*} S&amp;=&amp; \\displaystyle\\sum_{j=1}^{N} Y_{j} \\quad \\text{Recuerden que si $N \\equiv0 \\Rightarrow S\\equiv 0$ por convención} \\end{eqnarray*}\\] En tal caso, las probabilidades exactas de \\(S\\) vienen dadas por la recursión que ya conocemos: \\[\\begin{eqnarray*} \\mathbb{P}[S=s] &amp;=&amp; \\left \\{ \\begin{matrix} \\mathbb{P}[N=0] &amp; \\mbox{si }&amp; s=0 \\\\ \\displaystyle\\sum_{j=1}^{\\overline{K}} \\left(a+ \\displaystyle\\frac{b(j)}{t} \\right)\\mathbb{P}[Y=j]\\mathbb{P}[S=s-j]&amp;\\mbox{si } &amp; s \\in \\mathbb{N}\\diagdown \\{ 0\\} \\\\ 0 &amp; &amp; e.o.c \\end{matrix}\\right. \\end{eqnarray*}\\] Donde: \\(\\overline{K}=máx\\{ s, máx\\{ Sop \\{Y\\}\\}\\}\\). Primer punto: ¿Qué pasa si \\(0 \\in Sop \\{ Y\\}\\) ? Esto es de mucho interés pues hay v.a.´s asociadas al pago de una compañía de seguros tales que \\(0 \\in Sop \\{ Y\\}\\), un ejemplo son aquellas que tienen un deducible y a una compañía de seguros que le podría interesar calcular probabilidades de un portafolio del estilo \\[\\begin{eqnarray*} S&amp;=&amp; \\displaystyle\\sum_{j=1}^{N} máx \\{X_{i}-d,0 \\} \\end{eqnarray*}\\] Donde \\(X_{j}\\) es el monto del siniestro del asegurado \\(j\\) . Pensándolo desde este punto de vista, para una aseguradora, que un \\(X_{j}\\leq d\\) es equivalente a que no haya ocurrido un siniestro, es decir, el riesgo (\\(S\\)) del portafolio es cero. En otras palabras , asumiendo que \\(0 \\in Sop \\{ Y\\}\\) para alguna v.a \\(Y\\) de interés, tenemos que: \\[\\begin{eqnarray*} \\mathbb{P}[S=0]&amp;=&amp; \\mathbb{P}\\left[ \\displaystyle\\sum_{j=1}^{N} Y_{j}=0 \\right]\\\\ &amp;=&amp; \\mathbb{P}\\left[ \\{ N=0\\} \\cup \\bigcup_{k=1}^{\\infty}\\{ N=n, \\bigcap_{k=1}^{n}\\{Y_{k}=0 \\}\\} \\right]\\\\ &amp;=&amp; \\mathbb{P}[N=0]+\\sum_{n=1}^\\infty\\mathbb{P}[N=n](\\mathbb{P}[Y=0])^n{\\left\\{\\begin{array}{lcc} \\text{Pues cada caso es ajeno}\\\\ \\text{y las v.a.&#39;s son indep.} \\end{array}\\right.}\\\\ &amp;=&amp; \\sum_{n=0}^\\infty\\mathbb{P}[N=n](\\mathbb{P}[Y=0])^n{\\left\\{\\begin{array}{lcc} \\text{Aquí asumimos} \\\\ \\mbox{que } \\mathbb{P}[Y=0]\\neq 0 \\end{array}\\right.}\\\\ &amp;=&amp; \\mathbb{E}[(\\mathbb{P}[Y=0])^N]{\\left\\{\\begin{array}{lcc} \\text{Asumiendo que} \\\\ sop\\{N\\}\\subseteq\\mathbb{N}\\cup\\{0\\} \\end{array}\\right.}\\\\ \\therefore \\mathbb{P}[S=0]&amp;=&amp;\\mathbb{E}[(\\mathbb{P}[Y=0])^N] \\end{eqnarray*}\\] Si: \\(S=\\displaystyle\\sum_{j=1}^N Y_j\\hspace{0.5em}\\&amp;\\hspace{0.5em}\\mathbb{P}[Y=0]\\neq 0\\hspace{0.5em}\\&amp;\\hspace{0.5em}sop\\{N\\}\\subseteq\\mathbb{N}\\cup\\{0\\}\\) ¿Les suena \\(\\mathbb{E}[t^x]\\)? Por definición: \\[ G_X(t)\\hspace{0.4em}\\ddot{=}\\hspace{0.4em}\\mathbb{E}[t^X] \\] Es la función generadora de probabilidad de la v.a. \\(X\\). Entonces, para nuestro interés si \\(\\mathbb{P}[Y=0]\\neq 0\\) y \\(N\\) es de clase \\((a,b,0)\\); se tiene que: \\[ \\mathbb{P}[S=0]=G_N(\\mathbb{P}[Y=0]) \\] Por facilidad del lector agregamos lo siguiente: Curso intermedio de probabilidad, L. Rincón, pág:313 Por último nos falta ver qué sucede si \\(S&gt;0\\). Según el siguiente documento: En la página LM-250 hay otra demostración de lo anterior y además, en la página LM-251 se deduce lo siguiente: Sea \\(N\\) (frecuencia) de clase \\((a,b,0)\\) Sea \\(Y\\) (severidad) \\(sop\\{Y\\}\\subseteq\\mathbb{N}\\cup\\{0\\}\\) \\(\\mathbb{P}[Y=0]\\neq 0\\) Entonces \\[\\begin{eqnarray*} \\mathbb{P}[S=s]=\\left\\{ \\begin{array}{lcc} G_N(\\mathbb{P}[Y=0])\\mbox{ si } s=0 \\\\ \\frac{\\displaystyle\\sum_{j=1} ^{min\\{s,máx\\{sop\\{Y\\}\\}\\}}\\left(a+\\frac{b(j)}{s}\\right)\\mathbb{P}[Y=j]\\mathbb{P}[S=s-j]}{1-a\\mathbb{P}[Y=0]}\\quad s\\in \\mathbb{N}\\backslash \\{0\\}\\\\ 0 \\mbox{ en otro caso } \\end{array} \\right. \\end{eqnarray*}\\] Ejemplo 1: Sea \\(N\\sim Bin(n=2,p=\\text{0.25})\\) Consideremos el monto del siniestro \\(\\ddot{=}\\hspace{0.4em}X\\sim Unif\\{1,2,3\\} \\ (\\mathbb{P}[X=k]=\\frac{1}{3}\\hspace{0.6em}\\forall k\\in \\{1,2,3\\})\\) para cada asegurado \\(j\\). Sea \\(Y\\) el monto que paga una aseguradora con un contrato de deducible \\(d=2\\) sobre el monto de siniestro \\((X)\\) para cada asegurado \\(j\\). Definimos el riesgo de la compañía como: \\[S=\\displaystyle\\sum_{j=1}^NY_j=\\displaystyle\\sum_{j=1}^Nmáx\\{X_j-d,0\\}\\] ¿Qué sentido tiene la distribución de \\(N\\) en este caso?\\ Notemos que \\[\\begin{eqnarray*} \\mathbb{P}[Y=k]=\\left\\{ \\begin{matrix} \\frac{2}{3} &amp;\\mbox{si }&amp; k=0\\\\ \\frac{1}{3} &amp;\\mbox{si }&amp; k=1\\\\ 0 &amp;\\mbox{e.o.c.}&amp; \\end{matrix} \\right. \\end{eqnarray*}\\] Script: “Panjer Especial” Segundo Punto: ¿Qué pasa si \\(N\\) es de clase (\\(a,b,1\\))? Recordemos primero que si \\(N\\) es de clase \\((a,b,1)\\) quiere decir que sufrió una modificación a su probabilidad en cero. Esto es, que \\(\\mathbb{P}[N=0]\\) no es necesariamente la original de la distribución de la cual proviene. Por ejemplo, en el caso cero-truncado obligamos a que \\(\\mathbb{P}[N=0]=0\\). Para el caso cero modificado uno podría proponer que \\(\\mathbb{P}[N=0]=\\frac{\\pi}{4}\\) por ejemplo: Denotemos como \\(N^{\\star}\\) la clase (\\(a,b,1\\)) de la original \\(N\\) de clase \\((a,b,0)\\). Entonces si \\(\\mathbb{P}[N=k]\\hspace{0.4em}\\ddot{=}\\hspace{0.4em}P_k\\), tendremos: \\(\\mathbb{P}[N^\\star=0]=P_0^\\mu\\) \\(\\mathbb{P}[N^\\star=k]=P_k^\\mu=\\left(\\frac{1-P_0^\\mu}{1-P_0}\\right)P_k\\) ¡Cuidado con la notación! Entrados en este caso supongamos que \\(\\mathbb{P}[Y=0]=0\\) \\[\\Rightarrow \\mathbb{P}[S=0]=\\mathbb{P}[N^\\star=0]\\quad\\text{(la probabilidad modificada).}\\] Por otro lado si \\(\\mathbb{P}[Y=0]\\neq 0\\), análogamente \\[\\begin{eqnarray*} \\Rightarrow \\mathbb{P}[S=0]&amp;=&amp;\\mathbb{P}\\left[\\displaystyle\\sum_{j=1}^{N^\\star}Y_j=0\\right]\\\\ &amp;=&amp;\\mathbb{P}\\left[\\{N^\\star=0\\}\\cup\\left(\\bigcup_{n=1}^\\infty\\left\\{N^\\star=n,\\bigcap_{k=1}^n\\{Y_k=0\\}\\right\\}\\right)\\right]\\\\ &amp;=&amp; \\mathbb{P}[N^\\star=0]+\\displaystyle\\sum_{n=1}^\\infty\\mathbb{P}[N^\\star=n](\\mathbb{P}[Y=0])^n\\\\ &amp;=&amp; P_0^\\mu+\\displaystyle\\sum_{k=1}^\\infty P_k^\\mu (\\mathbb{P}[Y=0])^k\\\\ &amp;=&amp; P_0^\\mu + \\left(\\frac{1-P_0^\\mu}{1-P_0}\\right)P_k(\\mathbb{P}[Y=0])^k\\\\ &amp;=&amp; P_0^\\mu + \\left(\\frac{1-P_0^\\mu}{1-P_0}\\right)\\displaystyle\\sum_{k=1}^\\infty P_k(\\mathbb{P}[Y=0])^k\\\\ &amp;=&amp;P_0^\\mu + \\left(\\frac{1-P_0^\\mu}{1-P_0}\\right)\\left[\\left(\\displaystyle\\sum_{k=0}^\\infty P_k\\mathbb{P}[Y=0]^k\\right)-P_0\\right]\\\\ &amp;=&amp; P_0^\\mu + \\left(\\frac{1-P_0^\\mu}{1-P_0}\\right)\\left(G_N(\\mathbb{P}[Y=0])-P_0\\right)\\\\ &amp;=&amp;P_0^\\mu + \\left(\\frac{1-P_0^\\mu}{1-P_0}\\right)(G_N(\\mathbb{P}[Y=0])-1+1-P_0)\\\\ &amp;=&amp; P_0^\\mu +(1-P_0^\\mu)\\left(\\frac{G_N(\\mathbb{P}[Y=0])-1}{1-P_0}+1\\right)\\\\ &amp;=&amp; {P_0^\\mu}+\\left(\\frac{1-P_0^\\mu}{1-P_0}\\right)(G_N(\\mathbb{P}[Y=0]-1))+1-{P_0^\\mu}\\\\ &amp;=&amp; 1+\\left(\\frac{1-P_0^\\mu}{1-P_0}\\right)(G_N(\\mathbb{P}[Y=0]-1))\\\\ &amp;=&amp; 1-\\left(\\frac{1-P_0^\\mu}{1-P_0}\\right)(1-G_N(\\mathbb{P}[Y=0]))\\\\ &amp;\\mbox{o}&amp; \\mbox{bien } \\mathbb{P}[S=0]=G_{^\\star}(\\mathbb{P}[Y=0]) \\end{eqnarray*}\\] \\[\\begin{align*} \\therefore \\mathbb P [S = 0 ] &amp;=&amp; G_{N^{*}} (\\mathbb P [y = 0])\\\\ &amp;=&amp; 1 - (\\frac{1-P_{0}^{M}}{1-P_{0}}) (1 - G_{N}(\\mathbb P [y=0]))\\\\ \\end{align*}\\] Sea cual sea el caso, usando como referencia el último libro mencionado en la misma página, se deduce que, si \\(N_{*}\\) es de \\((a,b,1)\\) entonces: Tomando \\(S = \\displaystyle\\sum_{j=1}^{N^{*}} y_{j}\\), si \\(x\\in sop \\{S\\} / \\{0\\}\\): \\(\\mathbb {P} [S = x] = \\displaystyle\\frac{ [P_{1}^{M}-(a+b)P_{0}^{M}] \\mathbb{ P}[y=x]+\\displaystyle\\sum_{j=1}^{min\\{x,max\\{sop\\{y\\}\\}\\}} \\left(a+\\frac{bj}{x} \\right) \\mathbb {P} [y=j] \\mathbb {P} [s=x-j] }{1-a\\mathbb {P} [y=0]}\\) Nótese que éste es un caso que generaliza al anterior pues si \\(P_{0}^{M} = P_{0}\\) \\(\\Rightarrow\\) \\(P_{k}^{M} = P_{k}\\) \\(\\forall k&gt;0\\) además, \\(P_{1}^{M} - P_{0}^{M}(a+b) = 0\\); Recuperando así la fórmula anterior. De igual forma, es fácil ver que si \\(P_{0}^{M} = P_{0}\\) entonces: \\(G_{N^{*}}(t) = G_{N}(t)\\) \\(\\forall t\\)(bien definida según N). Ejemplo 2: Consideremos \\(N\\sim{ Poi (\\lambda=5) }\\) \\(\\mathbb P [X=x] = \\left\\{ \\begin{array}{lcc} 0.25 &amp; si &amp; {x=1}\\\\ 0.5 &amp; si &amp; {x=2}\\\\ 0.25 &amp; si &amp; {x=3}\\\\ \\end{array} \\right.\\) Hacemos \\(N^{*}\\) tal que \\(P_{0}^{M} = \\frac{\\pi}{4}\\) Definimos \\(S= \\displaystyle\\sum_{j=1}^{N^{*}} x_{j}\\) Modelo Colectivo Ejemplo 3: Consideremos \\(N\\sim{ Poi (\\lambda=5) }\\) \\(\\mathbb P [X=x] = \\left\\{ \\begin{array}{lcc} 0.25 &amp; si &amp; {x=0}\\\\ 0.5 &amp; si &amp; {x=1}\\\\ 0.25 &amp; si &amp; {x=2}\\\\ \\end{array} \\right.\\) Hacemos \\(N^{*}\\) tal que \\(P_{0}^{M} = \\frac{\\pi}{4}\\) Definimos \\(S= \\displaystyle\\sum_{j=1}^{N^{*}} x_{j}\\) Modelo Colectivo En resumen: Definiendo \\(S= \\displaystyle\\sum_{j=1}^{N}y_{j}\\) modelo colectivo \\(\\circ\\) Si \\(N\\) es de clase \\((a,b,0)\\) \\(\\Rightarrow \\mathbb P[S=0] = \\left\\{ \\begin{array}{lcc} \\mathbb P[N=0] &amp; si &amp; \\mathbb P [y=0] =0\\\\ G_{N}(\\mathbb P[y=0]) &amp; si &amp; \\mathbb P [y=0] \\neq 0\\\\ \\end{array} \\right.\\)\\ \\ Luego \\(\\forall x\\in sop\\{S\\}/\\{0\\}\\)\\ \\(\\mathbb P [S = x] = \\displaystyle\\frac{ \\displaystyle\\sum_{j=1}^{min\\{x,max\\{sop\\{y\\}\\}\\}} \\left(a+\\frac{bj}{x} \\right) \\mathbb P [y=j] \\mathbb P [s=x-j] }{1-a\\mathbb P [y=0]}\\) \\(\\circ\\) Si \\(N\\) es de clase \\((a,b,1)\\) \\(\\Rightarrow \\mathbb P[S=0] = \\left\\{ \\begin{array}{lcc} P_{0}^{M} &amp; si &amp; \\mathbb P [y=0] =0\\\\ 1-\\left(\\displaystyle\\frac{1-P_{0}^{M}}{1-P_{0}}\\right)(1-G_{N}(\\mathbb P[y=0])) &amp; si &amp; \\mathbb P [y=0] \\neq 0\\\\ \\end{array} \\right.\\) Luego \\(\\forall x\\in sop\\{S\\}/\\{0\\}\\)\\ \\(\\mathbb P [S = x] = \\displaystyle\\frac{ [P_{1}^{M}-(a+b)P_{0}^{M}] \\mathbb P[y=x]+\\displaystyle\\sum_{j=1}^{min\\{x,max\\{sop\\{y\\}\\}\\}} \\left(a+\\frac{bj}{x} \\right) \\mathbb P [y=j] \\mathbb P [s=x-j] }{1-a\\mathbb P [y=0]}\\) Nota: Recuerda \\(M_{N}(t)\\doteq\\mathbb E[e^{tx}]\\) y \\(G_{N}(t) = \\mathbb E[t^{x}]\\) y además \\[G_{N}(e^{t})\\doteq\\mathbb E [(e^{t})^{x}]=\\mathbb E[e^{tx}]=M_{N}(t)\\], \\[\\begin{align*} M_{N}(ln(t)) &amp;\\doteq \\mathbb E [e^{ln(t)x}] = \\mathbb E [e^{ln(t^{x})}]\\ \\ \\\\ &amp;= \\mathbb E [t^{x}] \\doteq G_{N}(t) \\end{align*}\\] \\(\\therefore G_{N}(e^{t}) = M_{N}(t)\\) \\(\\&amp;\\) \\(M_{n}(ln(t)) = G_{N}(t)\\) Nota: Recuerden que para las siguientes propiedades, sus demostraciones no involucran el supuesto de que \\(y\\geq 0\\), de hecho son válidas para construcciones bien definidas de \\(S\\). Proposición: Suponiendo que las cantidades y funciones indicadas existen, el riesgo \\(S\\) en el modelo colectivo cumple las siguientes propiedades: 1. \\(E(S) = E(N)E(Y)\\) -2._ \\(E(S^{2}) = E(N)E(Y^{2}) + E(N(N-1))E^{2}(Y)\\) 3. \\(Var(S) = Var(N)E^{2}(Y) + Var(Y)E(N)\\) 4. \\(M_{S}(t) = M_{N}(ln(M_{Y}(t)))\\) Introducción a la teoría del Riesgo, L. Rincón, pág: 19 Considerando \\(f_{0} \\doteq \\mathbb P[y=0]\\) tenemos lo siguiente: Table D.1. Starting values [\\(f_{s}(0)\\)] for recursions Son los valores iniciales para \\(\\mathbb P [S=0]\\) en cada caso Momento de S para Panjer Sea \\[S\\ddot{=} \\sum_{j=1}^{N}X_{j}\\] entonces: Para N de clase \\((a,b,0)\\): 5.4.3 Theorem (DePril’s Recursion). If the distribution of N is nondegenerate and satisfies \\[p_{n} = (a+\\frac{b}{n}) p_{n-1}\\] for some \\(a,b\\in \\textbf{R}\\) and all \\(n \\in \\textbf{N}\\), then the identity \\(E[S^{n}] = \\frac{1}{1-a} \\sum_{k=1}^{n} \\begin{pmatrix} n \\\\ k \\end{pmatrix} (a+b\\frac{k}{n})E[S^{n-k}]E[X^{k}]\\) \\(n\\in \\textbf{N}\\) Lectures on Risk Theory Klays D. Schmidt Para N de clase \\((a,b,1)\\): Teorema 4.3. Si la distribución primaria \\(\\{p_{k}\\}\\) de \\(S\\) en (14) es clase \\((a,b;1)\\), entonces, para \\(n\\in \\mathbb N\\) \\(E[S^{n}] = \\displaystyle\\frac{ [p_{1}-(a+b)p_{0}] E(X^{n}) + \\sum_{j=1}^{n} \\begin{pmatrix} n \\\\ j \\end{pmatrix} (a+\\frac{bj}{n}) E(X^{j}) E(S^{n-j}) } {1-a}\\) siempre que \\(E(X^{j})\\), con \\(j=1,2,...,n\\), exista Distribuciones clase (a,b) y algoritmo de Panjer César Escalante Coterio Ejemplo 4: Consideremos \\(S= \\sum_{j=1}^{N}X_{j}\\) \\(N\\sim{ Bin (n=4,p= \\textit{0.2}) }\\) \\(\\mathbb P [X=x] = \\left\\{ \\begin{array}{lcc} \\textit{0.5} &amp; si &amp; x=1\\\\ \\textit{0.3} &amp; si &amp; x=2\\\\ \\textit{0.2} &amp; si &amp; x=3\\\\ \\end{array} \\right.\\) \\(\\Rightarrow\\) \\(M_{x}(t) \\doteq \\mathbb E[e^{tx}] = \\textit{0.5}e^{t} + \\textit{0.3}e^{2t} + \\textit{0.2}e^{3t}\\) Continuemos el ejemplo en el Script de esta sección Adicionalmente, si la severidad resulta continua, existen diversas maneras de discretizarla y utilizar la fórmula de Panjer. se invita al lector a revisar y meditar esta clase de metodologías si en algún momento se enfrenta a situaciones de este estilo. Un vídeo donde se explican algunos detalles más de estos lo podemos ver a continuación: Link de YouTube: https://www.https://www.youtube.com/watch?v=H4ETDaUUvTk "],["reaseguro.html", "Capítulo 13 Reaseguro Reaseguro proporcional", " Capítulo 13 Reaseguro Ya que conocemos más de cómo funciona la v.a. \\(S\\), intentaremos modelarla desde otra perspectiva. Pensemos a \\(S\\) como siempre: \\[S=\\displaystyle\\sum_{j=1}^N X_j\\] Ahora, supongamos que este portafolio se fragmentará en dos partes, lo que paga la aseguradora \\((S^A)\\) y lo que paga la reaseguradora \\((S^R)\\) de tal manera que: \\[S={S^A}+{S^R}\\] Hay diferentes maneras de hacer una partición de pólizas entre la aseguradora y la reaseguradora. Veremos en lo siguiente las formas más comúnes. Notemos lo siguiente la similaridad con los temas pasados del curso. Reaseguro proporcional Similar al coaseguro el reaseguro proporcional divide el riesgo \\((S)\\) en dos partes considerando un \\(a\\in[0,1]\\), diremos entonces que “\\(a\\)” es la proporción del riesgo \\((S)\\) que le toca pagar a la aseguradora, mientras que “\\(1-a\\)” es lo que le toca a la reaseguradora. \\[\\begin{eqnarray*} \\begin{array}{lcc} S^A=aS=\\displaystyle\\sum_{j=1}^N aY_j, \\\\ S^R=(1-a)S=\\displaystyle\\sum_{j=1}^N(1-aY_j) \\end{array} \\end{eqnarray*}\\] Las características probabilísticas de \\(S^A\\), o bien de \\(S^R\\), se encuentran fácilmente de las de \\(S\\), pues no es difícil comprobar los siguientes resultados. a) \\(F_{S^A}(x)=F_{{S}}\\left(\\frac{x}{a}\\right)\\) b) \\(f_{S^A}(x)=\\frac{1}{a}f_{{S}}\\left(\\frac{x}{a}\\right)\\), cuando \\(S\\) es absolutamente continua. c) \\(M_{S^A}(r)=M_{{S}}(ar)\\) d) \\(E(S^A)=aE(S)\\leq E(S)\\). e) \\(Var(S^A)=a^2Var(S)\\leq Var(S).\\) Introducción a la teoría del Riesgo, L. Rincón, pág:81 Nótese que \\(aY_j\\) es la proporción por póliza que paga la aseguradora. Reaseguro no proporcional \\(\\bullet\\) Reaseguro en el riesgo completo (stop loss) Aquí lo que se define es un cierto monto \\(\\mu&gt;0\\) llamado nivel de retención del cual se establecerá que cada parte cubrirá un riesgo \\((S)\\) de la siguiente manera: \\[S^A=mín\\{S,\\mu\\}: S^R=máx\\{0,S-\\mu\\}\\] Una vez más en términos de \\(S\\) nosotros ya sabemos trabajar perfectamente tanto a \\(S^A\\) como \\(S^R\\) en este caso pues son casos particulares de monto máximo de beneficio y deducible. Notemos aquí un detalle importante \\(S^A\\) y \\(S^R\\) cubren un nivel de retención \\(\\mu\\) sobre todo el portafolio \\(S\\). Es decir, que no depende de cada póliza sino de todo lo que trae consigo el portafolio. Lo que nos da pie a un caso interesante. \\(\\bullet\\) Reaseguro en el riesgo completo (stop loss) Bajo esta idea, se ``repartirán” los pagos, de la siguiente manera: \\[\\begin{equation*} S^{A}= \\displaystyle\\sum_{j=1}^{N} mín \\{ X_{j}, M\\} \\quad \\text{y} \\quad S^{R}= \\displaystyle\\sum_{j=1}^{N} máx \\{ 0,X_{j}-M \\} \\end{equation*}\\] Donde \\(\\mu\\) juega un papel de monto máximo de beneficio y deducible por cada asegurado, desde el punto de vista de la aseguradora y reaseguradora respectivamente. A pesar de esto y daod que estamos hablando de reaseguro (excess of loss) seguiremos llamando A \\(m\\) como nivel de retención. Notemos que estos casos ya los hemos trabajado, pero hay aquí un detalle interesante. Recordemos que, por ejemplo para la reaseguradora en este caso, si \\(X_{j} \\leq M\\) para la reaseguradora no pagó. De tal manera que el número de pagos que hizo \\(S_{R}\\) no está del todo determinado por \\(N\\). Nota No confundir los siguientes conceptos \\[\\begin{eqnarray*} \\displaystyle\\sum_{j=1}^{N} mín \\{ X_{j}, M\\} \\neq mín \\{S,M \\}\\\\ \\displaystyle\\sum_{j=1}^{N} máx \\{0, X_{j}-M\\} \\neq máx \\{0,S-M \\}\\\\ \\end{eqnarray*}\\] Esto significa que los modelos “excess of loss”, y “stop loss” no son necesariamente equivalentes. Se invita a platicar un poco sobre esto. A continuación mostramos algunos vídeos con los temas que se acaban de mencionar. Link de YouTube: https://www.youtube.com/watch?v=LbDaSLqyfYE Link de YouTube: https://www.youtube.com/watch?v=xUroi0VZll4 Link de YouTube: https://www.youtube.com/watch?v=pGP_bK8x2-U Link de YouTube: https://www.youtube.com/watch?v=TAjhROWBkiE \\(\\longrightarrow\\) Número de reclamaciones Bajo el esquema “excess of loss” y considerando un nivel de retención M: \\(N^{A} \\ddot{=} \\displaystyle\\sum_{j=1}^{N} \\mathbb I_{(X_{j}\\leq M)}\\) = # pagos Sin incurrir al reaseguro \\(N^{R} = \\displaystyle\\sum_{j=1}^{N} \\mathbb I_{(X_{j}&gt; M)}\\) = # pagos que hizo la reaseguradora Es fácil notar que \\(N=N^{A} + N^{R}\\), luego se satisfacen las siguientes propiedades Proposición: Sea \\(a=P(Y_{j}\\leq M)\\). Entonces, 1. si \\(N\\) tiene distribución \\(bin(n,p)\\), a) \\(N^{A}\\sim{bin(n,ap)}\\) b) \\(N^{R}\\sim{bin(n,(1-a)p)}\\) 2. si \\(N\\) tiene distribución \\(Poisson(\\lambda)\\). a) \\(N^{A}\\sim{Poisson(\\lambda a)}\\) b) \\(N^{R}\\sim{Poisson(\\lambda(1-a))}\\) 3. si \\(N\\) tiene distribución \\(bin\\) \\(neg(k,p)\\) a) \\(N^{A}\\sim{bin neg(k,p/(p+a(1-p)))}\\) b) \\(N^{R}\\sim{bin neg(k,p/(p+(1-a)(1-p)))}\\) Introducción a la teoría del Riesgo, L. Rincón, pág: 86 Es muy útil notar que \\(N^{A}\\) y \\(N^{R}\\) son en realidad casos particulares del modelo colectivo, noten que ambas son sumas aleatorias de variables aleatorias ¿Cuáles? \\(I_{(X_{j}\\leq M)}\\sim{Ber(p=\\mathbb P [X_{j}\\leq M])}\\) \\(I_{(X_{j}&gt; M)}\\sim{Ber(p=\\mathbb P [X_{j}&gt; M])}\\) Donde, desde luego, \\(\\mathbb P [X_{j}\\leq M] = 1-\\mathbb P [X_{j}&gt; M]\\). Con base en esto, la siguiente demostración es sencilla recordando que para cualquier modelo colectivo: Tomando \\(a\\doteq \\mathbb P [y \\leq M]\\), P.D \\(N\\sim{Bin(n,p)}\\) \\(\\Rightarrow N^{A}\\sim{Bin(n,ap)}\\) } \\[M_{Y}(t) = E(e^{tY}) = 1-a+ae^{t}\\] Entonces \\(M_{N^{A}}(t) = M_{N}(ln(1-a+ae^{t}))\\). Cuando \\(N\\) tiene distribución bin\\((n,p)\\) tenemos que \\(M_{N}(t) = (1-p+pe^{t})^{n}\\). Por lo tanto, \\[M_{N^{A}}(t) = (1-p+p(1-a+ae^{t}))^{n} = (1-ap+ape^{t})^{n}\\]. Ejemplo: Sea \\(N\\sim{Bin(n=5,p=0.15)}\\) \\(\\mathbb P [X=k] = \\left\\{ \\begin{array}{lcc} \\textit{ 0.8} &amp; si &amp; x=1\\\\ \\textit{0.1} &amp; si &amp; x=2\\\\ \\textit{ 0.1} &amp; si &amp; x=3\\\\ \\end{array} \\right.\\) Consideremos un nivel de retención \\(M=2\\) \\(\\Rightarrow\\) \\(a\\doteq \\mathbb P[X\\leq M] = \\textit{0.9}\\) Veamos lo que sucede con \\(N^{A}\\) y \\(N^{R}\\) en R. Script: “Reaseguro” "],["calculo-de-primas.html", "Capítulo 14 Calculo de primas Propiedades y Principios del cálculo de Primas", " Capítulo 14 Calculo de primas A lo largo de la carrera hemos estudiado diversas formas de calcular una prima de seguros. Por ejemplo, en MASP nosotros definíamos \\({T_x}\\) como la variable aleatoria del tiempo futuro de vida para una persona de edad \\((x)\\). A partir de esta, lo que hacíamos era pensar en un flujo de efectivo “$”, el cual movíamos a lo largo del tiempo \\(T_x\\). De esta manera, los flujos de efectivo pasaban de ser “ciertos” como en las matemáticas financieras, a ser \\({Contingentes}\\) por el efecto de la \\(v.a.\\). \\[ (\\$)(1+i)^{-{T_x}}=(\\$)(V^{{T_x}})= (\\$){\\cdot e^{-\\delta {T_x}}} \\] \\(V^{T_x}\\) es v.a. Recordemos que como \\(T_x\\) era una \\(v.a.\\) entonces tenía asociada una función de densidad en el caso continuo: \\[f_{T_x}(t)=~_tP_x \\mu_{x+t}; \\text{para} ~t\\in (0,w-x)~//~ w-x=\\text{límite de vida}\\] B ajo un contexto de seguro de personas, una suma asegurada fija SA se pagaba al instante de fallecimiento. Al ser este un momento desconocido, la \\(v.a.\\) que indica el valor presente de la suma asegurada es: \\({SA}V^{{T_x}}\\). Su valor esperado se definía: \\[{SA}\\underbrace{{{A_x}}}_{notación~actuarial}= {SA} \\mathbb{E}[V^{{T_x}}]= {SA} \\displaystyle \\int_0^{w-x}V^t f_{{T_x}}(t)dt \\] Por otro lado el asegurado se comprometía a pagar una Prima pago que se haría hasta el momento en que la persona falleciera. En el caso discreto los pagos se ven como una anualidad vencida cuyo valor presente era modelado con la \\(v.a.\\): \\[{P}\\bar{a}_{{T_x}} ={P} \\left(\\frac{1-V^{{T_x}}}{i}\\right) \\] y generalizando esto al caso continuo, la \\(v.a.\\) está dada por: \\({P}{a}_{{{T_x}}|\\delta}= {P}\\left( \\frac{1-V^{{T_x}}}{\\delta}\\right)\\) y su valor esperado se calculaba: \\[{P}{\\bar{a_x}} = {P}\\mathbb{E} \\left[\\frac{1-V^{{T_x}}}{\\delta}\\right]={P} \\displaystyle \\int_0^{w-x} \\frac{1-V^t}{\\delta} f_{{T_x}}(t)dt={P} \\displaystyle \\int_0^{w-x} \\frac{1-V^t}{\\delta} _tP_x \\mu_{x+t}dt\\] Nota: En el caso discreto, estas esperanzas se calculaban usando probabilidad total. Finalmente esa prima P la llamábamos Prima de Riesgo si era tal que las obligaciones entre ambas partes fueran iguales a tiempo cero (el día de hoy). \\[{P}({\\text{obligaciones futuras del asegurado}})={P}{{a}_x}={SA}{{A}_x}={SA}({\\text{obligaciones futuras del asegurado}})\\] En el mundo actuarial SOA esto se le conoce como matemáticas actuariales de largo plazo (Por sus siglas en inglés LTAM). Nosotros en Teoría del Riesgo veremos algunas metodologías a corto plazo (STAM). Con las herramientas que tenemos podemos definir una prima túnica que bajo la idea anterior nos cubra de una forma justa tanto para la parte del asegurado como para la compañía Prima de Riesgo y esto es tomando Prima de riesgo\\(={P}=\\mathbb{E}[{S}]\\) Esta prima será la que cobrará la compañía de seguros. Únicamente para absorber el riesgo. Faltaría entonces agregar los gastos de administración o cualquier gasto operativo que tenga la compañía aseguradora. Resulta ser que esta prima debe ser únicamente de referencia ya que a la larga si una aseguradora cobrara la prima de riesgo podrían haber consecuencias no favorables Para ver esto consideremos un portafolio homogéneo de n pólizas de un mismo riesgo y válidas por un periodo determinado. Supongamos que cobramos la misma prima P por cada póliza y que \\({S_j}\\in\\{ 1, \\dots, n\\}\\) representa el monto de reclamaciones efectuadas por la póliza j, tomándolas homogéneas e independientes serán v.a.i.i.d.. Nota: La v.a. S puede representar a uno o más asegurados. Sea \\(u\\) el capital inicial de la aseguradora entonces el capital de la aseguradora al término de la vigencia de las n-pólizas es: \\[{X_n}=\\underbrace{{u}}_{capital~inicial}+n{P} -\\underbrace{\\sum_{j=1}^n {S_j}}_{Total~ siniestros}={u}+ \\underbrace{\\sum_{j=1}^n({P}-{S_j})}_{Ganancia/pérdida~por~póliza} \\] Notamos que tomando la esperanza de la v.a. anterior \\[\\mathbb{E}[{X_n}]={u}+ n{P}-\\mathbb{E}[\\sum_{j=1}^n{S_j}]= {u}+ n({P} -\\mathbb{E}[{S}] )\\] Luego dependiendo del valor que le asignamos a {P} \\[\\lim_{n\\to \\infty} \\mathbb{E}[{X_n}] \\begin{cases} \\infty~~~~~~si~~~~ {P}&gt;\\mathbb{E}[{S}]\\\\ \\text{¿}{u}?~~~~si~~~~ {P}=\\mathbb{E}[{S}]\\\\ -\\infty~~~~si~~~~ {P}&lt;\\mathbb{E}[{S}] \\end{cases}\\] Se puede observar vía simulaciones que si \\({P}=\\mathbb{E}[{S}]\\) entonces \\(\\mathbb{E}{X_n}]\\) puede oscilar entre valores muy grandes o muy pequeños (y con pequeños, hablamos de “muy negativos”) de forma aleatoria cuando \\(n\\rightarrow \\infty\\). Lo que nos lleva a las siguientes preguntas: ¿Cómo calcular una prima?, ¿Puedo proponer una metodología?, ¿Porqué estas viendo esto si a ti te gustan las finanzas? Propiedades y Principios del cálculo de Primas Las siguientes son propiedades generales que son deseables que posea cualquier método para calcular primas: a) \\(Simplicidad:\\) Debe ser fácil de calcular, por ejemplo a través de esperanzas, varianzas, etc. Sea “\\(P^{(\\star)}(S)\\)” la prima que cobraremos al asumir el riesgo “\\(S\\)” con la metodología (\\(\\star\\)). b) \\(Cota \\ \\ inferior:\\) Se debe verificar que: \\(P^{(\\star)}(S)\\geq \\mathbb{E}[S]\\). c) \\(Consistencia:\\) Si \\(a&gt;0\\Rightarrow P^{(\\star)}(S+a)=a+P(S).\\) d) \\(Aditividad:\\) Si \\(S_1 \\bot S_2 \\Rightarrow P^{(\\star)}(S_1+S_2)=P^{(\\star)}(S_1)+P^{(\\star)}(S_2)\\). e) \\(Invarianza\\ \\ de\\ \\ escala:\\) Tomemos \\(c&gt;0\\Rightarrow P^{(\\star)}(cS)=cP^{(\\star)}(S)\\). f) \\(Cota\\ \\ superior:\\) Si \\(\\exists \\mu &gt;0 \\hspace{0.4em}\\cdotp)\\cdotp\\hspace{0.4em} S\\leq \\mu \\Rightarrow P^{(\\star)}(S)\\leq\\mu\\). Estas son propiedades deseables, no siempre es de interés que se cumplan. Los siguientes son algunos Principios (Metodologías) de cálculos para primas: (citamos repetidas veces a Luis Rincón). Principio de valor esperado Establece que la prima puede calcularse de la siguiente manera: \\[P^{(E)}(S)\\hspace{0.4em }\\ddot{=}\\hspace{0.4em}(1+\\theta)\\mathbb{E}[S]\\] En donde \\(\\theta&gt;0\\) es una constante llamada Safety loading, la cual busca fungir como un factor de recargo para compensar los costos administrativos, entre otras cosas de la compañía de seguros. En el factor de recargo se encuentran inmersos los costos administrativos y comerciales del seguro, así como los márgenes de utilidad de la aseguradora. La forma simple en la que se calculan las primas mediante este principio es una de sus características principales, sin embargo puede observarse que una desventaja de esta fórmula es que asigna la misma prima a dos riesgos con distinta distribución pero con media común, y no toma en cuenta otros aspectos. Por ejemplo, si las varianzas de los riesgos fueran distintas, entonces las primas tal vez deberían ser distintas. Principio de la varianza \\[P^{(V)}(S)\\hspace{0.4em}\\ddot{=}\\hspace{0.4em}\\mathbb{E}[S]+\\theta Var(S)\\] Este principio hace uso de la esperanza y la varianza del riesgo. En este caso el factor de recargo \\(\\theta&gt;0\\) se aplica sobre el valor de la varianza. Es importante destacar que estos principios no necesariamente cumplen todas las propiedades del cálculo de primas. Por ejemplo: \\(\\bullet\\) Aditividad: Sean dos riesgos \\(S_1\\bot S_2\\), ahora: \\[\\begin{eqnarray*} \\left. \\begin{array}{lcc} P^{V}(S_1+S_2)&amp;=&amp;\\mathbb{E}[S_1+S_2]+\\theta Var(S_1+S_2)\\\\ &amp;=&amp;\\underbrace{\\mathbb{E}[S_1]\\theta Var(S_1)}+\\underbrace{\\mathbb{E}[S_2]+\\theta Var(S_2)}\\\\ &amp;=&amp;\\ P^{(V)}(S_1)\\quad +\\quad P^{(V)}(S_2)\\quad \\end{array} \\right\\} \\begin{array}{lcc} Var(S_1+S_2) =Var(S_1)+Var(S_2) \\end{array}\\\\ \\end{eqnarray*}\\] \\[\\therefore \\mbox {Satisface aditividad}\\] \\(\\bullet\\) Invarianza de escala: Sea \\(S\\) un riesgo y \\(c&gt;0\\): \\[\\begin{eqnarray*} { \\left.\\begin{array}{lcc} {P^{(V)}(cS)=\\mathbb{E}[cS]+\\theta Var(cS)=c(\\mathbb{E}[S]+\\theta cVar(S))} \\\\ \\hspace{2.0cm}{\\neq c(\\mathbb{E}[S]+\\theta Var(S))=cP^{V}(S)} \\end{array} \\right\\} \\mbox{Si } c\\neq 1} \\end{eqnarray*}\\] \\(\\therefore\\) No satisface la propiedad de Invarianza de escala. Principio de la desviación estándar \\[P^{(V)}(S)\\hspace{0.4em}\\ddot{=}\\hspace{0.4em}\\mathbb{E}[S]+\\theta Var(S)\\] Sea nuevamente \\(\\theta&gt;0\\) una constante.En este principio el factor de recargo se aplica sobre la desviación estándar del riesgo como indica la fórmula que aparece arriba. A diferencia del principio de la varianza, en este caso las unidades de medición del riesgo y de la prima coinciden.Y es evidente que la prima calculada mediante este principio produce una prima menor o igual a aquella calculada mediante el principio de varianza. Ejercicio: Propón un riesgo \\(S\\) que sirva de contra-ejemplo para está afirmación. En otras palabras, busca un riesgo \\(S\\) tal que \\(P^{(SD)}(S)&gt;P^{(V)}(S)\\). Principio de utilidad cero Este principio hace uso de una función de utilidad, esto es, una función \\(v(x)\\) definida sobre \\([0,\\infty)\\) o un subconjunto de este intervalo y con valores en \\(\\mathbb{R}\\), que cumple las propiedades que se mencionan a continuación} \\(a)\\) Es estrictamente creciente. \\(b)\\) Es cóncava. Suponiendo diferenciabilidad, la primera condición se escribe \\(v&#39;(x)&gt;0\\), y la segunda condición significa que \\(v&#39;&#39;(x)\\leq 0\\). A veces se añade la condición \\(v(0)=0\\) pues toda función de utilidad (definida en \\(x=0\\)) puede modificarse de tal forma que cumpla esa condición sin afectar el resultado en los procesos de decisión que llevaremos a cabo usando estas funciones. La nueva función de utilidad sería \\(v(x)-v(0)\\). Lo que hace una función de utilidad es brindar una manera en que la entidad/individuo que está expuesto a un evento fortuito observa las cosas. Dicho de alguna forma, es la herramienta que nos permite darle peso a algo desde nuestra perspectiva, nos permite indicar preferencias, en este caso, al riesgo. De acuerdo al principio de utilidad cero, la prima que debemos cobrar es el número real \\(P\\)=\\(P^{(vc)}(S)\\) tal que: \\[\\begin{eqnarray*} v({u})&amp;=&amp;\\mathbb{E}[v({u}+{P}-{S})] \\end{eqnarray*}\\] Donde \\(u\\) representa el capital inicial de la compañía y \\(S\\) el riesgo a asumir. Esto significa que la utilidad del capital inicial de la compañía debe ser equivalente a la utilidad esperada al cubrir el riesgo. En general nosotros supondremos que la ecuación anterior tiene una única solución. En muchas ocasiones encontrar una solución analítica para \\(P\\) suele ser complicado. En este caso buscaremos soluciones numéricas para este problema . A continuación, veamos un ejemplo que si tiene una solución sencilla. Ejemplo: Consideremos la función de utilidad: \\(v(x)=1-e^{-\\alpha x}: \\alpha&gt;0\\). (Queda como ejercicio para el lector verificar que es función de utilidad). de este manera buscamos una \\(P\\) tal que: \\[\\begin{eqnarray*} 1-e^{-\\alpha x}&amp;=&amp; v({u}) \\quad \\text{Esto queremos}\\\\ &amp;=&amp; \\mathbb{E}[v( {u} + {P} - {S} )]\\\\ &amp;=&amp; \\mathbb{E}[1-e^{-\\alpha (u+P-S)}]\\\\ &amp;=&amp; 1-e^{-\\alpha(u+P)}´\\mathbb{E}[e^{\\alpha S}\\\\ &amp;=&amp; 1-e^{-\\alpha (u+P)} M_{S}(\\alpha)\\\\ \\Leftrightarrow e^{\\alpha P}&amp;=&amp;M_{S}(\\alpha)\\\\ \\end{eqnarray*}\\] Si y solo si: \\[\\begin{eqnarray*} {{P} = \\displaystyle\\frac{1}{\\alpha} ln(M_{{S}}(\\alpha))}\\\\ \\end{eqnarray*}\\] Nota: En este caso particular, no depende de }} \\end{tcolorbox} \\end{list} Nota: En este caso particular, \\(P\\) no depende de \\(u\\). Otra pregunta que viene es ¿Por qué debe ser así una función de utilidad? Recordemos que: Proposición: Desigualdad de Jensen Sea \\(u\\) una función convexa ,y sea \\(X\\) una variable aleatoria con esperanza finita. \\[\\begin{eqnarray*} u(\\mathbb{E}(X)) \\leq \\mathbb{E}(u(X))\\\\ \\end{eqnarray*}\\] De aquí , sabemos que si u es convexa \\(\\Leftrightarrow -u \\ddot{=} v\\) es cóncava y: \\[\\begin{eqnarray*} u(\\mathbb{E}(X)) \\leq \\mathbb{E}[u(X)] &amp;\\Leftrightarrow&amp; v(\\mathbb{E}[X])=-u(\\mathbb{E}[X]) \\geq -\\mathbb{E}[u(x)]=\\mathbb{E}[v(X)]\\\\ \\end{eqnarray*}\\] \\(\\therefore\\) Si \\(v\\) es una función cóncava: \\(v(\\mathbb{E}[X])\\geq \\mathbb{E}[v(X)]\\) Entonces si \\(P\\) se obtiene de acuerdo al principio de utilidad cero y \\(v(x)\\) es una función de utilidad, se satisface: \\[\\begin{eqnarray*} v({u})&amp;=&amp; \\mathbb{E}[v({u} + {P} - {S})] \\leq v(\\mathbb{E}[{u} + {P} -{S} ])= v( {u}+{P} - \\mathbb{E}[{S}]) \\end{eqnarray*}\\] \\(v\\) es cóncava y usamos Jensen Como \\(v\\) es estrictamente creciente entonces tienen inversa y también es creciente. Aplicando \\(v^{-1}\\) de ambos lados de la desigualdad, esta NO se altera y entonces: \\[\\begin{eqnarray*} {u} \\leq {u} + {P} - \\mathbb{E}{{S}} \\Leftrightarrow \\mathbb{E}[{S}] \\leq {P} \\end{eqnarray*}\\] Cumpliendo así una de las propiedades más importantes: Cota inferior. Si no pidiéramos que \\(v\\) como función de utilidad, cumpliera alguno de los supuestos anteriores, no podríamos usar la prueba anterior y más aún, los resultados obtenidos podrían no cumplir la propiedad de cota inferior. Se presentan a continuación algunos ejemplos de funciones de utilidad: \\(a)\\) Función de utilidad exponencial \\[\\begin{eqnarray*} v(x)=1-e^{-\\alpha x}, \\quad \\alpha &gt;0\\\\ \\end{eqnarray*}\\] \\(b)\\) Función de utilidad cuadrática \\[\\begin{eqnarray*} v(x)=x-\\alpha x ^{2} \\quad \\alpha &gt;0, \\quad \\text{para} 0\\leq x \\leq 1/(2a)\\\\ \\end{eqnarray*}\\] \\(c)\\) Función de utilidad logarítmica \\[\\begin{eqnarray*} v(x)=a ln(x), \\quad \\alpha &gt;0\\\\ \\end{eqnarray*}\\] \\(d)\\) Función de utilidad de potencia fraccional \\[\\begin{eqnarray*} v(x)=x^{\\alpha}, \\quad 0&lt; \\alpha \\leq 1\\\\ \\end{eqnarray*}\\] Existen más y diversas formas de calcular la prima correspondiente a un riesgo que buscamos asumir. A continuación mostramos una serie de vídeos que explican lo anterior y más principios (metodologías). Al final, en la práctica cada aseguradora tiene su metodología técnica (a veces “ultra-secreta”) de hacer esta clase de cálculos. Propiedades generales Figura 1: https://www.youtube.com/watch?v=QSqioUk8di8 ¿Por qué: \\(P \\geq \\mathbb{E}[S]\\) ? Figura 2: https://www.youtube.com/watch?v=Wk4rj2X5QKU Principio de valor esperado Figura 3: https://www.youtube.com/watch?v=4rgG755GrzI Principio de la Varianza Figura 4: https://www.youtube.com/watch?v=8Gueak3JbmQ Principio de la desviación estándar Figura 5: https://www.youtube.com/watch?v=0PO_1paX6q0 Principio de utilidad cero Figura 6: https://www.youtube.com/watch?v=FTjJNnmtXEQ Un caso particular: Principio exponencial Figura 7: https://www.youtube.com/watch?v=G-kdmOvGQaM Similar al de utilidad cero, tenemos: Principio de valor medio Figura 8: https://www.youtube.com/watch?v=zZBLfA0smzM Usando una idea similar al VaR para la prima: Principio del porcentaje Figura 9: https://www.youtube.com/watch?v=fB9YgXOfWJI Algunas metodologías más elegantes: Principio Esscher Figura 10: https://www.youtube.com/watch?v=GrLNmeDKbec Principio de riesgo ajustado Figura 11: https://www.youtube.com/watch?v=qUnqBKJBXPI "],["credibilidad.html", "Capítulo 15 Credibilidad 15.1 Teoría de la credibilidad 15.2 Enfoque bayesiano 15.3 Teorema de Bayes 15.4 Familias conjugadas 15.5 Cálculo Bayesiano de primas de seguros", " Capítulo 15 Credibilidad 15.1 Teoría de la credibilidad 15.1.1 Introducción La teoría de la credibilidad es el conjunto de técnicas actuariales que permiten al asegurador ajustar de modelo sistemático las primas de los seguros en función de la experiencia de la siniestralidad ocurrida. En la teoría de la credibilidad tienen roles primordiales los dos tipos de riesgo ya considerados: el riesgo individual y el riesgo colectivo, y se da una solución rigurosa al problema de cómo analizar la información proveniente de estas dos fuentes, para calcular la prima de seguros y obtener una tarifa justa. La teoría de la credibilidad como disciplina matemática, utiliza diversas herramientas de varios campos de las matemáticas: Estadística Bayesiana, análisis funcional, mínimos cuadrados, modelos de espacio de esados, entre muchos otros. Varios autores, Beiley. Longley-Cook, Mayerson, Bühlmann, Straub, Jewell, entre otros, se han dado a la tarea de dar una fundamentación matemática rigurosa a esta teoría, que la ha convertido en una de las ramas más atractiva y estudiada de la ciencia actuarial. Uno de sus principales usos aparece en el seguro de automóviles, en el que las primas se van transformando paulatinamente a medida que se incorpora información sobre la siniestralidad, dando origen a los denominados sistemas de tarificación bonus-malus. El término credibilidad se introdujo por primera vez en USA antes de la primera guerra mundial, en relación con los sistemas de ajuste de primas en seguros de compensación obrera o seguros de accidentes. Por ese entonces, numerosas empresas ejercieron una fuerte presión a las aseguradoras dada la baja siniestralidad laboral y la elevada tasa de actividad, para que se les reconociera este hecho en los importes de primas a pagar. Withney (1918) publicó los primeros trabajos en esta materia con la aparición en los Proceedings de la Casualty Actuarial Society. de una forma simple, a través de una matemática elemental, propone que la prima que debe pagar un asegurado considere tanto la experiencia individual (del asegurado) y la del colectivo (la carta de seguros). De esta manera, la estimación del monto de la prima, se calculará como: \\[\\textbf{P}=Z\\cdot\\textbf{X}+(1-Z)\\cdot\\textbf{C}~~~~~~~~(1)\\] Con \\(\\textbf{X}\\) la experiencia individual, \\(\\textbf{C}\\) es la información disponible del colectivo y Z es un factor que pondera estas dos informaciones, conocido como \\(\\textit{factor de credibilidad }\\). Esta expresión dio respuesta a la idea que rondaba la mente de muchos actuarios de la época. Encontrar un mecanismo que permitiera asignar a estos dos tipos de información, la individual y la colectiva, un peso o ponderación que las complementara para la determinación de la prima a cobrar. Intuitivamente, este factor de credibilidad, Z, debería satisfacer las siguientes condiciones: Debe ser una función del tiempo de vigencia de la póliza, \\(\\textit{n}\\), i.e., \\(Z=Z(n)\\). Debe ser una función creciente de \\(n\\), de tal manera que converja a \\(uno\\) si $n$ y tienda a \\(cero\\) cuando \\(n\\to 0\\). Este ultimo caso, (\\(n=0\\)), implicaría que no se tiene información sobre el asegurado (sería un contrato nuevo), y la prima a cobrar sería, \\(C\\), la que se basa en la información del colectivo. En la medida que se incremente la información del asegurado (que \\(n\\) crezca), entonces esta información empezaría a tener más peso en el cálculo de la prima a cobrar, i.e., la experiencia de la siniestralidad del asegurado tendría mayor verosimilitud o credibilidad. En el caso extremo, (\\(n\\to\\infty\\)), el valor de la prima debería ser \\(X\\), esto es, la prima debería basarse únicamente en la experiencia individualidad de la siniestralidad del asegurado. El factor de la credibilidad, \\(Z\\), debería ser también una función creciente de la varianza de las primas teóricas, con límite \\(uno\\) cuando esta varianza tienda a infinito, y \\(cero\\) cuando tienda a cero. La lógica de esta cuestión es que si la cartera no es \\(\\textit{heterogénea}\\), i.e., es \\(\\textit{homogénea}\\) entonces la prima basada en la información del colectivo sería el mejor estimador de la prima individual. Por el contrario, una mayor heterogeneidad de la cartera, debería propiciar un mayor peso a la información individual del asegurado. A mediados del siglo \\(XX\\) empezaba a tomar forma un nuevo enfoque de la estadística, la \\(\\textit{Estadística Bayesiana}\\). No pasó mucho tiempo para que se constatara que muchos estimadores de Bayes, obtenidos para ciertas verosimilitudes (distribución conjunta de los datos) y la distribución \\(\\textit{A priori}\\) o inicial natural conjugada del parámetro o parámetros que determinan esta verosimilitud, correspondían a la expresión \\((1)\\). De hecho, Whetney (1918) ya señalaba que el problema de credibilidad era un caso de cálculo de probabilidades inversas (teorema de Bayes). En el trabajo de Mayerson (1964) se utilizan por primera vez los términos de credibilidad y estadística Bayesiana. Bajo el enfoque Bayesiano, la fórmula de credibilidad \\((1)\\) puede interpretarse también de la siguiente manera. Puede verse a \\(\\textbf{C}\\) como la información a priori (basada, por ejemplo, en contratos similares) y \\(\\textbf{X}\\) la nueva información obtenida mediante la observación de la siniestralidad de los últimos años. Finalmente, la prima, \\(\\textbf{P}\\), es el resultado de combinar la información a priori con la información adquirida para obtener un \\(\\textit{estimador actualizado}\\) de la prima. Por lo tanto, la teoría de la credibilidad es un proceso Bayesiano que combina la información inicial o apriori con la información muestral para lograr una actualización del estimador de la prima. Consideremos un riesgo determinado que proveniente de un conjunto de asegurados vigentes por un periodo determinado. Si este grupo de asegurados es homogéneo, en el sentido de que todos sus miembros tienen la misma probabilidad de realizar una reclamación, entonces es razonable aplicar una misma prima para todos ellos. Sin embargo, cuando el grupo no es homogéneo, o bien, al paso del tiempo aparecen factores de heterogeneidad dentro del mismo, habrá subgrupos de bajo riesgo y otros de alto riesgo. Cobrar una misma prima a todos resultaría injusto, y no sería conveniente para la aseguradora, pues, eventualmente, los asegurados de bajo riesgo buscarían un mejor trato con otra aseguradora. La idea fundamental es aplicar primas menores a los asegurados de bajo riesgo y primas mayores a los de alto riesgo, con base en el historial de reclamaciones que cada uno de los asegurados o subgrupos hayan realizado durante los periodos anteriores. \\(\\textit{En la teoría de la credibilidad}\\) se estudian métodos para el cálculo de primas a través de la combinación de la experiencia individual (historial de reclamaciones, datos propios) y la experiencia de grupo (datos del mercado, contratos similares, experiencia propia acumulada, datos colaterales). Con base en lo dicho anteriormente, podemos decir que la finalidad de la \\(\\textit{teoría de la credibilidad}\\) es ajustar el valor de una \\(prima\\) con base en el \\(historial\\)/\\(experiencia\\) que tiene la aseguradora con cierto siniestro. Para lograr esto, nosotros en este caso vamos a trabajar ajustando la \\(\\textit{prima de riesgo}\\), en general se puede hacer esto para que la \\(\\textit{prima de tarifa}\\) pueda ser calculada tomando como referencia a la de riesgo. Tomaremos para esta sección \\(S\\) un riesgo arbitrario que busca absorber una aseguradora, correspondiente a un asegurado o grupo de asegurados con \\(\\textit{características homogéneas}\\) y válido por un periodo determinado. Denotaremos como \\(\\{ S_i \\}_{i=1}^{m}\\) los montos registrados de las reclamaciones efectuadas por el asegurado o portafolio de asegurados durante \\(m\\) periodos consecutivos. Con base en la estadística clásica y Bayesiana, las metodologías que hay para la teoría de la credibilidad son dos principales ramas: \\[\\begin{equation*} \\text{Teoría de la credibilidad} \\begin{cases} \\text{Clásica} \\begin{cases} \\text{Completa}\\\\ \\text{Parcial} \\end{cases}\\\\ \\text{Bayesiana} \\end{cases} \\end{equation*}\\] Al igual que se hizo a lo largo de la historia, exploraremos la forma clásica, pues tiene sus fundamentos en resultados asintóticos que ya se han trabajado. Posteriormente veremos la perspectiva Bayesiana que es otra manera de atacar el problema pero con el apoyo de los fundamentos de la parte clásica. 15.1.2 Credibilidad Completa/total Para lograr el ajuste a la \\(\\textit{prima de riesgo}\\), la cual estamos modelando como \\(\\mathbb{E}[S]\\), con base en el histórico, vamos a recurrir a su versión muestral. Como ya lo hemos hecho antes, nos interesa conocer el comportamiento de: \\[\\overline{S}= \\frac{1}{m}\\sum_{i=1}^{m}S_i\\] Esto lo haremos así pues, si la modelación del riesgo que nosotros estamos proponiendo es correcta, entonces por las leyes de los grandes números: \\[\\begin{equation*} \\begin{array}{cc} \\text{La prima de} \\\\ \\text{riesgo que nos } \\\\ \\text{dicen los datos.}\\end{array} = \\overline{S}= \\displaystyle\\frac{1}{m}\\displaystyle\\sum_{i=1}^{m}S_i~ \\xrightarrow[m\\to \\infty]{c.s} ~\\mathbb{E}[S]=\\begin{array}{cc} \\text{La prima de } \\\\ \\text{riesgo según el } \\\\ \\text{modelo propuesto.}\\end{array} \\end{equation*}\\] Por lo que si nuestro modelo es incorrecto, esta relación no se da. Si estamos modelando de manera correcta, tiene sentido que, mientras el portafolio se mantenga homogéneo a medida que m crezca la información nueva sustente nuestra teoría. De lo contrario, aún consiguiendo \\(m\\) lo suficientemente grande, los datos no ajustarán el modelo. Por lo que nos interesa encontrar el valor de m tal que según nuestro modelo, \\(\\overline{S}\\) se encuentre “razonablemente” cercano a \\(\\mathbb{E}[S]\\). El que esto suceda es precisamente lo que le da credibilidad al modelo. Definición. Sean \\(k,~p\\) dos números fijos, se dice que \\(\\overline{S}\\) tiene Credibilidad completa (k,p) si: \\[\\begin{equation*} \\mathbb{P}\\left[ |\\overline{S}- \\mathbb{E}[S]|\\leq k\\mathbb{E}[S]\\right]\\geq p \\end{equation*}\\] Nota: En general se asume que \\(\\mathbb{E}[S]\\neq 0\\) por(espero) obvias razones. Así que para que lo dicho anteriormente tenga sentido, se toman valores para \\(k\\) cercanos a cero y \\(p\\) cercanos a uno. Así como se toma un nivel de significación \\(\\alpha=0.05\\), lo más usal es tomar \\(k=0.05\\), \\(p=0.90\\). 15.1.3 Credibilidad Completa Bajo Hipótesis de Normalidad Como usualmente es complicado obtener expresiones analíticas para las probabilidades de \\(S\\), acudiremos a las aproximaciones. Encontraremos la condición sobre el número de periodos de observación \\(m\\), para obtener credibilidad completa usando la distribución normal. Ejercicio: Arrastra el lápiz si no recuerdas que: \\[\\mathbb{E}[\\overline{S}]=\\mathbb{E}[S]~~~~~~~y~~~~~~~ Var(\\overline{S})= \\frac{1}{m}Var(S)\\] Tenemos que: \\[p\\le\\mathbb{P}\\left[ | \\overline{S} - \\mathbb{E}[S] | \\leq k\\mathbb{E}[S] \\right]=\\mathbb{P} \\left[ \\frac{| \\overline{S} - \\mathbb{E}[S] |}{\\sqrt{Var(\\overline{S})}} \\leq \\frac{k\\mathbb{E}[S]}{\\sqrt{Var(\\overline{S})}}\\right]\\] Llamando: \\[\\gamma=\\frac{k\\mathbb{E}[S]}{\\sqrt{Var(\\overline{S})}} \\] \\[\\underbrace{p\\leq \\mathbb{P}\\left[ -\\gamma \\leq \\frac{\\overline{S}-\\mathbb{E}[\\overline{S}]}{\\sqrt{Var(\\overline{S})}} \\leq \\gamma \\right]}_{Usando~ el ~valor ~absoluto ~anterior~ y~ que~ \\mathbb{E}[\\overline{S}]=\\mathbb{E}[S]}\\] \\[\\underbrace{\\thickapprox \\Phi(\\gamma) - \\Phi(-\\gamma)}_{\\text{usando ley de los grandes números}}\\] \\[\\begin{eqnarray*} \\Rightarrow &amp;=&amp; \\underbrace{ 2\\Phi(\\gamma)-1 }_{\\text{Por la simetría de la normal}~ \\Phi(-x)=1-\\Phi(x)}\\\\ &amp;=&amp; 2\\Phi\\left( \\frac{k\\mathbb{E}[S]}{\\sqrt{Var(S)}} \\right)-1 \\underbrace{ =2\\Phi\\left( \\frac{\\sqrt{m}k\\mathbb{E}[S]}{\\sqrt{Var(S)}}\\right)-1 }_{Var(\\overline{S})=\\frac{1}{m}Var(S)}\\\\ \\end{eqnarray*}\\] \\[\\therefore p\\leq 2\\Phi\\left( \\frac{k\\mathbb{E}[S]}{\\sqrt{Var(S)}} \\right)-1 =2\\Phi\\left( \\frac{\\sqrt{m}k\\mathbb{E}[S]}{\\sqrt{Var(S)}}\\right)-1\\] \\[\\Longleftrightarrow \\frac{p+1}{2}\\leq \\Phi\\left( \\frac{k\\mathbb{E}[S]}{\\sqrt{Var(S)}} \\right) =\\underbrace{\\Phi\\left( \\frac{\\sqrt{m}k\\mathbb{E}[S]}{\\sqrt{Var(S)}}\\right) }_{\\text{Las operaciones realizadas respetan la igualdad}}\\] Tomando \\(Z_x\\ddot{=}\\) cuantil del \\((\\alpha-100)\\%\\) de una \\(N(0,1)=\\Phi^{-1}(x)\\): \\[\\Longleftrightarrow Z_{(\\frac{p+1}{2})}\\leq \\left( \\frac{k\\mathbb{E}[S]}{\\sqrt{Var(S)}} \\right)\\\\=\\underbrace{\\left( \\frac{\\sqrt{m}k\\mathbb{E}[S]}{\\sqrt{Var(S)}}\\right)}_{Aplicando ~\\Phi^{-1} ~de~ ambos ~lados~ respeta~ la ~desigualdad ~pues~ \\Phi ~es ~creciente ~\\implies \\Phi^{-1}~lo~ es }\\] De esta última expresión obtenemos las dos siguientes: \\(Var(S)\\left[ \\frac{ Z_{(\\frac{p+1}{2})}}{k\\mathbb{E}[S]} \\right]^{2}\\lesssim m\\to\\) Esta es una manera de obtener la cantidad mínima de periodos \\(m\\) a partir del modelo \\(Var(\\overline{S})\\lesssim \\left[ \\frac{k\\mathbb{E}[S]}{Z_{(\\frac{p+1}{2})}} \\right]^2\\to\\) si \\(m=1\\) vemos una cota teórica para la varianza del riesgo \\(S\\). Nota: Recordar que \\(Var(\\overline{S})=\\frac{Var(S)}{m}\\). Nota: Como \\(m \\in \\mathbb{N}\\) si la cota inferior tiene decimales, la mínima \\(m\\) será el techo de la cota. En concreto, ¿cómo se realiza usando una muestra? Lo primero que debemos realizar es, dado nuestro modelo, calcularemos: \\[\\begin{equation*} \\underbrace{m_{min}\\ddot{=}\\left\\lceil \\frac{Var(S)}{\\mathbb{E}^2[S]} \\left[\\frac{Z_{(\\frac{p+1}{2})}}{k} \\right] \\right\\rceil^2}_{\\text{Este cálculo se hará con el modelo teórico que nosotros vamos a probar}} \\end{equation*}\\] Nota: Como usualmente \\(k=0.05\\) y \\(p=0.9\\Longrightarrow \\left[\\frac{Z_{(\\frac{p+1}{2})}}{k} \\right]^2\\thickapprox 1082.217\\) salvo que se especifiquen otros valores para \\((k,p)\\). Donde \\(\\lceil\\cdot\\rceil\\) es la función “parte entera mayor o igual” o simplemente conocida como “techo”. De tal manera que el modelo propuesto impone una cantidad de periodos necesaria para poder verificar credibilidad. Si \\(m\\) es la cantidad de datos disponibles una condición para poder verificar credibilidad completa (k,p)(Bajo hipótesis de normailidad) es: \\[\\begin{equation*} m_{min}\\leq m \\end{equation*}\\] Nota: Observando la definición de credibilidad completa y de \\(m_{min}\\) se vislumbra que cuando \\(k\\downarrow 0\\) o bien \\(p\\uparrow1\\) estamos siendo más estrictos con el modelo, y de hecho \\(m_{min}\\uparrow \\infty\\) lo que significa que necesitaremos más periodos. Recíprocamente cuando \\(k\\uparrow 1\\) o bien \\(p\\downarrow0\\) necesitamos menos periodos. De tal manera que si tenemos m datos, usando el modelo teórico \\(m_{min}\\) nos dirá si tenemos la cantidad suficiente de datos para verificar si nuestro modelo tiene credibilidad completa (k,p) o no. Ahora, con base en la teoría desarrollada por la SOA para el examen STAM, notemos que: \\[\\frac{Var(S)}{\\overline{S}\\mathbb{E}[S]}\\left[\\frac{Z_{(\\frac{p+1}{2})}}{k} \\right]^2\\thickapprox \\frac{Var(S)}{\\mathbb{E}[S]^2} \\left[\\frac{Z_{(\\frac{p+1}{2})}}{k} \\right]^2= Var(S)\\left[\\frac{Z_{(\\frac{p+1}{2})}}{k\\mathbb{E}[S]} \\right]^2 \\leq m\\] De aquí usaremos la muestra para verificar si se puede cumplir la credibilidad completa (k,p). Esto es: Si \\(m_{min}\\leq m\\) entonces nuestro modelo puede satisfacer credibilidad completa (k,p)(bajo hipótesis de normailidad) si: \\[\\begin{equation*} \\underbrace{\\frac{Var(S)}{\\mathbb{E}[S]} }_{Modelo~ teórico}\\underbrace{\\left[\\quad\\quad\\quad\\frac{Z_{(\\frac{p+1}{2})}}{k} \\right]^2}_{C.C.~(k,p)~normalidad } \\underbrace{\\quad\\quad\\quad\\leq m\\overline{S}= \\sum_{i=1}^mS_i}_{experiencia~de~los~siniestros} \\end{equation*}\\] Esto nos da otra condición que deberían satisfacer los datos si deseamos verificar la credibilidad completa (k,p). De tal manera que para poder si quiera preguntarnos si nuestros datos pueden satisfacer credibilidad completa (k,p) deberían satisfacerse las siguientes condiciones: \\(m_{min}\\leq m\\to\\) cantidad mínima de periodos requeridos SOA. \\(\\frac{Var(S)}{\\mathbb{E}[S]} \\left[\\frac{Z_{(\\frac{p+1}{2})}}{k}\\right]^2 \\leq \\sum_{i=1}^mS_i\\to\\) Monto total mínimo de reclamaciones experimentadas del riesgo SOA. \\(Var(\\overline{S})\\lesssim \\left[ \\frac{k\\mathbb{E}[S]}{Z_{(\\frac{p+1}{2})}} \\right]^2\\to\\) Cota superior de la volatilidad de la media de las reclamaciones experimentadas. Si no se satisfacen 2 y 3 son indicios de replantear el modelo. Más adelante hablamos de qué hacer si falla. Ahora estas condiciones las ponemos así porque estamos esperando que \\(\\overline{S}\\to \\mathbb{E}[S]\\) es decir que nuestros datos, en efecto, sean descritos por la teoría. Pero al final \\(\\overline{S}\\) se aproximará a su propia media. De tal manera que aún cumpliéndose las condiciones anteriores no significa que nuestro modelo explique los datos. Más bien de cumplirse aún falta verificar que en efecto nuestros datos explican el modelo mediante la definición de credibilidad completa (k,p) Podemos pensar que las condiciones anteriores son una puerta que necesito abrir para poder ver si mi modelo explica los datos. En resumen una vez satisfechas las condiciones hay que ver que en efecto \\(| \\overline{S}- \\mathbb{E}[S] | \\leq k\\mathbb{E}[S]\\) con probabilidad \\(\\geq p\\). Una posible verificación decisiva puede ser usando bootstrap para mostrar que se cumpla la definición de credibilidad completa (k,p). Lo ideal es primero verificar las condiciones y posteriormente esto. Equivalentemente decimos que \\(\\overline{S}\\) cumple credibilidad completa (k,p) bajo hipótesis de normalidad con nuestro modelo teórico. La idea es sencilla. Pensemos entonces que tenemos una muestra aleatoria \\(\\underline{S}_{m}= \\{S_{i}, S_{2},..., {S_m} \\}\\). Ahora, si esta muestra cumpliera la definición de credibilidad completa con (k, p) entonces: \\[\\begin{eqnarray*} \\mathbb{P} \\left[| \\overline{S}-\\mathbb{E}[S] | \\leq k \\quad \\mathbb{E}[S] \\right]&amp; \\geq p \\end{eqnarray*}\\] Lo que haremos es verificar que esto sucede en \\(n\\) ensayos realizados a partir de la primera muestra. Lo que haremos será muestrear con reemplazo de \\(\\underline{S}\\) y de cada una de estas muestras veremos si \\(| \\overline{S}-\\mathbb{E}[S] | \\leq k \\quad \\mathbb{E}[S]\\) o no. Es decir, tendremos \\(\\{ \\underline{ S }^{(i)}_m \\}_{i=1}^{n}\\) muestras con reemplazo de \\(\\underline{S}_m\\) y luego: \\[\\begin{eqnarray*} \\underline{ S }^{(1)} &amp;\\Rightarrow&amp; \\quad \\textit{Calculamos su promedio y lo llamamos} \\quad \\overline{ S }_{m}^{(1)}\\\\ \\underline{ S }^{(2)} &amp;\\Rightarrow&amp; \\quad \\textit{Calculamos su promedio y lo llamamos} \\quad \\overline{ S }_{m}^{(2)}\\\\ \\vdots \\\\ \\underline{ S }^{n} &amp;\\Rightarrow&amp; \\quad \\textit{Calculamos su promedio y lo llamamos} \\quad \\overline{ S }_{m}^{n}\\\\ \\end{eqnarray*}\\] Teniendo así, una muestra de tamaño \\(n\\) de \\(\\{\\underline{S}^{(i)}_m \\}_{i=1}^{n}\\) para cada una de estas estadísticas podemos calcular: \\(x_{i}= \\mathbb{I}\\{ | \\overline{S}_m-\\mathbb{E}[S] | \\leq k \\quad \\mathbb{E}[S]\\}\\) y entonces si \\(\\bar{x}=\\displaystyle\\frac{éxitos}{ensayos} \\geq p\\), tendremos que el modelo satisface c.c (k,p) por bootstrap. Cuando no hay credibilidad completa hay que replantear el modelo. Si \\({m_{mín}} &gt; m ( 1))\\) entonces podemos ver la siguiente alternativa. 15.1.4 Credibilidad Parcial Cuando no se obtiene credibilidad completa, por ejemplo cuando no tenemos la cantidad de periodos mínima para obtener este criterio obtenemos credibilidad parcial. Para esto, tomamos \\(\\alpha \\in (0,1]\\) y proponemos la combinación convexa del estimador de \\(\\mathbb{E}[S]\\): \\[\\begin{eqnarray*} \\alpha \\overline{S}+ (1- \\alpha) \\mathbb{E}[S] \\quad \\textit{con Factor de credibilidad}\\quad \\ddot{=} \\alpha \\in (0,1) \\end{eqnarray*}\\] Mediante esta expresión se le otorga credibilidad completa a una parte de la media muestral \\(\\overline{S}\\) y el complemento a \\(\\mathbb{E}[S]\\). Es decir: Definición: Sean k, p, \\(\\alpha \\in (0,1)\\) tres números fijos. Diremos que \\(\\overline{S}\\) tiene credibilidad parcial (k, p, \\(\\alpha\\)) si: \\[\\begin{eqnarray*} \\mathbb{P} \\left[| \\alpha \\overline{S}+(1- \\alpha)\\mathbb{E}[S] -\\mathbb{E}[S] | \\leq k \\quad \\mathbb{E}[S] \\right]&amp; \\geq p\\\\ \\end{eqnarray*}\\] Sin embargo, esta definición se vuelve irrelevante cuando se vislumbra que: \\[\\begin{eqnarray*} p&amp;\\leq&amp; \\mathbb{P} \\left[| \\alpha \\overline{S}+(1- \\alpha)\\mathbb{E}[S] -\\mathbb{E}[S] | \\leq k \\quad \\mathbb{E}[S] \\right]\\quad \\textit{¿Qué pasa si $\\alpha \\equiv 0$?}\\\\ &amp;=&amp; \\mathbb{P} \\left[\\alpha | \\overline{S}- \\mathbb{E}[S]| \\leq k \\quad \\mathbb{E}[S] \\right]\\\\ &amp;=&amp; \\mathbb{P} \\left[| \\overline{S}- \\mathbb{E}[S]| \\leq \\displaystyle\\frac{k}{\\alpha} \\quad \\mathbb{E}[S] \\right]\\\\ \\end{eqnarray*}\\] Por lo tanto: \\[\\begin{eqnarray*} p&amp;\\leq&amp; \\mathbb{P} [| \\alpha \\overline{S}+(1- \\alpha)\\mathbb{E}[S] -\\mathbb{E}[S] | \\leq k \\quad \\mathbb{E}[S]]\\\\ &amp;=&amp; \\mathbb{P} [| \\overline{S}- \\mathbb{E}[S]| \\leq \\displaystyle\\frac{k}{\\alpha} \\quad \\mathbb{E}[S]]\\\\ \\end{eqnarray*}\\] Es decir: Credibilidad parcial (k, p, \\(\\alpha\\)) \\(\\Leftrightarrow\\) credibilidad completa \\(\\left(\\displaystyle\\frac{k}{\\alpha}, p\\right)\\). Como \\(\\alpha\\in(0,1] \\Rightarrow \\dfrac{k}{\\alpha}\\geq k\\) y esto permite un rango de error mayor con credibilidad parcial que con credibilidad completa con la misma (k, p). 15.1.5 Credibilidad Parcial bajo Hipótesis de Normalidad Como ya vimos, credibilidad parcial no es más que tomar credibilidad total pero modificando una de sus componentes. Por lo que bajo el supuesto de normalidad asintótica, para credibilidad parcial tenemos que: \\[\\begin{equation*} Var(S) = \\left[ \\displaystyle\\frac{ z_{\\left(\\frac{p+1}{2}\\right)} }{\\displaystyle\\frac{k}{\\alpha}\\mathbb{E}[S]} \\right]^{2} \\lesssim m \\quad ; \\quad Var(\\overline{S}) \\lesssim \\left[ \\displaystyle\\frac{\\displaystyle\\frac{k}{\\alpha}\\mathbb{E}[S] }{z_{\\left(\\frac{p+1}{2}\\right)}} \\right]^{2} \\end{equation*}\\] Nota: Observemos que el Factor de credibilidad justo hace menos estricta la condición de credibilidad completa. Las interpretaciones son idénticas al caso que ya vimos con credibilidad total. El punto interesante aquí es que si el tamaño de muestra (m) NO fuese suficientemente grande pero fijo y conocido, entonces podemos calcular el Factor de credibilidad de la información que tenemos y el modelo propuesto como: \\[\\begin{equation*} \\alpha= \\left[ \\displaystyle\\frac{k \\cdot \\mathbb{E}[S] \\displaystyle\\sqrt{m} }{z_{\\left(\\frac{p+1}{2}\\right)} \\displaystyle\\sqrt{Var(S)}} \\right]= \\left[ \\displaystyle\\frac{k \\cdot \\mathbb{E}[S] }{z_{\\left(\\frac{p+1}{2}\\right)} \\displaystyle\\sqrt{Var(\\overline{S})}} \\right] \\end{equation*}\\] Nota: Si m es lo suficientemente grande \\(\\Rightarrow\\) \\(\\alpha\\) puede ser mayor a uno. Esto pues precisamente va alcanzando credibilidad completa. Con la finalidad de dar una versión generalizada del Factor de credibilidad tenemos que: \\[\\begin{eqnarray*} \\alpha&amp;=&amp; mín \\left \\{ \\underbrace{{\\displaystyle\\frac{k \\cdot \\mathbb{E}[S] \\displaystyle\\sqrt{m} }{z_{\\left(\\frac{p+1}{2}\\right)} \\displaystyle\\sqrt{Var(S)}}}}_\\textit{Usaremos este} = \\displaystyle\\frac{k \\cdot \\mathbb{E}[S] }{z_{\\left(\\frac{p+1}{2}\\right)} \\displaystyle\\sqrt{Var(\\overline{S})}},1 \\right \\} \\end{eqnarray*}\\] De aqui notamos que: \\[\\begin{equation*} \\displaystyle\\frac{k \\cdot \\mathbb{E}[S] \\displaystyle\\sqrt{m} }{z_{\\left(\\frac{p+1}{2}\\right)} \\displaystyle\\sqrt{Var(S)}} =\\displaystyle\\frac{ \\displaystyle\\sqrt{m} }{ \\displaystyle\\frac{z_{\\left(\\frac{p+1}{2}\\right)} \\displaystyle\\sqrt{Var(S)}}{k \\cdot \\mathbb{E}[S]}} = \\displaystyle\\sqrt{\\displaystyle\\frac{ m }{ \\displaystyle\\frac{Var(S)}{\\mathbb{E}^{2}[S]} \\left[ \\displaystyle\\frac{z_{\\left(\\frac{p+1}{2}\\right)}}{k} \\right]^{2}}} \\end{equation*}\\] Con base en la teoría desarrollada por la SAA para el examen STAM, tendremos entonces lo siguiente: Dependiendo de la cantidad de información que se tenga, el número anterior se calcula de la siguiente manera: \\[\\begin{eqnarray*} \\displaystyle\\sqrt{\\displaystyle\\frac{ m }{ \\displaystyle\\frac{Var(S)}{\\mathbb{E}^{2}[S]} \\left[ \\displaystyle\\frac{z_{\\left(\\frac{p+1}{2}\\right)}}{k} \\right]^{2}}}&amp;\\approx&amp; \\displaystyle\\sqrt{\\displaystyle\\frac{ m\\cdot \\overline{S} }{ \\displaystyle\\frac{Var(S)}{\\mathbb{E}[S]} \\left[ \\displaystyle\\frac{z_{\\left(\\frac{p+1}{2}\\right)}}{k} \\right]^{2}}} \\end{eqnarray*}\\] Nota: En esta expresión el numerador se calcula con la muestra y el denominador con el modelo teórico. Nota: Si no se tiene muestra, de hecho no tiene sentido invocar credibilidad. Sin embargo en ejercicios 100% teóricos donde se solicita el cálculo del Factor de credibilidad pero no se da una muestra, se debe tomar \\(\\alpha=1\\). Ahora, existen diversas propuestas de diferentes autores de cómo estimar/obtener el Factor de credibilidad; Nosotros nos centraremos en la metodología prouesta por la SOA. Usando la teoría desarrollada por la SOA tenemos que: Para invocar credibilidad parcial (k, p, \\(\\alpha\\)) (Bajo el supuesto de normalidad), el cálculo del Factor de credibilidad se hace de la siguiente manera: \\[\\begin{eqnarray*} \\alpha&amp;=&amp; mín \\left \\{ \\displaystyle\\frac{\\textit{&quot;Información disponible&quot;}}{\\textit{&quot;Información necesaria para credibilidad completa&quot;}}\\right\\} \\end{eqnarray*}\\] Donde: \\(\\textrm{&quot;Información disponible&quot;}\\). Es el numerador de las expresiones anteriores y se obtiene dependiendo de la muestra dada (o bien si no se cuenta con muestra, se hace teórica). \\(\\textrm{&quot;Información necesaria para credibilidad completa&quot;}\\). Es el denominador de las expresiones anteriores y se obtiene con el modelo propuesto. Las cosas pueden ponerse más interesantes dependiendo si \\(S\\) es un modelo colectivo, algunos de los cálculos con los que se verifican o se obtienen ciertos factores tanto para credibilidad completa o parcial se modifican dependiendo de la \\(\\textrm{&quot;Información disponible&quot;}\\). Esto se hace con la finalidad de explotar los datos y la experiencia obtenida de la muestra de la forma más adecuada posible. Aunque de momento, vamos a tratar la credibilidad como hasta este punto. 15.1.6 Ajuste de primas con credibilidad clásica Finalmente llegamos al objetivo principal de esta sección; recordemos que la finalidad de la teoría de la credibilidad es dar verosimilitud al modelo que estamos proponiendo con base en el histórico que tenemos. En el caso en el que nuestro modelo cumpla credibilidad completa, como su nombre lo indica, nuestro modelo funciona correctamente a los niveles (k, p), por lo que no es necesario hacer un ajuste al modelo de prima de riesgo. Sin embargo, se acostumbra dar más peso a la información recolectada y con base en esto tener la nueva prima. Esto significa: \\[\\begin{equation*} \\text{credibilidad completa } (k, p) \\Rightarrow \\text{Prima de riesgo ajustada } \\ddot{=} \\overline{S} \\underbrace{\\approx}_{(k, p)} \\mathbb{E}[S]. \\end{equation*}\\] Nota: Recuerda que buscamos \\(k \\approx 0\\) y \\(p \\approx 1\\). Sin ser exactamente iguales. Por otro lado, en el caso en que tengamos credibilidad parcial \\((k, p, \\alpha)\\), entonces realizamos un ajuste a la prima y de hecho podemos considerar modificar el modelo propuesto, si \\(\\alpha \\approx0\\) o si el número de periodos con los que contamos es aún muy pequeño con respecto a la cota inferior de m. El ajuste de la prima en este caso será: \\[\\begin{equation*} \\text{credibilidad parcial } (k, p, \\alpha) \\Rightarrow \\text{Prima de riesgo ajustada } \\ddot{=} \\alpha \\overline{S}+(1-\\alpha)\\mathbb{E}[S] \\underbrace{\\approx}_{(k, p, \\alpha)}\\mathbb{E}[S]. \\end{equation*}\\] Nota: No queremos que \\(\\alpha \\approx 0\\) pues hacemos que el modelo ajuste a los datos no a sí mismo. 15.2 Enfoque bayesiano En estadística tradicional, enfoque clásico, uno de los problemas inferenciales más importantes es la estimación del parámetro \\(\\theta\\), de una distribución de probabilidad \\(f(x; \\theta)\\). Para realizar dicha estimación seleccionamos una muestra aleatoria de esta distribución y se tienen distintos métodos para estimar \\(\\theta\\), considerando siempre que este parámetro tiene un valor desconocido y fijo. En el enfoque Bayesiano, \\(\\theta\\) se trata como una variable aleatoria para la que se supone una distribución de probabilidad \\(p(\\theta)\\), llama distribución inicial o distribución a priori. Esta distribución refleja la información subjetiva o cuantitativa que el observador pueda tener sobre este parámetro \\(\\theta\\), antes de observar la muestra. Actualización de la información a través del teorema de Bayes La forma en la que se actualiza la información inicial sobre nuestro parámetros de interpes \\(\\theta\\), mediante la información contenida en la muestra \\(p(x|\\theta)=L(\\theta, \\underline{X})\\) (la verosimilitud), es a través del teorema de Bayes. 15.3 Teorema de Bayes Teorema de Bayes Dados dos eventos A y B tales que \\(\\mathbb{P}(B)&gt;0\\), la probabilidad condicional de A dado B, \\(\\mathbb{P}(A|B)\\), se define como: \\[\\begin{eqnarray*} \\mathbb{P}(A|B)&amp;=&amp; \\displaystyle\\frac{\\mathbb{P} (B\\cap A) }{\\mathbb{P}(B)}\\\\ &amp;=&amp; \\displaystyle\\frac{\\mathbb{P}(B|A)\\mathbb{P}(A)}{\\mathbb{P}(B)}\\\\ \\end{eqnarray*}\\] Teorema de Bayes Si \\(\\{ A_{i}: i=1,2,...,M\\}\\) en un conjunto de eventos mutuamente excluyentes, entonces: \\[\\begin{eqnarray*} \\mathbb{P}(A_{i}|B)&amp;=&amp; \\displaystyle\\frac{\\mathbb{P}(B|A_i)\\mathbb{P}(A_i)}{\\displaystyle\\sum_{j=1}^{M} \\mathbb{P}(B|A_{j}) \\mathbb{P}(A_{j})}\\\\ \\end{eqnarray*}\\] La forma esquemática de actualizar esta información a través del teorema de Bayes es la siguiente: \\(1.\\) \\(\\theta\\) debe tener una distribución de probabilidad \\(p(\\theta)\\), que refleje nuestro conocimiento inicial acerca de su valor. \\(2.\\) La información sobre \\(\\theta\\) que contiene la muestra aleatoria seleccionada, está resumida en la verosimilitud \\(p(x|\\theta)=L(\\theta; \\underline{X})\\). Por lo tanto, nuestro conocimiento acerca del valor \\(\\theta\\) queda descrito a través de su distribución final. El teorema de Bayes nos dice cómo encontrarla: \\[\\begin{eqnarray*} {p(\\theta| \\underline{X})= \\displaystyle\\frac{p(x|\\theta)p(\\theta)}{\\displaystyle\\int p(x|\\theta)p(\\theta) d\\theta}} \\end{eqnarray*}\\] Este proceso se conoce como el proceso de actualización de la información sobre \\(\\theta\\) ,y es la manera de combinar las dos fuentes de información que tenemos. La inicial dada a través de \\(p(\\theta)\\), y la de la muestra, dada por medio de la verosimilitud \\(p(x|\\theta)\\), para obtener la distribución final \\(p(\\theta; \\underline{X})\\), que contiene la suma de estas dos fuentes de información. Obsérvese que el denominador, \\(p(x)=\\displaystyle\\int p(x|\\theta)p(\\theta) d\\theta\\) no depende de \\(\\theta\\), por lo que es común escribir esta distribución final como: \\[\\begin{eqnarray*} p(\\theta| \\underline{X})&amp;\\propto &amp; p(x|\\theta)p(\\theta)\\\\ \\end{eqnarray*}\\] En la práctica, el cálculo de la distribución final puede ser un asunto complicado, especialmente si la dimensión del parámetro es grande. Sin embargo, para ciertas combinaciones de distribuciones iniciales y verosimilitudes es posible simplificar el análisis. En otros casos se requieren aproximaciones analíticas y/o técnicas computacionales relativamente sofisticadas. Como hemos visto, la prima de riesgo puede cambiar según el comportamiento de la muestra y que a medida que tuviéramos más información, se nos indica que el modelo va en dirección correcta. Todo esto es algo que nos hace pensar en estadística bayesiana, por lo que veremos un pequeño repaso de cómo hacer estimaciones con este tipo de estadística. Comencemos dejando claro un poco la notación en términos probabilísticos. Supongamos que \\(X_1, X_2,...,X_n \\sim Algo (\\Theta)\\) (\\(\\Theta\\) podría ser un vector de parámetros). \\(\\Theta \\sim Algo_{2} (\\Delta)\\), donde \\(\\Delta\\) asumimos totalmente conocido (propuesto). Verosimilitud \\[\\begin{eqnarray*} p(\\underline{x} | \\Theta) &amp; \\ddot{=}&amp; f_{x_1, x_2,...,x_n}(x_1, x_2,...,x_n) \\end{eqnarray*}\\] Es la función de densidad conjunta de la muestra, cuya distribución depende del parámetro de interés \\(\\Theta\\). Distribución inicial (a priori) \\[\\begin{eqnarray*} p(\\theta)&amp; \\ddot{=}&amp; f_{\\Theta} (\\theta) \\end{eqnarray*}\\] Es la función de densidad del parámetro de interés, crecordando que este se piensa como v.a Distribución final (a posteriori) \\[\\begin{eqnarray*} p(\\theta|\\underline{x})&amp; \\ddot{=}&amp; f_{\\Theta|\\underline{X}=\\underline{x}} (\\theta) \\end{eqnarray*}\\] Es la función de densidad que depende únicamente de \\(\\theta\\). Tomando en cuenta valores ya observados y fijos de la muestra. El siguiente resultado NO viene directamente del teorema de Bayes, ya que aunque es muy común usar la notación ” \\(p(\\theta)\\) “, esto no necesariamente es probabilidad, pues de hecho es una función de densidad. Del Teorema de Bayes se puede encontrar que: \\[\\begin{equation*} p(\\theta| \\underline{X})= \\displaystyle\\frac{p(x|\\theta)p(\\theta)}{\\displaystyle\\int_{\\Omega_{\\Theta}} p(x|\\theta)p(\\theta) d\\theta} \\propto p(x|\\theta)p(\\theta) \\end{equation*}\\] Donde {\\(\\propto\\) Kernel de la v.a \\(\\Theta|\\underline{X}\\)} La razón de porque \\(p(\\theta|\\underline{X}) \\propto p(x|\\theta)p(\\theta)\\) es porque \\(\\displaystyle\\int_{\\Omega_{\\Theta}} p(x|\\theta)p(\\theta) d\\theta\\) no depende de \\(\\theta\\) (Se integran) y quedan simplemente constantes para \\(\\theta\\) , como lo son \\(\\underline{X}\\) y \\(\\Delta\\). Nota: En general se asume una muestra aleatoria en \\(\\underline{X}\\) entonces la independencia queda implícita. Así: \\(p(\\underline{x| \\theta})= \\prod_{i=1}^{n}p(x_i|\\theta)\\)}. \\(Definición:\\) Dada una distribución final y una muestra fija, decimos que estimador bayesiano para \\(\\Theta\\) es: \\[\\begin{equation*} \\widehat{\\Theta}\\ddot{=} \\mathbb{E}[\\Theta| \\underline{X}= \\underline{x}]=\\displaystyle\\int_{\\Omega_{\\Theta}} \\theta p(\\theta| \\underline{x}) d\\theta \\end{equation*}\\] Nota: “Muestra fija” es la clave, ya que de otro modo \\(\\widehat{\\Theta}\\) sería v.a. Ejemplo: Suponga \\(\\{X_i \\}_{i=1}^{n}\\) una muestra aleatoria con distribución Bernoulli(\\(\\Theta\\)) y consideremos \\(\\Theta \\sim Beta(\\Delta=(a,b))\\) entonces: \\[\\begin{equation*} p(\\theta)= \\displaystyle\\frac{1}{\\beta(a,b)} \\theta^{a-1} (1-\\theta)^{b-1} \\quad ; \\quad \\mathbb{E}[\\Theta]= \\displaystyle\\frac{a}{b+a} \\quad \\quad ;\\beta(a,b) \\ddot{=} \\displaystyle\\frac{\\Gamma(a \\Gamma(b))}{\\Gamma(a+b)} \\end{equation*}\\] \\[\\begin{eqnarray*} p(x_i|\\theta)p(\\theta)&amp;=&amp; \\theta^{x_i} (1-\\theta)^{1-x_i}\\mathbb{I}_{\\{ 0,1\\}} (x_{i}) \\quad \\quad \\text{Noten que está bien definido pues $\\theta \\in (0,1)$} \\end{eqnarray*}\\] Kernel \\[\\begin{eqnarray*} p(\\underline{x}|\\theta)p(\\theta) &amp;=&amp; \\displaystyle\\prod_{i=1}^{n} p(x_i| \\theta) p(\\theta)\\\\ &amp;=&amp; \\displaystyle\\prod_{i=1}^{n} \\theta^{x_i} (1-\\theta)^{1-x_i} \\displaystyle\\frac{1}{\\beta(a,b)} \\theta^{a-1} (1-\\theta)^{b-1}\\\\ &amp;=&amp; \\displaystyle\\frac{1}{\\beta(a,b)} \\theta^{n \\bar{x}+a-1} (1-\\theta)^{n(1- \\bar{x})+b-1}\\\\ &amp;\\propto&amp; {\\underbrace{{\\theta^{n \\bar{x}+a} (1-\\theta)^{n(1- \\bar{x})+b}}}_{\\text{Un kernel conocido}}} \\end{eqnarray*}\\] Por lo tanto Como \\(p(\\theta| \\underline{x}) \\propto p(\\underline{x}|\\theta)p(\\theta)\\) entonces \\(\\Theta| \\underline{X}=\\underline{x} \\sim Beta(n \\bar{x}+a-1, n(1- \\bar{x})+b-1)\\) Sin embargo, es común que la gente sea escéptica a “mandar a la … constante de integración” las cosas. Entonces, sin tomar proporciones, tenemos: Kernel \\(P(\\underline{x}|\\theta)P(\\theta)=\\displaystyle\\frac{1}{\\beta(a,b)}\\theta^{n\\overline{x}+a-1}(1-\\theta)^{n(1-\\overline{x})+b-1}\\) Constante de integración \\[\\displaystyle\\int_{\\Omega_{\\Theta}}P(\\underline{x}|\\theta)P(\\theta)d\\theta\\] \\(=\\displaystyle\\int_0^1\\frac{1}{\\beta(a,b)}\\theta^{n\\overline{x}+a-1}(1-\\theta)^{n(1-\\overline{x})+b-1}d\\theta\\) \\(=\\displaystyle\\frac{1}{\\beta(a,b)}{\\beta(a+n\\overline{x},b(1-\\overline{x}+b))}{\\underbrace{{\\displaystyle\\int_0^1{1}{{\\frac{1}{\\beta(a+n\\overline{x},n(1-\\overline{x})+b)}}\\theta^{n\\overline{x}+a-1}(1-\\theta)^{n(1-\\overline{x})+b-1}}d\\theta}}_{\\mbox{Una densidad Beta sobre todo su soporte}}}\\) \\(=\\displaystyle\\frac{1}{\\beta(a,b)}{\\beta(a+n\\overline{x},n(1-\\overline{x})+b)}\\) \\[\\begin{eqnarray*} \\therefore P(\\theta|\\underline{x})&amp;=&amp;\\displaystyle\\frac{P(\\underline{x}|\\theta)P(\\theta)}{\\displaystyle\\int_{\\Omega_{\\Theta}}P(\\underline{x}|\\theta)P(\\theta)d\\theta}\\\\ &amp;=&amp;\\displaystyle\\frac{{\\frac{1}{\\beta(a,b)}}\\theta^{n\\overline{x}+a-1}(1-\\theta)^{n(1-\\overline{x})+b-1}}{{\\frac{1}{\\beta(a,b)}}{\\beta(a+n\\overline{x},n(1-\\overline{x})+b)}}\\\\ &amp;=&amp;\\displaystyle\\frac{1}{\\beta(a+n\\overline{x},n(1-\\overline{x})+b)}\\theta^{n\\overline{x}+a-1}(1-\\theta)^{n(1-\\overline{x})+b-1}\\\\ \\end{eqnarray*}\\] \\(\\therefore\\Theta|\\underline{X}=\\underline{x}\\sim Beta(b\\overline{x}+a,n(1-\\overline{x})+b)\\),también haciendo más cuentas. \\(\\Rightarrow \\widehat{\\Theta}={E}[\\Theta| \\underline{X}=\\underline{x}]=\\displaystyle\\frac{n\\overline{x}+a}{(n\\overline{x}+a)+(n(1-\\overline{x})+b)}=\\frac{n\\overline{x}+a}{n+a+b}\\) En este caso, la distribución final tuvo una distribución conocida, sin embargo, esto no sucede necesariamente. Afortunadamente, existen distribuciones que si las utilizamos para la verosimilitud y la inicial,tendremos una final conocida. Esto se conoce como familias conjugadas. 15.4 Familias conjugadas Comentamos en uno de los puntos anteriores, que existen cierta combinaciones de distribuciones y verosimilitudes, que simplifican el análisis Bayesiano, esencialmente, porque el modelo de la distribución final de \\(\\theta\\), pertenece a la misma familia que el de la inicial. \\(Definición.\\) Sea {\\(\\mathscr{P}\\)}=\\(\\{p(x|\\theta):\\theta\\in\\Theta\\}\\) una familia paramétrica. Una clase (o colección) de distribuciones de probabilidad \\(\\mathscr{F}\\) es una familia conjugada para \\(\\mathscr{P}\\) si para toda \\(p(x|\\theta)\\in\\mathscr{P}\\) y \\(p(\\theta)\\in\\mathscr{F}\\) se tiene que \\(p(\\theta |x)\\in \\mathscr{F}\\) Algunos modelos paramétricos univariados con sus respectivas familias conjugadas: Ejemplo: Consideremos la familia paramétrica \\(\\mathscr{P}=\\{\\mbox{Poisson}(x|\\lambda):\\lambda\\in{P}^+\\}\\). Si utilizamos como distribución inicial \\(p(\\lambda)\\in\\mathscr{F}=\\{\\mbox{Gamma}(\\lambda|\\alpha,\\beta):\\alpha,\\beta\\in{R}^+\\}\\)}. Entonces, si se tiene una muestra aleatoria \\(\\mbox{x}=(x_1,...,x_n)\\), la distribución final es \\[{ p(\\lambda|\\underline{X})=\\mbox{Gamma}(\\lambda|\\alpha+r,n+\\beta) }\\qquad \\mbox{con } r =\\displaystyle\\sum_{i=1}^n x_i\\] Demostración. Solo demostraremos que el kernel de la distribución final, pertenece a la distribución \\(Gamma(\\lambda|\\alpha+r,n+\\beta)\\). Sabemos, por Bayes, que \\[p(\\lambda|\\underline{X})=\\displaystyle\\frac{{p(x|\\lambda)p(\\lambda)}}{\\displaystyle\\int p(x|\\lambda)p(\\lambda)d\\lambda}\\] con \\(p(x|\\lambda)\\) =\\(\\displaystyle\\prod_{i=1}^n\\displaystyle\\frac{\\lambda^{x_i}e^{-\\lambda}}{x_i!}\\varpropto \\lambda^{\\displaystyle\\sum_{i=1}^nx_i}e^{-n\\lambda}\\) y \\(p(\\lambda)\\)=\\(\\displaystyle\\frac{\\beta^\\alpha\\lambda^{\\alpha-1}e^{-\\beta\\lambda}}{\\Gamma(\\alpha)}\\), por lo que \\(p(\\lambda|\\underline{X})\\varpropto\\)\\(\\lambda^{\\displaystyle\\sum_{i=1}^nx_i}e^{-n\\lambda}\\lambda^{\\alpha-1}e^{-\\beta\\lambda}=\\lambda^{\\alpha+\\displaystyle\\sum_{i=1}^n x_i-1}e^{-\\lambda(\\beta+n)}\\varpropto Gamma\\left(\\alpha+\\displaystyle\\sum_{i=1}^n x_i,\\beta+n\\right)\\) 15.5 Cálculo Bayesiano de primas de seguros El uso de las distribuciones iniciales que tienen un carácter evidentemente subjetivo, resulta de utilidad en el mercado de seguros, sobre todo si se tiene en cuenta que cuando se quiere tarifar un riesgo nuevo no se dispone de información para ello. La visión Bayesiana se incorporó rápidamente a la disciplina actuarial, demostrando que algunas primas que se obtienen a través de la metodología Bayesiana pueden escribirse como fórmulas de credibilidad. En estos términos actuariales, la cuestión básica de credibilidad es determinar una prima establecida como una combinación lineal convexa entre la experiencia particular de un asegurado y la experiencia del colectivo,esto es, toda la cartera. Es decir \\[\\mathbb{P}_j=Z\\hat{\\mathbb{P}}+(1-Z){P}_0\\] \\(\\bullet\\) \\(\\mathbb{P}_j\\) prima a aplicar a los asegurados por el riesgo \\(j\\). (final-posterior) \\(\\bullet\\) \\(\\mathbb{P}_0\\) prima a aplicar a un colectivo al que pertenece el asegurado \\(j\\). (inicial-propuesta) \\(\\bullet\\) \\(\\hat{\\mathbb{P}}\\) Prima calculada con base en la experiencia del asegurado \\(j\\). (muestral) \\(\\bullet\\) \\(Z\\) Factor de credibilidad Que debe verificar las condiciones: \\(\\lim\\limits_{m\\rightarrow\\infty}Z=1\\), con \\(m\\) el número de sujetos expuestos al riesgo \\(j\\) o el periodo de observación de la póliza \\(j\\). Entonces,si \\(Z=1\\) la experiencia del asegurados recibe credibilidad total o del 100%, mientras que si \\(Z=0,\\mathbb{P}_j=\\mathbb{P}_0\\) y la prima del asegurado \\(j\\) coincide con la del colectivo} a la que pertenece dicha póliza, o la experiencia del colectivo recibe credibilidad total o del 100% Entonces, desde el punto de vista Bayesiano, esta fórmula de credibilidad puede interpretarse como: Podemos considerar \\(\\mathbb{P}_0\\) como la información inicial o A \\(\\mathbb{P}_0\\) como la nueva información que se obtiene mediante la observación de la siniestralidad del riesgo \\(j\\) (los datos recabados; la información recabada) y \\(\\mathbb{P}_j\\) la actualización del cálculo de la póliza (prima a posteriori), resultado de combinar la información inicial con la información recabada. Por lo tanto Prima (a posteriori) =\\((1-Z)\\ast\\) Prima a priori+ \\(Z\\ast\\) Experiencia dada por los datos; De esta manera, la teoría de la credibilidad Bayesiana, sigue un esquema donde la información a priori sobre el cálculo de las primas, se actualiza con la información dada por la observación del siniestro (muestra), dando como resultado la actualización de la prima, mediante el cálculo de la prima a posteriori. ¿Cómo modelar un riesgo para obtener una prima de credibilidad Bayesiana? Ahora aplicaremos estas ideas al problema del cálculo de primas tomando en cuenta la experiencia de un riesgo. Suponga que las variables \\(S_1,...,S_m\\) representan el historial de reclamaciones en \\(m\\) años o periodos que se han registrado de un riesgo dado. Suponga además que estas variables son independientes y todas ellas tienen una distribución común dependiente de un parámetro desconocido \\(\\theta\\), y esta distribución es tal que \\(E(S)=\\theta\\). Bajo el enfoque Bayesiano se considera que el parámetro \\(\\theta\\) es una variable aleatoria para la cual se asume una distribución de probabilidad a priori. La esperanza a porteriori de \\(\\theta\\), es decir, \\(E(\\theta|S_1,...,S_m)\\), representa una estimación para \\(E(S)=\\theta\\) tomando en cuenta el historial \\(S_1,...,S_m\\). A esta esperanza posteriori se le llama prima de credibilidad Bayesiana. En los casos que analizaremos esta prima tiene la forma de la credibilidad parcial mencionada antes. Los casos que consideraremos para la distribución de \\(S\\) son: la distribución Poisson con media \\(\\lambda\\), y la distribución normal con media \\(\\theta\\). \\(\\blacksquare\\) Modelo Poisson-Gamma Este modelo adquiere su nombre a partir de las siguientes hipótesis: se postula que cada una de las variables aleatorias independientes \\(S_1,...,S_m\\) tiene distribución Poisson con parámetro \\(\\lambda\\), el cual se considera aleatorio con una distribución a priori gamma\\((\\gamma,\\alpha)\\),con \\(\\gamma\\mbox{ y }\\alpha\\) parámetros conocidos. Observe que en este modelo se considera que los montos de las reclamaciones toman valores enteros. La función de densidad a posteriori de \\(\\lambda\\) es, para \\(x&gt;0\\), \\[\\begin{eqnarray*} g(\\lambda|S_1,...,S_m)&amp;=&amp;\\displaystyle\\frac{f(S_1,...,S_m|\\lambda)h(\\lambda)}{\\displaystyle\\int_0^\\infty f(S_1,...,S_m|\\lambda)h(\\lambda)d\\lambda}\\\\ &amp;=&amp;\\displaystyle\\frac{\\displaystyle\\prod_{j=1}^m\\left(\\frac{\\lambda^{S_j}}{S_j!}e^{-\\lambda}\\right)\\frac{\\alpha^\\gamma}{\\Gamma(\\gamma)}\\lambda^{\\gamma-1}e^{-\\alpha\\lambda}}{\\displaystyle\\int_0^\\infty\\displaystyle\\prod_{j=1}^m\\left(\\frac{\\lambda^{S_j}}{S_j!}\\right)\\frac{\\alpha^\\gamma}{\\Gamma(\\gamma)}\\lambda^{\\gamma-1}e^{-\\alpha\\lambda}d\\lambda}\\\\ &amp;=&amp;\\displaystyle\\frac{\\lambda^{m\\overline{S}+\\gamma-1}e^{-(m+\\alpha)\\lambda}}{\\displaystyle\\int_0^\\infty \\lambda^{m\\overline{S}+\\gamma-1}e^{-(m+\\alpha)\\lambda}d\\lambda}\\\\ &amp;=&amp; \\displaystyle\\frac{(m+\\alpha)^{m\\overline{S}+\\gamma}}{\\Gamma(m\\overline{S}+\\gamma)}\\lambda^{m\\overline{S}+\\gamma-1}e^{-(m+\\alpha)\\lambda}. \\end{eqnarray*}\\] Es decir, la densidad a posteriori es gamma(\\(m\\overline{S}+\\gamma,m+\\alpha\\)).Por lo tanto, la prima por credibilidad, esperanza de esta densidad, es \\[\\begin{eqnarray*} {\\text{prima}}&amp;=&amp; E(\\lambda|S_1,...,S_m)\\\\ &amp;=&amp;\\displaystyle\\frac{m\\overline{S}+\\gamma}{m+\\alpha}\\\\ &amp;=&amp; \\displaystyle\\frac{m}{m+\\alpha}\\overline{S}+\\displaystyle\\frac{\\alpha}{m+\\alpha}\\displaystyle\\frac{\\gamma}{\\alpha}\\\\ &amp;=&amp;{z\\overline{S}+(1-z)\\displaystyle\\frac{\\gamma}{\\alpha}}, \\end{eqnarray*}\\] en donde \\(z=\\frac{m}{(m+\\alpha)}\\) es llamado factor de credibilidad. Esta cantidad crece monótonamente a uno cuando \\(m\\) crece a infinito, dando cada vez más credibilidad a la media muestral \\(\\overline{S}\\) y favoreciendo cada vez menos a la media teórica \\(\\frac{\\gamma}{\\alpha}\\). Observe además que cuando \\(m\\) crece a infinito, la media de la distribución a posteriori converge a la media muestral límite dado por el historial de reclamaciones, y que la varianza de \\(\\lambda\\) dada por \\(Var(\\lambda|\\underline{S}) =\\frac{(m\\overline{S}+\\gamma)}{(m+\\alpha)^2}\\) converge a cero, lo cual indica que la distribución posteriori se concentra cada vez más alrededor de su media. \\(\\blacksquare\\) Modelo Normal-Normal En este modelo se postula que cada una de las reclamaciones \\(S_1,...,S_m\\) tiene distribución \\(N(\\theta,\\sigma^2)\\), en donde el parámetro \\(\\sigma^2\\) es conocido y la media \\(\\theta\\) es una variable aleatoria con distribución \\(N(\\mu,\\eta)\\), con \\(\\mu\\mbox{ y }\\eta^2\\) conocidos. La primera hipótesis puede ser justificada en el caso cuando los montos anuales se componen de un gran número de reclamaciones individuales, para ello no es necesario suponer que las reclamaciones individuales tienen la misma distribución. La segunda hipótesis podría ser razonable si es que los parámetros \\(\\mu\\mbox{ y }\\eta^2\\) son tales que la probabilidad asignada a la parte negativa del eje es muy pequeña.La función de densidad a posteriori de \\(\\theta\\) es \\[\\begin{eqnarray*} g(\\theta|S_1,...,S_m)&amp;=&amp; \\displaystyle\\frac{f(S_1,...,S_m|\\theta)h(\\theta)}{\\displaystyle\\int_{-\\infty}^\\infty f(S_1,...,S_m|\\theta)h(\\theta)\\theta d\\theta}\\\\ &amp;=&amp; \\displaystyle\\frac{\\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\sum_{j=1}^m(S_j-\\theta)^2/2\\sigma^2}\\frac{1}{\\sqrt{2\\pi\\eta^2}}e^{-(\\theta-\\mu)^2/2\\eta^2}}{\\displaystyle\\int_{-\\infty}^\\infty \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\sum_{j=1}^m(S_j-\\theta)^2/2\\sigma^2}\\frac{1}{\\sqrt{2\\pi\\eta^2}}e^{-(\\theta-\\mu)^2/2\\eta^2}d\\theta}\\\\ \\end{eqnarray*}\\] Nos concentramos en analizar únicamente el exponente y tenemos que \\[-\\displaystyle\\sum_{j=1}^m\\displaystyle\\frac{(S_j-\\theta)^2}{2\\sigma^2}-\\displaystyle\\frac{(\\theta-\\mu)^2}{2\\eta^2}=-\\theta^2\\left(\\frac{m}{2\\sigma^2}+\\frac{1}{2\\eta^2}\\right)+2\\theta\\left(\\frac{m\\overline{S}}{2\\sigma^2}+\\frac{\\mu}{2\\eta^2}\\right)-\\left(\\displaystyle\\sum_{j=1}^m\\displaystyle\\frac{S_j^2}{2\\sigma^2}\\right)-\\frac{\\mu^2}{2\\eta^2}.\\] Completando el cuadrado en \\(\\theta\\), este exponente se puede escribir como sigue \\[-\\displaystyle\\frac{\\left[\\theta-\\left(\\frac{m\\overline{S}}{\\sigma^2}+\\frac{\\mu}{\\eta^2}\\right)/\\left(\\frac{m}{\\sigma^2}+\\frac{1}{\\eta^2}\\right)\\right]}{2\\left(\\frac{m}{\\sigma^2}+\\frac{1}{\\eta^2}\\right)^{-1}}+\\displaystyle\\frac{\\left(\\frac{m\\overline{S}}{\\sigma^2}+\\frac{\\mu}{\\eta^2}\\right)^2}{2\\left(\\frac{m}{\\sigma^2}+\\frac{1}{\\eta^2}\\right)}-\\left(\\displaystyle\\sum_{j=1}^m\\frac{S_j^2}{2\\sigma^2}\\right)-\\frac{\\mu^2}{2\\eta^2}.\\] Este exponente aparece tanto en el numerador como en el denominador, y como los últimos dos sumandos no dependen de \\(\\theta\\) éstos desaparecen completamente al hacer el cociente. Lo que resulta es nuevamente la distribución normal \\[g(\\theta|S_1,...,S_m)=\\displaystyle\\frac{1}{\\sqrt{2\\pi \\left(\\frac{m}{\\sigma^2}+\\frac{1}{\\eta^2}\\right)^{-1}}}exp\\left\\{-\\frac{\\left[\\theta-{\\left(\\frac{m\\overline{S}}{\\sigma^2}+\\frac{\\mu}{\\eta^2}\\right)/\\left(\\frac{m}{\\sigma^2}+\\frac{1}{\\eta^2}\\right)}\\right]^2}{2\\left(\\frac{m}{\\sigma^2}+\\frac{1}{\\eta^2}\\right)^{-1}}\\right\\}.\\] La media de esta distribución es entonces la prima por credibilidad, es decir, \\[\\begin{eqnarray*} {prima}&amp;=&amp; E(\\theta|S_1,...,S_m)\\\\ &amp;=&amp; {\\left(\\frac{m\\overline{S}}{\\sigma^2}+\\frac{\\mu}{\\eta^2}\\right)/\\left(\\frac{m}{\\sigma^2}+\\frac{1}{\\eta^2}\\right)}\\\\ &amp;=&amp; \\displaystyle\\frac{m\\eta^2}{m\\eta^2+\\sigma^2}\\overline{S}+\\displaystyle\\frac{\\sigma^2}{m\\eta^2+\\sigma^2}\\mu\\\\ &amp;=&amp; z\\overline{S}+(1-z)\\mu, \\end{eqnarray*}\\] en donde \\(z=\\frac{m\\eta^2}{(m\\eta^2+\\sigma^2)}\\) es el factor de credibilidad, el cual tiene nuevamente comportamiento monótono creciente a uno conforme \\(m\\) crece a infinito. Observe además que \\(Var(\\theta|\\underline{S})=(\\frac{m}{\\sigma^2}+\\frac{1}{\\eta^2})^{-1}\\) y que esta cantidad converge a cero cuando el tamaño de muestra \\(m\\) crece a infinito, indicando nuevamente que la distribución a posteriori se concentra cada vez más alrededor de su media. Ejemplo: Suponga \\(\\{X_i\\}_{i=1}^n\\) una muestra aleatoria con distribución \\(Bernoulli(\\Theta)\\) y consideremos \\(\\Theta\\sim Beta(\\Lambda=(a,b))\\). Con base en esto, ya vimos que: \\(\\hat{\\Theta}=\\displaystyle\\frac{n\\overline{X}+a}{n+a+b}=\\displaystyle\\frac{n}{n+a+b}\\overline{X}+\\frac{1}{n+a+b}a\\) Sea \\(Z\\) tal que: \\(\\displaystyle\\frac{1}{n+a+b}={Z}\\frac{1}{a+b}\\Leftrightarrow{Z}=\\displaystyle\\frac{a+b}{n+a+b}\\in(0,1)\\), además notemos que: \\(1-{Z}=1-\\displaystyle\\frac{a+b}{n+a+b}\\). De tal manera que: \\[\\begin{eqnarray*} \\hat{\\Theta}&amp;=&amp;\\displaystyle\\frac{n}{n+a+b}\\overline{X}+\\frac{1}{n+a+b}a=(1-{Z})\\overline{X}+{Z}\\frac{a}{a+b}\\\\ &amp;=&amp;(1-{Z})\\overline{X}+{Z}{\\mathbb{E}[\\theta]};\\mbox{ si }{Z&#39;}\\ \\ \\ddot{=}\\ \\ 1-{Z} \\end{eqnarray*}\\] \\[\\begin{eqnarray*} \\therefore \\underset{{\\hookrightarrow\\mbox{ De credibilidad Bayesiana}}}{\\begin{array}{cc} {\\text{Prima final}} {\\text{(Posterior)}} \\end{array}={\\hat{\\Theta}}} &amp;=&amp;{Z&#39;}{\\overline{X}}+(1-{Z&#39;}){\\mathbb{E}[\\Theta]}\\\\ &amp;=&amp;{Z&#39;}{\\left(\\begin{array}{cc} \\text{Experiencia} \\\\ \\text{de los datos} \\end{array}\\right)}+(1-{Z&#39;}){\\left(\\begin{array}{cc} \\text{Prima inicial} \\\\ \\text{(a priori)} \\end{array}\\right)} \\end{eqnarray*}\\] Nota: En esta metodología, debemos tener en cuenta que pensamos a la prima de riesgo como una v.a. que cambia con base en la muestra y \\(\\mathbb{E}[S|\\Theta=\\theta]=\\theta\\). Pero puede ser que \\(\\mathbb{E}[S|\\Theta=\\theta]=\\tau(\\theta)\\) Un par de últimas observaciones de lo que se está haciendo. Noten que la prima de credibilidad bayesiana se puede obtener sin calcular el factor de credibilidad \\(Z\\), más bien, se obtiene simplemente de actualizar la distribución inicial. La aparición de \\(Z\\) se hace para observar qué tanto se otorga en la transformación lineal convexa, a la experiencia muestral y a la propuesta teórica. \\[{Z}{\\overline{X}}+(1-{Z}){\\mathbb{E}[\\Theta]}\\] Por eso en credibilidad Bayesiana es fundamentar proponer una distribución inicial que tenga como media (al menos de forma numérica) la Prima de Riesgo teórica que se propone en el modelo inicial. También se debe recalcar que el modelo que se propone inicialmente es para \\(p(\\underline{x}| \\theta)\\) (la verosimilitud) no para \\(p(\\theta)\\) (la distribución inicial). Esto significa que todo lo que vimos en la primera parte del curso es para \\(p(\\underline{x}|\\theta)\\). Mientras que \\(p(\\theta)\\) se propone “a colmillo” y tal teóricamente: si \\(\\mathbb{E}[{S}]=\\mathbb{E}[{S}|\\Theta={\\theta}]={\\tau({\\theta})}\\Rightarrow{\\tau({\\mathbb{E}[\\Theta]})}={\\tau({\\theta})}\\) Más aún, la prima de riesgo de Credibilidad Beyesiana y el factor de credibilidad Bayesiana son respectivamente: \\({\\tau({\\hat{\\Theta}})}={\\tau({\\mathbb{E}[\\Theta|\\underline{S}]})}\\)   y \\({Z}\\hspace{0.4em} \\cdot)\\cdot\\)   \\({\\tau({\\hat{\\Theta}})}{Z}{\\overline{S}}+(1-{Z}){\\tau({\\mathbb{E}[\\Theta]})}\\) Todo esto significa que debemos plantear la distribución inicial con base en nuestro modelo y luego simplemente actualizarlo. Vía estadística Bayesiana. Ejemplo: Por muchos años un investigador ha estudiado una muestra de observaciones \\({S}_i\\). Él ha dicho en diversos artículos que \\({S}_i\\sim Exp({\\lambda}),\\mathbb{E}[{S}_i]=2\\hspace{0.4em}\\forall i\\). Hoy en día existe un fenómeno natural que hace dudar que \\({\\lambda}=\\frac{1}{2}\\). Pero no se sabe qué valor pueda tomar \\(\\lambda\\), así que los expertos en las \\({S}_i\\)’s han dicho que \\(\\lambda\\), podría tener un comportamiento \\({\\Lambda\\sim Gamma(\\alpha,\\beta)}\\) con \\(\\alpha=2\\). Hoy se tomó una muestra aleatoria de \\({S}\\) la cual es la siguiente: \\(2.71,11.04,0.53,0.88,0.14,7.13,5.35,2.82,1.14,5.09\\). Si \\({S}\\) está asociado a un monto de siniestros. ¿Cuál sería una prima de riesgo adecuada dada esta información? Solución: Como el investigador decía que antes \\(\\mathbb{E}[{S}_i]=2\\) y se ha propuesto una distribución inicial \\({\\Lambda}\\sim Gamma(2,\\beta)\\) entonces: \\(\\mathbb{E}[|\\Lambda=\\lambda]={{\\tau({\\lambda})}=\\displaystyle\\frac{{1}}{{\\lambda}}}= 2 \\Rightarrow \\frac{\\beta}{2}=\\frac{{1}}{{\\mathbb{E}[\\Lambda]}}= {\\tau({\\mathbb{E}[\\Lambda]})}={\\tau({\\lambda})}=2\\) Los expertos proponen una distribución inicial \\({\\Lambda}\\sim Gamma({\\alpha}=2,{\\beta}=4)\\). Trabajando con la nueva información: Distribución inicial: \\(P(\\lambda)\\sim Gamma({\\alpha}=2,{\\beta}=4)\\) Verosimilitud: \\(P(\\underline{S}|\\lambda)\\sim Exp({\\Lambda})\\). \\[\\begin{eqnarray*} &amp;\\Rightarrow&amp; \\mbox{ Distribución final: }p(\\lambda|\\underline{S})\\sim {\\underbrace{{Gamma({\\alpha}+{n}=12,{\\beta}+{\\displaystyle\\sum_{i=1}^n S_i}=\\text{40.83})}}_{\\mbox{ejercicio para el lector}}}\\\\ &amp;\\Rightarrow&amp; {\\hat{\\Lambda}}\\ \\ddot{=} {\\mathbb{E}[\\Lambda|\\underline{S}]}=\\frac{12}{\\text{40.83}}=\\frac{400}{1361}\\approx \\text{0.293901543}\\\\ &amp;\\Rightarrow&amp; \\mbox{Prima de Riesgo de C.B.}={\\tau({\\hat{\\Lambda}}})=\\frac{1361}{400} \\end{eqnarray*}\\] \\(\\therefore\\) La prima de riesgo actualizada es 3.4025. Ejemplo (Parte 2): Del ejemplo anterior ¿cuál sería el factor de credibilidad? Solución: Buscamos \\({Z}\\) tal que: \\[\\begin{eqnarray*} {Z}\\left(\\frac{\\text{36.83}}{10}\\right)+(1-{Z})(2)={Z}{\\overline{S}}+(1-{Z}){\\tau\\left({\\mathbb{E}[\\Lambda]}\\right)}=\\begin{array}{cc} {\\text{Prima}} \\\\ {\\text{de}}\\\\ {\\text{Riesgo}} \\end{array}={\\tau({\\hat{\\Lambda}})}=\\text{3.4025}\\\\ \\end{eqnarray*}\\] \\[\\begin{eqnarray*} &amp;\\Rightarrow &amp;\\text{3.683}Z+\\text{2.2}Z=2+\\text{1.6837}=\\text{3.4025}\\Leftrightarrow {Z}=\\frac{\\text{3.4025}-2}{\\text{1.683}}\\hspace{3.3cm}\\\\ &amp;\\therefore&amp; \\text{El factor de credibilidad es} {Z}=\\frac{\\text{3.4025}-2}{\\text{1.683}}=\\frac{5}{6}\\approx\\text{83.3}\\overline{3}\\%\\hspace{2.4cm} \\end{eqnarray*}\\] Moraleja: Recuerda siempre lo que se está haciendo y cómo se está haciendo. Nota: Todo esto tiene sentido pues el autor obtuvo los datos de una \\(Exponencial(\\lambda=\\frac{1}{4})\\) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
